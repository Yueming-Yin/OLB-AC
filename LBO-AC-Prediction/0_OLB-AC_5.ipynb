{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import math\n",
    "torch.manual_seed(8)\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP.AttentiveLayers_Sim_copy import Fingerprint, GRN, AFSE\n",
    "from AttentiveFP import Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set()\n",
    "from IPython.display import SVG, display\n",
    "import sascorer\n",
    "from AttentiveFP.utils import EarlyStopping\n",
    "from AttentiveFP.utils import Meter\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "import AttentiveFP.Featurizer\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kd_P31389_1_25\n",
      "model_file/0_GAFSE_Kd_P31389_1_25_run_0\n"
     ]
    }
   ],
   "source": [
    "train_filename = \"./data/benchmark/Kd_P31389_1_25_train.csv\"\n",
    "test_filename = \"./data/benchmark/Kd_P31389_1_25_test.csv\"\n",
    "test_active = 25\n",
    "val_rate = 0.15\n",
    "random_seed = 1\n",
    "file_list1 = train_filename.split('/')\n",
    "file1 = file_list1[-1]\n",
    "file1 = file1[:-10]\n",
    "number = '_run_0'\n",
    "model_file = \"model_file/0_GAFSE_\"+file1+number\n",
    "log_dir = f'log/{\"0_GAFSE_\"+file1}'+number\n",
    "result_dir = './result/0_GAFSE_'+file1+number\n",
    "print(file1)\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              smiles     value\n",
      "0    CN(C)CCCN1C(SCC1=O)C2=CC(=CC=C2)[N+](=O)[O-].Cl -3.600000\n",
      "1                          CC(=O)NC(=NCCCC1=CN=CN1)N -3.930000\n",
      "2       C1CCC(CC1)CCCOCCCC2=CN=CN2.C(=CC(=O)O)C(=O)O -3.900000\n",
      "3  CN(C)C1=CC=CC2=C1C=CC=C2S(=O)(=O)NCCCCCCN(C)CC... -1.249932\n",
      "4    C1=CC=C2C(=C1)C(=CN2)CCC(=O)NC(=NCCCC3=CN=CN3)N -2.600003\n",
      "number of all smiles:  178\n",
      "number of successfully processed smiles:  178\n",
      "                                              smiles     value  \\\n",
      "0    CN(C)CCCN1C(SCC1=O)C2=CC(=CC=C2)[N+](=O)[O-].Cl -3.600000   \n",
      "1                          CC(=O)NC(=NCCCC1=CN=CN1)N -3.930000   \n",
      "2       C1CCC(CC1)CCCOCCCC2=CN=CN2.C(=CC(=O)O)C(=O)O -3.900000   \n",
      "3  CN(C)C1=CC=CC2=C1C=CC=C2S(=O)(=O)NCCCCCCN(C)CC... -1.249932   \n",
      "4    C1=CC=C2C(=C1)C(=CN2)CCC(=O)NC(=NCCCC3=CN=CN3)N -2.600003   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0       CN(C)CCCN1C(=O)CSC1c1cccc([N+](=O)[O-])c1.Cl  \n",
      "1                         CC(=O)NC(N)=NCCCc1cnc[nH]1  \n",
      "2        O=C(O)C=CC(=O)O.c1ncc(CCCOCCCC2CCCCC2)[nH]1  \n",
      "3  COc1ccc(CN(CCN(C)CCCCCCNS(=O)(=O)c2cccc3c(N(C)...  \n",
      "4        NC(=NCCCc1cnc[nH]1)NC(=O)CCc1c[nH]c2ccccc12  \n"
     ]
    }
   ],
   "source": [
    "# task_name = 'Malaria Bioactivity'\n",
    "tasks = ['value']\n",
    "\n",
    "# train_filename = \"../data/active_inactive/median_active/EC50/Q99500.csv\"\n",
    "feature_filename = train_filename.replace('.csv','.pickle')\n",
    "filename = train_filename.replace('.csv','')\n",
    "prefix_filename = train_filename.split('/')[-1].replace('.csv','')\n",
    "train_df = pd.read_csv(train_filename, header=0, names = [\"smiles\",\"value\"],usecols=[0,1])\n",
    "# train_df = train_df[1:]\n",
    "# train_df = train_df.drop(0,axis=1,inplace=False) \n",
    "print(train_df[:5])\n",
    "# print(train_df.iloc(1))\n",
    "def add_canonical_smiles(train_df):\n",
    "    smilesList = train_df.smiles.values\n",
    "    print(\"number of all smiles: \",len(smilesList))\n",
    "    atom_num_dist = []\n",
    "    remained_smiles = []\n",
    "    canonical_smiles_list = []\n",
    "    for smiles in smilesList:\n",
    "        try:        \n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            atom_num_dist.append(len(mol.GetAtoms()))\n",
    "            remained_smiles.append(smiles)\n",
    "            canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "        except:\n",
    "            print(smiles)\n",
    "            pass\n",
    "    print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "    train_df = train_df[train_df[\"smiles\"].isin(remained_smiles)]\n",
    "    train_df['cano_smiles'] =canonical_smiles_list\n",
    "    return train_df\n",
    "# print(train_df)\n",
    "train_df = add_canonical_smiles(train_df)\n",
    "\n",
    "print(train_df.head())\n",
    "# plt.figure(figsize=(5, 3))\n",
    "# sns.set(font_scale=1.5)\n",
    "# ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "# plt.tight_layout()\n",
    "# # plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "# plt.show()\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "\n",
    "p_dropout= 0.03\n",
    "fingerprint_dim = 100\n",
    "\n",
    "weight_decay = 4.3 # also known as l2_regularization_lambda\n",
    "learning_rate = 4\n",
    "radius = 2 # default: 2\n",
    "T = 1\n",
    "per_task_output_units_num = 1 # for regression model\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  133\n",
      "number of successfully processed smiles:  133\n",
      "(133, 3)\n",
      "                                              smiles     value  \\\n",
      "0  CN(CCCCCCNC(=O)CCCCCNC1=CC=C(C2=NON=C12)[N+](=... -0.290035   \n",
      "1                 CN(C)CCCN1C(SCC1=O)C2=CC=C(C=C2)Cl -3.400001   \n",
      "2  C1CCN(CC1)CC2=CC(=CC=C2)OCCCN=C(NCCNC(=O)C3=CC... -3.199999   \n",
      "3  C1CN(CCN1CCCOC2=CC3=C(C=C2)C(=C(C(=O)O3)[N+](=... -1.100026   \n",
      "4                         C1CCC(CC1)CCCOCCCC2=CN=CN2 -3.900000   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0  COc1ccc(CN(CCN(C)CCCCCCNC(=O)CCCCCNc2ccc([N+](...  \n",
      "1                    CN(C)CCCN1C(=O)CSC1c1ccc(Cl)cc1  \n",
      "2  N#CNC(=NCCCOc1cccc(CN2CCCCC2)c1)NCCNC(=O)c1cc(...  \n",
      "3  O=c1oc2cc(OCCCN3CCN(Cc4ccccc4)CC3)ccc2c(O)c1[N...  \n",
      "4                        c1ncc(CCCOCCCC2CCCCC2)[nH]1  \n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_filename,header=0,names=[\"smiles\",\"value\"],usecols=[0,1])\n",
    "test_df = add_canonical_smiles(test_df)\n",
    "for l in test_df[\"cano_smiles\"]:\n",
    "    if l in train_df[\"cano_smiles\"]:\n",
    "        print(\"same smiles:\",l)\n",
    "        \n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/benchmark/Kd_P31389_1_25_train.pickle\n",
      "./data/benchmark/Kd_P31389_1_25_train\n",
      "311\n",
      "feature dicts file saved as ./data/benchmark/Kd_P31389_1_25_train.pickle\n"
     ]
    }
   ],
   "source": [
    "print(feature_filename)\n",
    "print(filename)\n",
    "total_df = pd.concat([train_df,test_df],axis=0)\n",
    "total_smilesList = total_df['smiles'].values\n",
    "print(len(total_smilesList))\n",
    "# if os.path.isfile(feature_filename):\n",
    "#     feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "# else:\n",
    "#     feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "feature_dicts = save_smiles_dicts(total_smilesList,filename)\n",
    "remained_df = total_df[total_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = total_df.drop(remained_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151, 3) (27, 3) (133, 3)\n"
     ]
    }
   ],
   "source": [
    "val_df = train_df.sample(frac=val_rate,random_state=random_seed)\n",
    "train_df = train_df.drop(val_df.index)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "train_df = train_df[train_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df[val_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df[test_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "print(train_df.shape,val_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([total_df[\"cano_smiles\"].values[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "loss_function = nn.MSELoss()\n",
    "model = Fingerprint(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "amodel = AFSE(fingerprint_dim, output_units_num, p_dropout)\n",
    "gmodel = GRN(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, p_dropout)\n",
    "model.cuda()\n",
    "amodel.cuda()\n",
    "gmodel.cuda()\n",
    "\n",
    "# optimizer = optim.Adam([\n",
    "# {'params': model.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# {'params': gmodel.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# ])\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "optimizer_AFSE = optim.Adam(params=amodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# optimizer_AFSE = optim.SGD(params=amodel.parameters(), lr = 0.01, momentum=0.9)\n",
    "\n",
    "optimizer_GRN = optim.Adam(params=gmodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# tensorboard = SummaryWriter(log_dir=\"runs/\"+start_time+\"_\"+prefix_filename+\"_\"+str(fingerprint_dim)+\"_\"+str(p_dropout))\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "# print(params)\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def sorted_show_pik(dataset, p, k, k_predict, i, acc):\n",
    "    p_value = dataset[tasks[0]].astype(float).tolist()\n",
    "    x = np.arange(0,len(dataset),1)\n",
    "#     print('plt',dataset.head(),p[:10],k_predict,k)\n",
    "#     plt.figure()\n",
    "#     fig, ax1 = plt.subplots()\n",
    "#     ax1.grid(False)\n",
    "#     ax2 = ax1.twinx()\n",
    "#     plt.grid(False)\n",
    "    plt.scatter(x,p,marker='.',s=6,color='r',label='predict')\n",
    "#     plt.ylabel('predict')\n",
    "    plt.scatter(x,p_value,s=6,marker=',',color='blue',label='p_value')\n",
    "    plt.axvline(x=k-1,ls=\"-\",c=\"black\")#添加垂直直线\n",
    "    k_value = np.ones(len(dataset))\n",
    "# #     print(EC50[k-1])\n",
    "    k_value = k_value*k_predict\n",
    "    plt.plot(x,k_value,'-',color='black')\n",
    "    plt.ylabel('p_value')\n",
    "    plt.title(\"epoch: {},  top-k recall: {}\".format(i,acc))\n",
    "    plt.legend(loc=3,fontsize=5)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def topk_acc2(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "    \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    k_true = true_sort[tasks[0]].values[k-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('k_true: ',type(k_true),k_true)\n",
    "#     print('k_true: ',k_true,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=k_true,'acc_num: ',len(df3[df3['predict'].values>=k_true]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k)\n",
    "    acc = len(df3[df3[tasks[0]].values>=k_true])/k #预测值前k个中真实排在前k个的个数/k\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/k\n",
    "    if k>active_num:\n",
    "        min_active = true_sort[tasks[0]].values[active_num-1]\n",
    "        acc = len(df3[df3[tasks[0]].values>=min_active])/k\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "def topk_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "        \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个，因为后面的全是-4.1\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    min_active = true_sort[tasks[0]].values[active_num-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('min_active: ',type(min_active),min_active)\n",
    "#     print('min_active: ',min_active,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=min_active,'acc_num: ',len(df3[df3['predict'].values>=min_active]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k,'active_num: ',active_num)\n",
    "    acc = len(df3[df3[tasks[0]].values>-4.1])/active_num #预测值前k个中真实排在前active_num个的个数/active_num\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/active_num\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "    \n",
    "def topk_acc_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    if k>active_num:\n",
    "        return topk_recall(df, predict, k, active_num, show_flag, i)\n",
    "    return topk_acc2(df,predict,k, active_num,show_flag,i)\n",
    "\n",
    "def weighted_top_index(df, predict, active_num):\n",
    "    weighted_acc_list=[]\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        acc, fp = topk_acc_recall(df, predict, k, active_num)\n",
    "        weight = (len(df)-k)/len(df)\n",
    "#         print('weight=',weight,'acc=',acc)\n",
    "        weighted_acc_list.append(acc*weight)#\n",
    "    weighted_acc_list = np.array(weighted_acc_list)\n",
    "#     print('weighted_acc_list=',weighted_acc_list)\n",
    "    return np.sum(weighted_acc_list)/weighted_acc_list.shape[0]\n",
    "\n",
    "def AP(df, predict, active_num):\n",
    "    prec = []\n",
    "    rec = []\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        prec_k, fp1 = topk_acc2(df,predict,k, active_num)\n",
    "        rec_k, fp2 = topk_recall(df, predict, k, active_num)\n",
    "        prec.append(prec_k)\n",
    "        rec.append(rec_k)\n",
    "    # 取所有不同的recall对应的点处的精度值做平均\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.], rec, [1.]))\n",
    "    mpre = np.concatenate(([0.], prec, [0.]))\n",
    "\n",
    "    # 计算包络线，从后往前取最大保证precise非减\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # 找出所有检测结果中recall不同的点\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "#     print(prec)\n",
    "#     print('prec='+str(prec)+'\\n\\n'+'rec='+str(rec))\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    # 用recall的间隔对精度作加权平均\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_r2(y,predict):\n",
    "#     print(y)\n",
    "#     print(predict)\n",
    "    y = torch.FloatTensor(y).reshape(-1,1)\n",
    "    predict = torch.FloatTensor(predict).reshape(-1,1)\n",
    "    y_mean = torch.mean(y)\n",
    "    predict_mean = torch.mean(predict)\n",
    "    \n",
    "    y1 = torch.pow(torch.mm((y-y_mean).t(),(predict-predict_mean)),2)\n",
    "    y2 = torch.mm((y-y_mean).t(),(y-y_mean))*torch.mm((predict-predict_mean).t(),(predict-predict_mean))\n",
    "#     print(y1,y2)\n",
    "    return y1/y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def l2_norm(input, dim):\n",
    "    norm = torch.norm(input, dim=dim, keepdim=True)\n",
    "    output = torch.div(input, norm+1e-6)\n",
    "    return output\n",
    "\n",
    "def normalize_perturbation(d,dim=-1):\n",
    "    output = l2_norm(d, dim)\n",
    "    return output\n",
    "\n",
    "def tanh(x):\n",
    "    return (torch.exp(x)-torch.exp(-x))/(torch.exp(x)+torch.exp(-x))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "def perturb_feature(f, model, alpha=1, lamda=10**-learning_rate, output_lr=False, output_plr=False, y=None):\n",
    "    mol_prediction = model(feature=f, d=0)\n",
    "    pred = mol_prediction.detach()\n",
    "#     f = torch.div(f, torch.norm(f, dim=-1, keepdim=True)+1e-9)\n",
    "    eps = 1e-6 * normalize_perturbation(torch.randn(f.shape))\n",
    "    eps = Variable(eps, requires_grad=True)\n",
    "    # Predict on randomly perturbed image\n",
    "    eps_p = model(feature=f, d=eps.cuda())\n",
    "    eps_p_ = model(feature=f, d=-eps.cuda())\n",
    "    p_aux = nn.Sigmoid()(eps_p/(pred+1e-6))\n",
    "    p_aux_ = nn.Sigmoid()(eps_p_/(pred+1e-6))\n",
    "#     loss = nn.BCELoss()(abs(p_aux),torch.ones_like(p_aux))+nn.BCELoss()(abs(p_aux_),torch.ones_like(p_aux_))\n",
    "    loss = loss_function(p_aux,torch.ones_like(p_aux))+loss_function(p_aux_,torch.ones_like(p_aux_))\n",
    "    loss.backward(retain_graph=True)\n",
    "\n",
    "    # Based on perturbed image, get direction of greatest error\n",
    "    eps_adv = eps.grad#/10**-learning_rate\n",
    "    optimizer_AFSE.zero_grad()\n",
    "    # Use that direction as adversarial perturbation\n",
    "    eps_adv_normed = normalize_perturbation(eps_adv)\n",
    "    d_adv = lamda * eps_adv_normed.cuda()\n",
    "    if output_lr:\n",
    "        f_p, max_lr = model(feature=f, d=d_adv, output_lr=output_lr)\n",
    "    f_p = model(feature=f, d=d_adv)\n",
    "    f_p_ = model(feature=f, d=-d_adv)\n",
    "    p = nn.Sigmoid()(f_p/(pred+1e-6))\n",
    "    p_ = nn.Sigmoid()(f_p_/(pred+1e-6))\n",
    "    vat_loss = loss_function(p,torch.ones_like(p))+loss_function(p_,torch.ones_like(p_))\n",
    "    if output_lr:\n",
    "        if output_plr:\n",
    "            loss = loss_function(mol_prediction,y)\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer_AFSE.zero_grad()\n",
    "            punish_lr = torch.norm(torch.mean(eps.grad,0))\n",
    "            return eps_adv, d_adv, vat_loss, mol_prediction, max_lr, punish_lr\n",
    "        return eps_adv, d_adv, vat_loss, mol_prediction, max_lr\n",
    "    return eps_adv, d_adv, vat_loss, mol_prediction\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "\n",
    "def d_loss(f, pred, model, y_val):\n",
    "    diff_loss = 0\n",
    "    length = len(pred)\n",
    "    for i in range(length):\n",
    "        for j in range(length):\n",
    "            if j == i:\n",
    "                continue\n",
    "            pred_diff = model(feature_only=True, feature1=f[i], feature2=f[j])\n",
    "            true_diff = y_val[i] - y_val[j]\n",
    "            diff_loss += loss_function(pred_diff, torch.Tensor([true_diff]).view(-1,1))\n",
    "    diff_loss = diff_loss/(length*(length-1))\n",
    "    return diff_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CE(x,y):\n",
    "    c = 0\n",
    "    l = len(y)\n",
    "    for i in range(l):\n",
    "        if y[i]==1:\n",
    "            c += 1\n",
    "    w1 = (l-c)/l\n",
    "    w0 = c/l\n",
    "    loss = -w1*y*torch.log(x+1e-6)-w0*(1-y)*torch.log(1-x+1e-6)\n",
    "    loss = loss.mean(-1)\n",
    "    return loss\n",
    "\n",
    "def weighted_CE_loss(x,y):\n",
    "    weight = 1/(y.detach().float().mean(0)+1e-9)\n",
    "    weighted_CE = nn.CrossEntropyLoss(weight=weight)\n",
    "#     atom_weights = (atom_weights-min(atom_weights))/(max(atom_weights)-min(atom_weights))\n",
    "    return weighted_CE(x, torch.argmax(y,-1))\n",
    "\n",
    "def generate_loss_function(refer_atom_list, x_atom, validity_mask, atom_list):\n",
    "    [a,b,c] = x_atom.shape\n",
    "    reconstruction_loss = 0\n",
    "    counter = 0\n",
    "    validity_mask = torch.from_numpy(validity_mask).cuda()\n",
    "    for i in range(a):\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        reconstruction_loss += weighted_CE_loss(refer_atom_list[i,:l,:16], x_atom[i,:l,:16]) - \\\n",
    "                        ((validity_mask[i,:l]*torch.log(1-atom_list[i,:l,:16]+1e-9)).sum(-1)/(validity_mask[i,:l].sum(-1)+1e-9)).mean(-1).mean(-1)\n",
    "        counter += 1\n",
    "    reconstruction_loss = reconstruction_loss/counter\n",
    "    return reconstruction_loss\n",
    "\n",
    "\n",
    "def train(model, amodel, gmodel, dataset, test_df, optimizer_list, loss_function, epoch):\n",
    "    model.train()\n",
    "    amodel.train()\n",
    "    gmodel.train()\n",
    "    optimizer, optimizer_AFSE, optimizer_GRN = optimizer_list\n",
    "    np.random.seed(epoch)\n",
    "    max_len = np.max([len(dataset),len(test_df)])\n",
    "    valList = np.arange(0,max_len)\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, max_len, batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[batch%len(dataset),:]\n",
    "        batch_test = test_df.loc[batch%len(test_df),:]\n",
    "        global_step = epoch * len(batch_list) + counter\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        smiles_list_test = batch_test.cano_smiles.values\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        x_atom_test, x_bonds_test, x_atom_index_test, x_bond_index_test, x_mask_test, smiles_to_rdkit_list_test = get_smiles_array(smiles_list_test,feature_dicts)\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                  torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),\n",
    "                                                  mol_feature=mol_feature,activated_features=activated_features.detach())\n",
    "        \n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        \n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        eps_adv, d_adv, vat_loss, mol_prediction, conv_lr, punish_lr = perturb_feature(mol_feature, amodel, alpha=1, \n",
    "                                                                                       lamda=10**-learning_rate, output_lr=True, \n",
    "                                                                                       output_plr=True, y=torch.Tensor(y_val).view(-1,1)) # 10**-learning_rate     \n",
    "        regression_loss = loss_function(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "        atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "                                      torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/1e-6,activated_features=activated_features.detach())\n",
    "        success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(smiles_list, x_atom, \n",
    "                            bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "                                                     refer_atom_list, refer_bond_list,topn=1)\n",
    "        reconstruction_loss = generate_loss_function(refer_atom_list, x_atom, validity_mask, atom_list)\n",
    "        x_atom_test = torch.Tensor(x_atom_test)\n",
    "        x_bonds_test = torch.Tensor(x_bonds_test)\n",
    "        x_bond_index_test = torch.cuda.LongTensor(x_bond_index_test)\n",
    "        \n",
    "        bond_neighbor_test = [x_bonds_test[i][x_bond_index_test[i]] for i in range(len(batch_test))]\n",
    "        bond_neighbor_test = torch.stack(bond_neighbor_test, dim=0)\n",
    "        activated_features_test, mol_feature_test = model(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "                                                          torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),\n",
    "                                                          torch.Tensor(x_mask_test),output_activated_features=True)\n",
    "#         mol_feature_test = torch.div(mol_feature_test, torch.norm(mol_feature_test, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features_test = torch.div(activated_features_test, torch.norm(activated_features_test, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_test, d_test, test_vat_loss, mol_prediction_test = perturb_feature(mol_feature_test, amodel, \n",
    "                                                                                    alpha=1, lamda=10**-learning_rate)\n",
    "        atom_list_test, bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),torch.cuda.LongTensor(x_atom_index_test),\n",
    "                                                torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "                                                mol_feature=mol_feature_test+d_test/1e-6,activated_features=activated_features_test.detach())\n",
    "        refer_atom_list_test, refer_bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "                                                            torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "                                                            mol_feature=mol_feature_test,activated_features=activated_features_test.detach())\n",
    "        success_smiles_batch_test, modified_smiles_test, success_batch_test, total_batch_test, reconstruction_test, validity_test, validity_mask_test = modify_atoms(smiles_list_test, x_atom_test, \n",
    "                            bond_neighbor_test, atom_list_test, bond_list_test,smiles_list_test,smiles_to_rdkit_list_test,\n",
    "                                                     refer_atom_list_test, refer_bond_list_test,topn=1)\n",
    "        test_reconstruction_loss = generate_loss_function(atom_list_test, x_atom_test, validity_mask_test, atom_list_test)\n",
    "        \n",
    "        if vat_loss>1 or test_vat_loss>1:\n",
    "            vat_loss = 1*(vat_loss/(vat_loss+1e-6).item())\n",
    "            test_vat_loss = 1*(test_vat_loss/(test_vat_loss+1e-6).item())\n",
    "        \n",
    "        logger.add_scalar('loss/regression', regression_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE', vat_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE_test', test_vat_loss, global_step)\n",
    "        logger.add_scalar('loss/GRN', reconstruction_loss, global_step)\n",
    "        logger.add_scalar('loss/GRN_test', test_reconstruction_loss, global_step)\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_AFSE.zero_grad()\n",
    "        optimizer_GRN.zero_grad()\n",
    "        loss =  regression_loss + 0.6 * (vat_loss + test_vat_loss) + reconstruction_loss + test_reconstruction_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_AFSE.step()\n",
    "        optimizer_GRN.step()\n",
    "\n",
    "        \n",
    "def clear_atom_map(mol):\n",
    "    [a.ClearProp('molAtomMapNumber') for a  in mol.GetAtoms()]\n",
    "    return mol\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "        \n",
    "def modify_atoms(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list,refer_atom_list, refer_bond_list,topn=1,viz=False):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    refer_atom_list = refer_atom_list.cpu().detach().numpy()\n",
    "    refer_bond_list = refer_bond_list.cpu().detach().numpy()\n",
    "    atom_symbol_sorted = np.argsort(x_atom[:,:,:16], axis=-1)\n",
    "    atom_symbol_generated_sorted = np.argsort(atom_list[:,:,:16], axis=-1)\n",
    "    generate_confidence_sorted = np.sort(atom_list[:,:,:16], axis=-1)\n",
    "    modified_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    confidence_threshold = 0.001\n",
    "    validity_mask = np.zeros_like(atom_list[:,:,:16])\n",
    "    symbol_list = ['B','C','N','O','F','Si','P','S','Cl','As','Se','Br','Te','I','At','other']\n",
    "    symbol_to_rdkit = [4,6,7,8,9,14,15,16,17,33,34,35,52,53,85,0]\n",
    "    for i in range(len(atom_list)):\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        first_run_flag = True\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "        mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "        counter = 0\n",
    "        for j in range(l): \n",
    "            if mol.GetAtomWithIdx(int(smiles_to_rdkit_list[cano_smiles][j])).GetAtomicNum() == \\\n",
    "                symbol_to_rdkit[refer_atom_list[i,j,:16].argmax(-1)]:\n",
    "                counter += 1\n",
    "#             print(f'atom#{smiles_to_rdkit_list[cano_smiles][j]}(f):',{symbol_list[k]: np.around(refer_atom_list[i,j,k],3) for k in range(16)},\n",
    "#                   f'\\natom#{smiles_to_rdkit_list[cano_smiles][j]}(f+d):',{symbol_list[k]: np.around(atom_list[i,j,k],3) for k in range(16)},\n",
    "#                  '\\n------------------------------------------------------------------------------------------------------------')\n",
    "#         print('预测为每个原子的平均概率：\\n',np.around(atom_list[i,:l,:16].mean(1),2))\n",
    "#         print('预测为每个原子的最大概率：\\n',np.around(atom_list[i,:l,:16].max(1),2))\n",
    "        if counter == l:\n",
    "            success_reconstruction += 1\n",
    "        while not flag==topn:\n",
    "            if rank == 16:\n",
    "                rank = 0\n",
    "                top_idx += 1\n",
    "            if top_idx == l:\n",
    "#                 print('没有满足条件的分子生成。')\n",
    "                flag += 1\n",
    "                continue\n",
    "#             if np.sum((atom_symbol_sorted[i,:l,-1]!=atom_symbol_generated_sorted[i,:l,-1-rank]).astype(int))==0:\n",
    "#                 print(f'根据预测的第{rank}大概率的原子构成的分子与原分子一致，原子位重置为0，生成下一个元素……')\n",
    "#                 rank += 1\n",
    "#                 top_idx = 0\n",
    "#                 generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "#                                              x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "#             print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            if rank == 0:\n",
    "                generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "                                             x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "            atom_symbol_generated = np.argsort(atom_list[i,generate_index,:16]-\\\n",
    "                                                    refer_atom_list[i,generate_index,:16] -\\\n",
    "                                                    x_atom[i,generate_index,:16])[-1-rank]\n",
    "            if atom_symbol_generated==x_atom[i,generate_index,:16].argmax(-1):\n",
    "#                 print('生成了相同元素，生成下一个元素……')\n",
    "                rank += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            if np.sort(atom_list[i,generate_index,:16]-\\\n",
    "                refer_atom_list[i,generate_index,:16] -\\\n",
    "                x_atom[i,generate_index,:16])[-1-rank]<confidence_threshold:\n",
    "#                 print(f'原子位{generate_rdkit_index}生成{symbol_list[atom_symbol_generated]}元素的置信度小于{confidence_threshold}，寻找下一个原子位……')\n",
    "                top_idx += 1\n",
    "                rank = 0\n",
    "                continue\n",
    "#             if symbol_to_rdkit[atom_symbol_generated]==6:\n",
    "#                 print('生成了不推荐的C元素')\n",
    "#                 rank += 1\n",
    "#                 continue\n",
    "            mol.GetAtomWithIdx(int(generate_rdkit_index)).SetAtomicNum(symbol_to_rdkit[atom_symbol_generated])\n",
    "            print_mol = mol\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                if first_run_flag == True:\n",
    "                    success_validity += 1\n",
    "                total[flag] += 1\n",
    "                if Chem.MolToSmiles(clear_atom_map(print_mol))==y_smiles[i]:\n",
    "                    success[flag] +=1\n",
    "#                     print('Congratulations!', success, total)\n",
    "                    success_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "#                 print(\"修改前的分子：\", smiles[i])\n",
    "#                 display(mol_init)\n",
    "                modified_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 print(f\"将第{generate_rdkit_index}个原子修改为{symbol_list[atom_symbol_generated]}的分子：\", Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 display(mol_with_atom_index(mol))\n",
    "                mol_y = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "#                 print(\"高活性分子：\", y_smiles[i])\n",
    "#                 display(mol_y)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "#                 print(f\"第{generate_rdkit_index}个原子符号修改为{symbol_list[atom_symbol_generated]}不符合规范，生成下一个元素……\")\n",
    "                validity_mask[i,generate_index,atom_symbol_generated] = 1\n",
    "                rank += 1\n",
    "                first_run_flag = False\n",
    "    return success_smiles, modified_smiles, success, total, success_reconstruction, success_validity, validity_mask\n",
    "\n",
    "def modify_bonds(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    modified_smiles = []\n",
    "    for i in range(len(bond_neighbor)):\n",
    "        l = (bond_neighbor[i].sum(-1).sum(-1)!=0).sum(-1)\n",
    "        bond_type_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        bond_type_generated_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        generate_confidence_sorted = np.sort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        while not flag==3:\n",
    "            cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "            if np.sum((bond_type_sorted[i,:,-1]!=bond_type_generated_sorted[:,:,-1-rank]).astype(int))==0:\n",
    "                rank += 1\n",
    "                top_idx = 0\n",
    "            print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            bond_type = bond_type_sorted[i,:,-1]\n",
    "            bond_type_generated = bond_type_generated_sorted[:,:,-1-rank]\n",
    "            generate_confidence = generate_confidence_sorted[:,:,-1-rank]\n",
    "#             print(np.sort(generate_confidence + \\\n",
    "#                                     (atom_symbol!=atom_symbol_generated).astype(int), axis=-1))\n",
    "            generate_index = np.argsort(generate_confidence + \n",
    "                                (bond_type!=bond_type_generated).astype(int), axis=-1)[-1-top_idx]\n",
    "            bond_type_generated_one = bond_type_generated[generate_index]\n",
    "            mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "            if generate_index >= len(smiles_to_rdkit_list[cano_smiles]):\n",
    "                top_idx += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            mol.GetBondWithIdx(int(generate_rdkit_index)).SetBondType(bond_type_generated_one)\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "                print(\"修改前的分子：\")\n",
    "                display(mol_init)\n",
    "                modified_smiles.append(mol)\n",
    "                print(f\"将第{generate_rdkit_index}个键修改为{atom_symbol_generated}的分子：\")\n",
    "                display(mol)\n",
    "                mol = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "                print(\"高活性分子：\")\n",
    "                display(mol)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "                print(f\"第{generate_rdkit_index}个原子符号修改为{atom_symbol_generated}不符合规范\")\n",
    "                top_idx += 1\n",
    "    return modified_smiles\n",
    "        \n",
    "def eval(model, amodel, gmodel, dataset, topn=1, output_feature=False, generate=False, modify_atom=True,return_GRN_loss=False, viz=False):\n",
    "    model.eval()\n",
    "    amodel.eval()\n",
    "    gmodel.eval()\n",
    "    predict_list = []\n",
    "    test_MSE_list = []\n",
    "    r2_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    feature_list = []\n",
    "    d_list = []\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    generated_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    reconstruction_loss, one_hot_loss, interger_loss, binary_loss = [0,0,0,0]\n",
    "    \n",
    "# #     取dataset中排序后的第k个\n",
    "#     sorted_dataset = dataset.sort_values(by=tasks[0],ascending=False)\n",
    "#     k_df = sorted_dataset.iloc[[k-1]]\n",
    "#     k_smiles = k_df['cano_smiles'].values\n",
    "#     k_value = k_df[tasks[0]].values.astype(float)    \n",
    "    \n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch) \n",
    "#     print(batch_list)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "#         print(type(batch))\n",
    "        batch_df = dataset.loc[batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        matched_smiles_list = smiles_list\n",
    "#         print(batch_df)\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "#         print(type(y_val))\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(matched_smiles_list,feature_dicts)\n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        lamda=10**-learning_rate\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_adv, d_adv, vat_loss, mol_prediction = perturb_feature(mol_feature, amodel, alpha=1, lamda=lamda)\n",
    "#         print(mol_feature,d_adv)\n",
    "        atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),\n",
    "                                      torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "                                      torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/(1e-6),activated_features=activated_features)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),mol_feature=mol_feature,activated_features=activated_features)\n",
    "        if generate:\n",
    "            if modify_atom:\n",
    "                success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(matched_smiles_list, x_atom, \n",
    "                            bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "                                                     refer_atom_list, refer_bond_list,topn=topn,viz=viz)\n",
    "            else:\n",
    "                modified_smiles = modify_bonds(matched_smiles_list, x_atom, bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list)\n",
    "            generated_smiles.extend(modified_smiles)\n",
    "            success_smiles.extend(success_smiles_batch)\n",
    "#             for n in range(topn):\n",
    "#                 success[n] += success_batch[n]\n",
    "#                 total[n] += total_batch[n]\n",
    "#                 print('congratulations:',success,total)\n",
    "            success_reconstruction += reconstruction\n",
    "            success_validity += validity\n",
    "            reconstruction_loss, one_hot_loss, interger_loss, binary_loss = generate_loss_function(refer_atom_list, x_atom, refer_bond_list, bond_neighbor, validity_mask, atom_list, bond_list)\n",
    "        d = d_adv.cpu().detach().numpy().tolist()\n",
    "        d_list.extend(d)\n",
    "        mol_feature_output = mol_feature.cpu().detach().numpy().tolist()\n",
    "        feature_list.extend(mol_feature_output)\n",
    "#         MAE = F.l1_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')   \n",
    "#         print(type(mol_prediction))\n",
    "        \n",
    "        MSE = F.mse_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')\n",
    "#         r2 = caculate_r2(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "# #         r2_list.extend(r2.cpu().detach().numpy())\n",
    "#         if r2!=r2:\n",
    "#             r2 = torch.tensor(0)\n",
    "#         r2_list.append(r2.item())\n",
    "#         predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         print(x_mask[:2],atoms_prediction.shape, mol_prediction,MSE)\n",
    "        predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         test_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n",
    "        test_MSE_list.extend(MSE.data.view(-1,1).cpu().numpy())\n",
    "#     print(r2_list)\n",
    "    if generate:\n",
    "        generated_num = len(generated_smiles)\n",
    "        eval_num = len(dataset)\n",
    "        unique = generated_num\n",
    "        novelty = generated_num\n",
    "        for i in range(generated_num):\n",
    "            for j in range(generated_num-i-1):\n",
    "                if generated_smiles[i]==generated_smiles[i+j+1]:\n",
    "                    unique -= 1\n",
    "            for k in range(eval_num):\n",
    "                if generated_smiles[i]==dataset['smiles'].values[k]:\n",
    "                    novelty -= 1\n",
    "        unique_rate = unique/(generated_num+1e-9)\n",
    "        novelty_rate = novelty/(generated_num+1e-9)\n",
    "#         print(f'successfully/total generated molecules =', {f'Top-{i+1}': f'{success[i]}/{total[i]}' for i in range(topn)})\n",
    "        return success_reconstruction/len(dataset), success_validity/len(dataset), unique_rate, novelty_rate, success_smiles, generated_smiles, caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    if return_GRN_loss:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list,reconstruction_loss, one_hot_loss, interger_loss,binary_loss\n",
    "    if output_feature:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    return caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "\n",
    "epoch = 0\n",
    "max_epoch = 1000\n",
    "batch_size = 10\n",
    "patience = 30\n",
    "stopper = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_model.pth')\n",
    "stopper_afse = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_amodel.pth')\n",
    "stopper_generate = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_gmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log/0_GAFSE_Kd_P31389_1_25_run_0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "now = datetime.datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "if os.path.isdir(log_dir):\n",
    "    for files in os.listdir(log_dir):\n",
    "        os.remove(log_dir+\"/\"+files)\n",
    "    os.rmdir(log_dir)\n",
    "logger = SummaryWriter(log_dir)\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3078571/3510960041.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  y = torch.FloatTensor(y).reshape(-1,1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Step: 15 Index:0.0124 R2:0.0350 0.0124 0.1081 RMSE:1.5943 1.8478 1.5284 Tau:-0.1101 0.1066 -0.3244\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 2 Step: 30 Index:0.0102 R2:0.0323 0.0102 0.1059 RMSE:1.5805 1.6692 1.5941 Tau:-0.1069 0.1009 -0.3193\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 3 Step: 45 Index:0.0056 R2:0.0254 0.0056 0.1022 RMSE:1.5119 1.7209 1.4610 Tau:-0.0938 0.1066 -0.3088\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 4 Step: 60 Index:0.0030 R2:0.0205 0.0030 0.0973 RMSE:1.4696 1.6316 1.4339 Tau:-0.0873 0.0951 -0.2963\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 5 Step: 75 Index:0.0007 R2:0.0149 0.0007 0.0914 RMSE:1.4357 1.5285 1.4196 Tau:-0.0793 0.0836 -0.2831\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 6 Step: 90 Index:0.0013 R2:0.0061 0.0013 0.0787 RMSE:1.3933 1.5485 1.3547 Tau:-0.0639 0.0951 -0.2604\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 7 Step: 105 Index:0.0120 R2:0.0007 0.0120 0.0625 RMSE:1.3498 1.4536 1.3193 Tau:-0.0447 0.1009 -0.2238\n",
      "Epoch: 8 Step: 120 Index:0.0778 R2:0.0069 0.0778 0.0285 RMSE:1.3091 1.4164 1.2751 Tau:0.0067 0.1066 -0.1478\n",
      "Epoch: 9 Step: 135 Index:0.3384 R2:0.1006 0.3384 0.0062 RMSE:1.2690 1.4060 1.2294 Tau:0.1810 0.3545 0.0164\n",
      "Epoch: 10 Step: 150 Index:0.3527 R2:0.2015 0.3527 0.0610 RMSE:1.2384 1.3344 1.1983 Tau:0.2967 0.4121 0.1123\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 11 Step: 165 Index:0.2876 R2:0.2720 0.2876 0.1188 RMSE:1.2140 1.3066 1.1737 Tau:0.4044 0.4525 0.2125\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 12 Step: 180 Index:0.2282 R2:0.2885 0.2282 0.1573 RMSE:1.1903 1.3120 1.1516 Tau:0.4256 0.4582 0.2912\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 13 Step: 195 Index:0.1828 R2:0.2744 0.1828 0.1812 RMSE:1.1861 1.3775 1.1590 Tau:0.4139 0.4525 0.3606\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 14 Step: 210 Index:0.2396 R2:0.3042 0.2396 0.1706 RMSE:1.1876 1.2483 1.1433 Tau:0.4374 0.4755 0.3033\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 15 Step: 225 Index:0.1828 R2:0.2789 0.1828 0.1961 RMSE:1.1605 1.3375 1.1329 Tau:0.4138 0.4582 0.3821\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 16 Step: 240 Index:0.2298 R2:0.3094 0.2298 0.1807 RMSE:1.1515 1.2605 1.1225 Tau:0.4427 0.5044 0.3334\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 17 Step: 255 Index:0.2132 R2:0.3089 0.2132 0.1978 RMSE:1.1357 1.3057 1.1216 Tau:0.4333 0.4986 0.3700\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 18 Step: 270 Index:0.2731 R2:0.3404 0.2731 0.1761 RMSE:1.1568 1.1971 1.1327 Tau:0.4511 0.4986 0.3162\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 19 Step: 285 Index:0.2253 R2:0.3249 0.2253 0.2057 RMSE:1.1127 1.2812 1.1091 Tau:0.4382 0.4928 0.3829\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 20 Step: 300 Index:0.2180 R2:0.3243 0.2180 0.2180 RMSE:1.1075 1.3175 1.1205 Tau:0.4324 0.4640 0.4059\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch: 21 Step: 315 Index:0.2756 R2:0.3616 0.2756 0.2076 RMSE:1.1051 1.1819 1.0979 Tau:0.4628 0.4813 0.3552\n",
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch: 22 Step: 330 Index:0.2879 R2:0.3722 0.2879 0.2147 RMSE:1.0960 1.1676 1.0937 Tau:0.4660 0.4871 0.3595\n",
      "EarlyStopping counter: 13 out of 30\n",
      "Epoch: 23 Step: 345 Index:0.2756 R2:0.3694 0.2756 0.2302 RMSE:1.0620 1.2269 1.0857 Tau:0.4620 0.4928 0.3899\n",
      "EarlyStopping counter: 14 out of 30\n",
      "Epoch: 24 Step: 360 Index:0.2858 R2:0.3792 0.2858 0.2397 RMSE:1.0510 1.2146 1.0785 Tau:0.4657 0.5044 0.3914\n",
      "EarlyStopping counter: 15 out of 30\n",
      "Epoch: 25 Step: 375 Index:0.2985 R2:0.3902 0.2985 0.2484 RMSE:1.0385 1.1971 1.0703 Tau:0.4683 0.4928 0.3883\n",
      "Epoch: 26 Step: 390 Index:0.3814 R2:0.4276 0.3814 0.2344 RMSE:1.1217 1.0995 1.1340 Tau:0.4804 0.4986 0.3209\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 27 Step: 405 Index:0.3008 R2:0.4006 0.3008 0.2884 RMSE:1.0697 1.3152 1.1128 Tau:0.4659 0.4755 0.4074\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 28 Step: 420 Index:0.3333 R2:0.4212 0.3333 0.2846 RMSE:1.0218 1.1755 1.0466 Tau:0.4760 0.5101 0.3766\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 29 Step: 435 Index:0.3550 R2:0.4363 0.3550 0.2885 RMSE:1.0382 1.1055 1.0466 Tau:0.4768 0.5044 0.3653\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 30 Step: 450 Index:0.3441 R2:0.4372 0.3441 0.3110 RMSE:1.0087 1.1310 1.0225 Tau:0.4790 0.4813 0.3887\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 31 Step: 465 Index:0.3344 R2:0.4334 0.3344 0.3244 RMSE:1.0059 1.2040 1.0401 Tau:0.4788 0.4813 0.4004\n",
      "Epoch: 32 Step: 480 Index:0.3914 R2:0.4612 0.3914 0.2914 RMSE:1.0356 1.0630 1.0634 Tau:0.4900 0.4928 0.3478\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 33 Step: 495 Index:0.3857 R2:0.4644 0.3857 0.3129 RMSE:0.9796 1.1167 1.0211 Tau:0.4931 0.4755 0.3681\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 34 Step: 510 Index:0.3787 R2:0.4641 0.3787 0.3269 RMSE:0.9740 1.1459 1.0209 Tau:0.4990 0.4813 0.3829\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 35 Step: 525 Index:0.3860 R2:0.4687 0.3860 0.3296 RMSE:0.9669 1.1393 1.0189 Tau:0.5052 0.4640 0.3794\n",
      "Epoch: 36 Step: 540 Index:0.4222 R2:0.4804 0.4222 0.3143 RMSE:0.9644 1.0568 1.0186 Tau:0.5305 0.4582 0.3337\n",
      "Epoch: 37 Step: 555 Index:0.4276 R2:0.4802 0.4276 0.2984 RMSE:0.9804 1.0286 1.0476 Tau:0.5300 0.4582 0.3201\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 38 Step: 570 Index:0.4063 R2:0.4819 0.4063 0.3519 RMSE:0.9555 1.1368 1.0115 Tau:0.5245 0.4582 0.3677\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 39 Step: 585 Index:0.4184 R2:0.4887 0.4184 0.3451 RMSE:0.9393 1.0620 0.9930 Tau:0.5385 0.4582 0.3474\n",
      "Epoch: 40 Step: 600 Index:0.4306 R2:0.4922 0.4306 0.3281 RMSE:1.0007 1.0155 1.0585 Tau:0.5355 0.4525 0.3232\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 41 Step: 615 Index:0.4074 R2:0.4899 0.4074 0.3940 RMSE:0.9418 1.1135 0.9746 Tau:0.5311 0.4698 0.3774\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 42 Step: 630 Index:0.4177 R2:0.4979 0.4177 0.3919 RMSE:0.9307 1.0624 0.9594 Tau:0.5413 0.4582 0.3681\n",
      "Epoch: 43 Step: 645 Index:0.4336 R2:0.5045 0.4336 0.3843 RMSE:0.9320 1.0500 0.9674 Tau:0.5532 0.4525 0.3451\n",
      "Epoch: 44 Step: 660 Index:0.4353 R2:0.5092 0.4353 0.3832 RMSE:0.9275 1.0340 0.9667 Tau:0.5541 0.4525 0.3384\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 45 Step: 675 Index:0.4289 R2:0.5090 0.4289 0.3911 RMSE:0.9184 1.0534 0.9591 Tau:0.5541 0.4525 0.3587\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 46 Step: 690 Index:0.4286 R2:0.5116 0.4286 0.3996 RMSE:0.9168 1.0702 0.9579 Tau:0.5554 0.4525 0.3544\n",
      "Epoch: 47 Step: 705 Index:0.4372 R2:0.5151 0.4372 0.3845 RMSE:0.9529 1.0087 0.9953 Tau:0.5567 0.4352 0.3170\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 48 Step: 720 Index:0.4339 R2:0.5196 0.4339 0.4076 RMSE:0.9186 1.0430 0.9515 Tau:0.5606 0.4294 0.3201\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 49 Step: 735 Index:0.4358 R2:0.5229 0.4358 0.4092 RMSE:0.9157 1.0318 0.9497 Tau:0.5603 0.4294 0.3228\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 50 Step: 750 Index:0.4286 R2:0.5237 0.4286 0.4288 RMSE:0.9078 1.0581 0.9346 Tau:0.5614 0.4352 0.3474\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 51 Step: 765 Index:0.4357 R2:0.5273 0.4357 0.4140 RMSE:0.9229 1.0129 0.9522 Tau:0.5626 0.4352 0.3337\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 52 Step: 780 Index:0.4228 R2:0.5253 0.4228 0.4417 RMSE:0.9120 1.0968 0.9425 Tau:0.5649 0.4294 0.3610\n",
      "Epoch: 53 Step: 795 Index:0.4375 R2:0.5306 0.4375 0.4036 RMSE:0.9681 1.0128 1.0047 Tau:0.5653 0.4410 0.3154\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 54 Step: 810 Index:0.4213 R2:0.5285 0.4213 0.4563 RMSE:0.9429 1.1607 0.9770 Tau:0.5632 0.4237 0.3614\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 55 Step: 825 Index:0.4355 R2:0.5370 0.4355 0.4511 RMSE:0.9030 1.0774 0.9303 Tau:0.5675 0.4179 0.3493\n",
      "Epoch: 56 Step: 840 Index:0.4476 R2:0.5424 0.4476 0.4359 RMSE:0.9078 1.0055 0.9351 Tau:0.5716 0.4352 0.3369\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 57 Step: 855 Index:0.4371 R2:0.5409 0.4371 0.4548 RMSE:0.8925 1.0643 0.9215 Tau:0.5697 0.4121 0.3544\n",
      "Epoch: 58 Step: 870 Index:0.4541 R2:0.5495 0.4541 0.4347 RMSE:0.9278 0.9956 0.9592 Tau:0.5720 0.4237 0.3224\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 59 Step: 885 Index:0.4485 R2:0.5506 0.4485 0.4607 RMSE:0.8845 1.0450 0.9139 Tau:0.5771 0.4294 0.3513\n",
      "Epoch: 60 Step: 900 Index:0.4570 R2:0.5545 0.4570 0.4442 RMSE:0.8999 0.9928 0.9311 Tau:0.5762 0.4237 0.3384\n",
      "Epoch: 61 Step: 915 Index:0.4681 R2:0.5548 0.4681 0.4243 RMSE:0.8926 0.9838 0.9406 Tau:0.5792 0.4294 0.3388\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 62 Step: 930 Index:0.4664 R2:0.5564 0.4664 0.4395 RMSE:0.8742 1.0007 0.9190 Tau:0.5812 0.4467 0.3575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63 Step: 945 Index:0.4685 R2:0.5625 0.4685 0.4460 RMSE:0.8955 0.9806 0.9289 Tau:0.5848 0.4294 0.3497\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 64 Step: 960 Index:0.4554 R2:0.5608 0.4554 0.4736 RMSE:0.8807 1.0679 0.9206 Tau:0.5759 0.4294 0.3657\n",
      "Epoch: 65 Step: 975 Index:0.4759 R2:0.5696 0.4759 0.4448 RMSE:0.9145 0.9759 0.9521 Tau:0.5904 0.4294 0.3427\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 66 Step: 990 Index:0.4732 R2:0.5713 0.4732 0.4602 RMSE:0.8638 0.9918 0.9043 Tau:0.5893 0.4352 0.3571\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 67 Step: 1005 Index:0.4722 R2:0.5744 0.4722 0.4647 RMSE:0.8625 0.9863 0.9007 Tau:0.5904 0.4352 0.3564\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 68 Step: 1020 Index:0.4676 R2:0.5747 0.4676 0.4781 RMSE:0.8611 1.0382 0.9056 Tau:0.5876 0.4410 0.3642\n",
      "Epoch: 69 Step: 1035 Index:0.4812 R2:0.5794 0.4812 0.4523 RMSE:0.8719 0.9691 0.9218 Tau:0.5945 0.4294 0.3505\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 70 Step: 1050 Index:0.4770 R2:0.5817 0.4770 0.4724 RMSE:0.8474 1.0020 0.8956 Tau:0.5931 0.4352 0.3626\n",
      "Epoch: 71 Step: 1065 Index:0.4865 R2:0.5846 0.4865 0.4459 RMSE:0.9259 0.9760 0.9793 Tau:0.5943 0.4352 0.3392\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 72 Step: 1080 Index:0.4797 R2:0.5867 0.4797 0.4800 RMSE:0.8435 1.0073 0.8939 Tau:0.5955 0.4467 0.3661\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 73 Step: 1095 Index:0.4834 R2:0.5836 0.4834 0.4698 RMSE:0.8817 1.0835 0.9522 Tau:0.5936 0.4467 0.3708\n",
      "Epoch: 74 Step: 1110 Index:0.4973 R2:0.5916 0.4973 0.4510 RMSE:0.9266 0.9677 0.9757 Tau:0.6037 0.4237 0.3408\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 75 Step: 1125 Index:0.4920 R2:0.5966 0.4920 0.4744 RMSE:0.8407 0.9782 0.8934 Tau:0.6033 0.4467 0.3618\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 76 Step: 1140 Index:0.4865 R2:0.5987 0.4865 0.4957 RMSE:0.8381 1.0150 0.8897 Tau:0.5984 0.4410 0.3727\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 77 Step: 1155 Index:0.4902 R2:0.6037 0.4902 0.4988 RMSE:0.8289 0.9820 0.8737 Tau:0.6006 0.4525 0.3708\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 78 Step: 1170 Index:0.4945 R2:0.6078 0.4945 0.4968 RMSE:0.8336 0.9612 0.8757 Tau:0.6055 0.4698 0.3645\n",
      "Epoch: 79 Step: 1185 Index:0.5062 R2:0.6058 0.5062 0.4779 RMSE:0.8240 0.9627 0.8873 Tau:0.6060 0.4525 0.3677\n",
      "Epoch: 80 Step: 1200 Index:0.5095 R2:0.6126 0.5095 0.4869 RMSE:0.8367 0.9449 0.8891 Tau:0.6086 0.4467 0.3618\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 81 Step: 1215 Index:0.5040 R2:0.6170 0.5040 0.5027 RMSE:0.8187 0.9581 0.8685 Tau:0.6083 0.4410 0.3704\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 82 Step: 1230 Index:0.4981 R2:0.6189 0.4981 0.5179 RMSE:0.8159 0.9971 0.8698 Tau:0.6051 0.4352 0.3805\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 83 Step: 1245 Index:0.5005 R2:0.6216 0.5005 0.5206 RMSE:0.8148 0.9978 0.8697 Tau:0.6060 0.4352 0.3755\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 84 Step: 1260 Index:0.4849 R2:0.6211 0.4849 0.5238 RMSE:0.8439 0.9671 0.8760 Tau:0.6055 0.4121 0.3415\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 85 Step: 1275 Index:0.4822 R2:0.6237 0.4822 0.5454 RMSE:0.8149 1.0062 0.8491 Tau:0.6028 0.4006 0.3696\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 86 Step: 1290 Index:0.5075 R2:0.6273 0.5075 0.5274 RMSE:0.8033 0.9684 0.8520 Tau:0.6094 0.4467 0.3755\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 87 Step: 1305 Index:0.5023 R2:0.6295 0.5023 0.5359 RMSE:0.7975 0.9606 0.8391 Tau:0.6113 0.4410 0.3755\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 88 Step: 1320 Index:0.5085 R2:0.6334 0.5085 0.5327 RMSE:0.8040 0.9430 0.8435 Tau:0.6144 0.4410 0.3696\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 89 Step: 1335 Index:0.5078 R2:0.6345 0.5078 0.5332 RMSE:0.8199 0.9439 0.8548 Tau:0.6115 0.4410 0.3630\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 90 Step: 1350 Index:0.5081 R2:0.6353 0.5081 0.5409 RMSE:0.7916 0.9665 0.8410 Tau:0.6124 0.4352 0.3813\n",
      "Epoch: 91 Step: 1365 Index:0.5109 R2:0.6415 0.5109 0.5430 RMSE:0.7915 0.9438 0.8330 Tau:0.6152 0.4294 0.3759\n",
      "Epoch: 92 Step: 1380 Index:0.5124 R2:0.6399 0.5124 0.5454 RMSE:0.7873 0.9619 0.8375 Tau:0.6150 0.4294 0.3844\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 93 Step: 1395 Index:0.5008 R2:0.6413 0.5008 0.5578 RMSE:0.7870 0.9778 0.8325 Tau:0.6137 0.4410 0.3829\n",
      "Epoch: 94 Step: 1410 Index:0.5378 R2:0.6488 0.5378 0.5360 RMSE:0.8410 0.9276 0.8838 Tau:0.6231 0.4525 0.3599\n",
      "Epoch: 95 Step: 1425 Index:0.5389 R2:0.6523 0.5389 0.5529 RMSE:0.7745 0.9301 0.8251 Tau:0.6186 0.4410 0.3774\n",
      "Epoch: 96 Step: 1440 Index:0.5430 R2:0.6552 0.5430 0.5522 RMSE:0.7932 0.9099 0.8343 Tau:0.6223 0.4467 0.3747\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 97 Step: 1455 Index:0.5372 R2:0.6548 0.5372 0.5544 RMSE:0.7746 0.9433 0.8319 Tau:0.6244 0.4525 0.3868\n",
      "Epoch: 98 Step: 1470 Index:0.5459 R2:0.6606 0.5459 0.5501 RMSE:0.8059 0.9114 0.8478 Tau:0.6251 0.4294 0.3778\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 99 Step: 1485 Index:0.5390 R2:0.6568 0.5390 0.5601 RMSE:0.7879 0.9732 0.8510 Tau:0.6228 0.4467 0.3860\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 100 Step: 1500 Index:0.5431 R2:0.6644 0.5431 0.5680 RMSE:0.7660 0.9245 0.8136 Tau:0.6262 0.4352 0.3860\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 101 Step: 1515 Index:0.5425 R2:0.6630 0.5425 0.5692 RMSE:0.7685 0.9126 0.8078 Tau:0.6251 0.4352 0.3864\n",
      "Epoch: 102 Step: 1530 Index:0.5556 R2:0.6696 0.5556 0.5643 RMSE:0.7895 0.9011 0.8288 Tau:0.6280 0.4410 0.3805\n",
      "Epoch: 103 Step: 1545 Index:0.5704 R2:0.6663 0.5704 0.5384 RMSE:0.7602 0.8885 0.8340 Tau:0.6308 0.4813 0.3747\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 104 Step: 1560 Index:0.5584 R2:0.6705 0.5584 0.5667 RMSE:0.7534 0.9039 0.8096 Tau:0.6343 0.4352 0.3805\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 105 Step: 1575 Index:0.5671 R2:0.6744 0.5671 0.5588 RMSE:0.7484 0.8926 0.8157 Tau:0.6372 0.4525 0.3786\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 106 Step: 1590 Index:0.5609 R2:0.6768 0.5609 0.5655 RMSE:0.8027 0.9068 0.8475 Tau:0.6413 0.4467 0.3712\n",
      "Epoch: 107 Step: 1605 Index:0.5726 R2:0.6833 0.5726 0.5701 RMSE:0.7609 0.8857 0.8136 Tau:0.6389 0.4467 0.3794\n",
      "Epoch: 108 Step: 1620 Index:0.5734 R2:0.6819 0.5734 0.5682 RMSE:0.7876 0.8905 0.8349 Tau:0.6379 0.4525 0.3747\n",
      "Epoch: 109 Step: 1635 Index:0.5797 R2:0.6842 0.5797 0.5629 RMSE:0.7415 0.8940 0.8182 Tau:0.6379 0.4525 0.3813\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 110 Step: 1650 Index:0.5744 R2:0.6869 0.5744 0.5762 RMSE:0.7358 0.8904 0.8026 Tau:0.6379 0.4410 0.3844\n",
      "Epoch: 111 Step: 1665 Index:0.5800 R2:0.6870 0.5800 0.5682 RMSE:0.7387 0.8957 0.8144 Tau:0.6441 0.4467 0.3782\n",
      "Epoch: 112 Step: 1680 Index:0.5846 R2:0.6918 0.5846 0.5730 RMSE:0.7354 0.8760 0.8038 Tau:0.6438 0.4525 0.3798\n",
      "Epoch: 113 Step: 1695 Index:0.5904 R2:0.6931 0.5904 0.5682 RMSE:0.7307 0.8748 0.8088 Tau:0.6445 0.4467 0.3759\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 114 Step: 1710 Index:0.5877 R2:0.6937 0.5877 0.5774 RMSE:0.7351 0.8644 0.8009 Tau:0.6451 0.4467 0.3786\n",
      "Epoch: 115 Step: 1725 Index:0.5909 R2:0.6951 0.5909 0.5794 RMSE:0.7234 0.8654 0.7964 Tau:0.6450 0.4525 0.3798\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 116 Step: 1740 Index:0.5905 R2:0.6967 0.5905 0.5805 RMSE:0.8084 0.8987 0.8581 Tau:0.6460 0.4467 0.3751\n",
      "Epoch: 117 Step: 1755 Index:0.5920 R2:0.7006 0.5920 0.5887 RMSE:0.7195 0.8636 0.7879 Tau:0.6461 0.4352 0.3825\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 118 Step: 1770 Index:0.5823 R2:0.6976 0.5823 0.6012 RMSE:0.7414 0.9152 0.8129 Tau:0.6455 0.4352 0.3887\n",
      "Epoch: 119 Step: 1785 Index:0.6065 R2:0.7058 0.6065 0.5802 RMSE:0.7592 0.8602 0.8275 Tau:0.6554 0.4582 0.3692\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 120 Step: 1800 Index:0.6037 R2:0.7016 0.6037 0.5794 RMSE:0.7329 0.8510 0.8087 Tau:0.6501 0.4698 0.3700\n",
      "Epoch: 121 Step: 1815 Index:0.6094 R2:0.7087 0.6094 0.5899 RMSE:0.7112 0.8423 0.7861 Tau:0.6530 0.4582 0.3751\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 122 Step: 1830 Index:0.5977 R2:0.7058 0.5977 0.6054 RMSE:0.7245 0.8852 0.7968 Tau:0.6480 0.4467 0.3840\n",
      "Epoch: 123 Step: 1845 Index:0.6158 R2:0.7074 0.6158 0.5813 RMSE:0.7237 0.8373 0.8041 Tau:0.6552 0.4813 0.3673\n",
      "Epoch: 124 Step: 1860 Index:0.6189 R2:0.7134 0.6189 0.5874 RMSE:0.7028 0.8368 0.7892 Tau:0.6601 0.4640 0.3712\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 125 Step: 1875 Index:0.6163 R2:0.7146 0.6163 0.5914 RMSE:0.7007 0.8393 0.7858 Tau:0.6600 0.4640 0.3696\n",
      "Epoch: 126 Step: 1890 Index:0.6216 R2:0.7184 0.6216 0.5988 RMSE:0.7003 0.8339 0.7787 Tau:0.6595 0.4640 0.3731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 127 Step: 1905 Index:0.6252 R2:0.7184 0.6252 0.5857 RMSE:0.7379 0.8399 0.8161 Tau:0.6648 0.4813 0.3700\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 128 Step: 1920 Index:0.6114 R2:0.7160 0.6114 0.5933 RMSE:0.7559 0.8678 0.8278 Tau:0.6645 0.4928 0.3610\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 129 Step: 1935 Index:0.6193 R2:0.7150 0.6193 0.5981 RMSE:0.7899 0.9431 0.8752 Tau:0.6534 0.4582 0.3759\n",
      "Epoch: 130 Step: 1950 Index:0.6257 R2:0.7211 0.6257 0.5927 RMSE:0.7225 0.8311 0.8013 Tau:0.6638 0.4755 0.3673\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 131 Step: 1965 Index:0.6218 R2:0.7225 0.6218 0.6004 RMSE:0.6941 0.8359 0.7778 Tau:0.6650 0.4698 0.3720\n",
      "Epoch: 132 Step: 1980 Index:0.6278 R2:0.7239 0.6278 0.5951 RMSE:0.6905 0.8232 0.7808 Tau:0.6637 0.4813 0.3716\n",
      "Epoch: 133 Step: 1995 Index:0.6308 R2:0.7254 0.6308 0.5979 RMSE:0.6893 0.8220 0.7787 Tau:0.6652 0.4698 0.3708\n",
      "Epoch: 134 Step: 2010 Index:0.6383 R2:0.7044 0.6383 0.5430 RMSE:0.8259 0.8737 0.9334 Tau:0.6510 0.5159 0.3567\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 135 Step: 2025 Index:0.6136 R2:0.7209 0.6136 0.5984 RMSE:0.6968 0.8466 0.7798 Tau:0.6646 0.4467 0.3595\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 136 Step: 2040 Index:0.6375 R2:0.7259 0.6375 0.5961 RMSE:0.6956 0.8303 0.7900 Tau:0.6671 0.4813 0.3700\n",
      "Epoch: 137 Step: 2055 Index:0.6444 R2:0.7293 0.6444 0.5916 RMSE:0.7453 0.8316 0.8335 Tau:0.6746 0.4928 0.3634\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 138 Step: 2070 Index:0.6344 R2:0.7301 0.6344 0.6082 RMSE:0.6887 0.8292 0.7752 Tau:0.6691 0.4755 0.3688\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 139 Step: 2085 Index:0.6428 R2:0.7330 0.6428 0.6074 RMSE:0.6990 0.8109 0.7814 Tau:0.6728 0.4871 0.3673\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 140 Step: 2100 Index:0.6420 R2:0.7314 0.6420 0.6020 RMSE:0.7671 0.8574 0.8468 Tau:0.6741 0.4813 0.3618\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 141 Step: 2115 Index:0.6392 R2:0.7336 0.6392 0.6058 RMSE:0.6798 0.8082 0.7708 Tau:0.6735 0.4813 0.3708\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 142 Step: 2130 Index:0.6410 R2:0.7355 0.6410 0.6072 RMSE:0.6797 0.8070 0.7710 Tau:0.6753 0.4871 0.3677\n",
      "Epoch: 143 Step: 2145 Index:0.6456 R2:0.7353 0.6456 0.6056 RMSE:0.6788 0.8096 0.7744 Tau:0.6726 0.4755 0.3727\n",
      "Epoch: 144 Step: 2160 Index:0.6587 R2:0.7295 0.6587 0.5721 RMSE:0.7232 0.8140 0.8452 Tau:0.6721 0.4928 0.3567\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 145 Step: 2175 Index:0.6358 R2:0.7386 0.6358 0.6132 RMSE:0.6807 0.8148 0.7665 Tau:0.6766 0.4928 0.3684\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 146 Step: 2190 Index:0.6451 R2:0.7402 0.6451 0.6102 RMSE:0.6825 0.8062 0.7741 Tau:0.6778 0.4986 0.3642\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 147 Step: 2205 Index:0.6378 R2:0.7334 0.6378 0.6174 RMSE:0.7588 0.8995 0.8519 Tau:0.6708 0.4755 0.3762\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 148 Step: 2220 Index:0.6518 R2:0.7426 0.6518 0.6121 RMSE:0.7099 0.8157 0.7955 Tau:0.6832 0.5159 0.3618\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 149 Step: 2235 Index:0.6520 R2:0.7443 0.6520 0.6179 RMSE:0.6661 0.7972 0.7593 Tau:0.6806 0.5044 0.3684\n",
      "Epoch: 150 Step: 2250 Index:0.6614 R2:0.7466 0.6614 0.6097 RMSE:0.6733 0.7877 0.7720 Tau:0.6857 0.5159 0.3622\n",
      "Epoch: 151 Step: 2265 Index:0.6623 R2:0.7462 0.6623 0.6097 RMSE:0.6719 0.7862 0.7734 Tau:0.6854 0.5332 0.3603\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 152 Step: 2280 Index:0.6443 R2:0.7442 0.6443 0.6291 RMSE:0.6910 0.8405 0.7791 Tau:0.6799 0.4813 0.3704\n",
      "Epoch: 153 Step: 2295 Index:0.6676 R2:0.7478 0.6676 0.6071 RMSE:0.6930 0.7952 0.7950 Tau:0.6872 0.5332 0.3606\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 154 Step: 2310 Index:0.6617 R2:0.7461 0.6617 0.6137 RMSE:0.6672 0.7954 0.7737 Tau:0.6802 0.4986 0.3759\n",
      "Epoch: 155 Step: 2325 Index:0.6711 R2:0.7461 0.6711 0.6036 RMSE:0.6599 0.7728 0.7745 Tau:0.6825 0.5159 0.3696\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 156 Step: 2340 Index:0.6504 R2:0.7480 0.6504 0.6261 RMSE:0.6602 0.7958 0.7524 Tau:0.6838 0.5159 0.3712\n",
      "Epoch: 157 Step: 2355 Index:0.6744 R2:0.7461 0.6744 0.5866 RMSE:0.6812 0.7777 0.8035 Tau:0.6855 0.5044 0.3626\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 158 Step: 2370 Index:0.6743 R2:0.7419 0.6743 0.5759 RMSE:0.7020 0.7879 0.8256 Tau:0.6848 0.5389 0.3645\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 159 Step: 2385 Index:0.6198 R2:0.7387 0.6198 0.6492 RMSE:0.6778 0.8449 0.7498 Tau:0.6719 0.5044 0.3829\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 160 Step: 2400 Index:0.6572 R2:0.7543 0.6572 0.6369 RMSE:0.6597 0.7934 0.7415 Tau:0.6873 0.5216 0.3762\n",
      "Epoch: 161 Step: 2415 Index:0.6757 R2:0.7576 0.6757 0.6195 RMSE:0.6677 0.7743 0.7634 Tau:0.6943 0.5159 0.3677\n",
      "Epoch: 162 Step: 2430 Index:0.6786 R2:0.7571 0.6786 0.6164 RMSE:0.6539 0.7657 0.7602 Tau:0.6907 0.5159 0.3684\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 163 Step: 2445 Index:0.6619 R2:0.7587 0.6619 0.6358 RMSE:0.6570 0.7864 0.7429 Tau:0.6881 0.5216 0.3727\n",
      "Epoch: 164 Step: 2460 Index:0.6794 R2:0.7579 0.6794 0.6158 RMSE:0.6499 0.7675 0.7628 Tau:0.6955 0.5332 0.3716\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 165 Step: 2475 Index:0.6721 R2:0.7236 0.6721 0.5372 RMSE:0.7314 0.7938 0.8732 Tau:0.6692 0.5389 0.3645\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 166 Step: 2490 Index:0.6682 R2:0.7574 0.6682 0.6282 RMSE:0.6508 0.7762 0.7495 Tau:0.6886 0.5044 0.3720\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 167 Step: 2505 Index:0.6684 R2:0.7567 0.6684 0.6369 RMSE:0.6593 0.7841 0.7439 Tau:0.6896 0.4986 0.3778\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 168 Step: 2520 Index:0.6782 R2:0.7606 0.6782 0.6250 RMSE:0.6629 0.7734 0.7610 Tau:0.6917 0.5159 0.3708\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 169 Step: 2535 Index:0.6660 R2:0.7590 0.6660 0.6391 RMSE:0.6535 0.7917 0.7526 Tau:0.6890 0.4986 0.3755\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 170 Step: 2550 Index:0.6458 R2:0.7484 0.6458 0.6257 RMSE:0.7061 0.8370 0.7858 Tau:0.6836 0.5159 0.3704\n",
      "Epoch: 171 Step: 2565 Index:0.6798 R2:0.7593 0.6798 0.6093 RMSE:0.6468 0.7693 0.7745 Tau:0.6923 0.5101 0.3759\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 172 Step: 2580 Index:0.6711 R2:0.7632 0.6711 0.6355 RMSE:0.6702 0.8101 0.7866 Tau:0.6901 0.5216 0.3790\n",
      "Epoch: 173 Step: 2595 Index:0.6852 R2:0.7597 0.6852 0.6157 RMSE:0.7460 0.8466 0.8437 Tau:0.6978 0.5447 0.3669\n",
      "Epoch: 174 Step: 2610 Index:0.6868 R2:0.7657 0.6868 0.6253 RMSE:0.6545 0.7785 0.7801 Tau:0.6991 0.5389 0.3759\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 175 Step: 2625 Index:0.6827 R2:0.7670 0.6827 0.6328 RMSE:0.6828 0.7900 0.7668 Tau:0.7024 0.5389 0.3708\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 176 Step: 2640 Index:0.6769 R2:0.7688 0.6769 0.6503 RMSE:0.6344 0.7686 0.7312 Tau:0.6982 0.5389 0.3751\n",
      "Epoch: 177 Step: 2655 Index:0.7028 R2:0.7654 0.7028 0.6141 RMSE:0.6496 0.7421 0.7668 Tau:0.6994 0.5216 0.3653\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 178 Step: 2670 Index:0.6786 R2:0.7707 0.6786 0.6465 RMSE:0.6316 0.7641 0.7297 Tau:0.6971 0.5274 0.3712\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 179 Step: 2685 Index:0.6893 R2:0.7721 0.6893 0.6373 RMSE:0.6277 0.7512 0.7400 Tau:0.6984 0.5216 0.3704\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 180 Step: 2700 Index:0.6856 R2:0.7726 0.6856 0.6375 RMSE:0.6276 0.7553 0.7404 Tau:0.6982 0.5216 0.3716\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 181 Step: 2715 Index:0.6932 R2:0.7732 0.6932 0.6350 RMSE:0.6253 0.7464 0.7447 Tau:0.6967 0.5216 0.3708\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 182 Step: 2730 Index:0.6848 R2:0.7726 0.6848 0.6432 RMSE:0.6531 0.7856 0.7718 Tau:0.6953 0.4928 0.3716\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 183 Step: 2745 Index:0.6677 R2:0.7700 0.6677 0.6454 RMSE:0.6310 0.7767 0.7309 Tau:0.6963 0.5044 0.3661\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 184 Step: 2760 Index:0.6900 R2:0.7697 0.6900 0.6198 RMSE:0.7257 0.8279 0.8327 Tau:0.7040 0.5620 0.3661\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 185 Step: 2775 Index:0.6872 R2:0.7689 0.6872 0.6165 RMSE:0.6336 0.7529 0.7604 Tau:0.6986 0.5332 0.3762\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 186 Step: 2790 Index:0.6900 R2:0.7763 0.6900 0.6370 RMSE:0.6227 0.7530 0.7452 Tau:0.7002 0.5562 0.3759\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 187 Step: 2805 Index:0.6949 R2:0.7788 0.6949 0.6424 RMSE:0.6413 0.7572 0.7427 Tau:0.7072 0.5678 0.3751\n",
      "Epoch: 188 Step: 2820 Index:0.7035 R2:0.7802 0.7035 0.6348 RMSE:0.6341 0.7423 0.7474 Tau:0.7045 0.5620 0.3716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 189 Step: 2835 Index:0.6967 R2:0.7760 0.6967 0.6265 RMSE:0.6262 0.7467 0.7570 Tau:0.7034 0.5274 0.3727\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 190 Step: 2850 Index:0.6879 R2:0.7815 0.6879 0.6491 RMSE:0.6177 0.7539 0.7290 Tau:0.7015 0.5735 0.3727\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 191 Step: 2865 Index:0.7021 R2:0.7825 0.7021 0.6354 RMSE:0.6157 0.7349 0.7415 Tau:0.7052 0.5735 0.3727\n",
      "Epoch: 192 Step: 2880 Index:0.7038 R2:0.7836 0.7038 0.6380 RMSE:0.6511 0.7589 0.7588 Tau:0.7113 0.5678 0.3712\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 193 Step: 2895 Index:0.6972 R2:0.7841 0.6972 0.6489 RMSE:0.6112 0.7418 0.7320 Tau:0.7063 0.5735 0.3751\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 194 Step: 2910 Index:0.6936 R2:0.7854 0.6936 0.6518 RMSE:0.6163 0.7463 0.7242 Tau:0.7107 0.5620 0.3751\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 195 Step: 2925 Index:0.7028 R2:0.7803 0.7028 0.6231 RMSE:0.6270 0.7382 0.7569 Tau:0.7081 0.5678 0.3708\n",
      "Epoch: 196 Step: 2940 Index:0.7093 R2:0.7823 0.7093 0.6285 RMSE:0.6619 0.7652 0.7853 Tau:0.7075 0.5678 0.3677\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 197 Step: 2955 Index:0.6921 R2:0.7852 0.6921 0.6497 RMSE:0.6128 0.7505 0.7346 Tau:0.7043 0.5389 0.3766\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 198 Step: 2970 Index:0.6775 R2:0.7724 0.6775 0.6367 RMSE:0.6354 0.7653 0.7400 Tau:0.7008 0.5447 0.3837\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 199 Step: 2985 Index:0.6791 R2:0.7837 0.6791 0.6760 RMSE:0.6144 0.7639 0.6987 Tau:0.7040 0.5044 0.3747\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 200 Step: 3000 Index:0.7089 R2:0.7872 0.7089 0.6341 RMSE:0.6128 0.7308 0.7452 Tau:0.7115 0.5620 0.3739\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 201 Step: 3015 Index:0.6963 R2:0.7924 0.6963 0.6641 RMSE:0.6039 0.7435 0.7111 Tau:0.7119 0.5678 0.3751\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 202 Step: 3030 Index:0.7035 R2:0.7950 0.7035 0.6603 RMSE:0.6028 0.7363 0.7153 Tau:0.7146 0.5735 0.3759\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 203 Step: 3045 Index:0.7043 R2:0.7927 0.7043 0.6523 RMSE:0.5984 0.7316 0.7291 Tau:0.7113 0.5562 0.3759\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 204 Step: 3060 Index:0.6998 R2:0.7953 0.6998 0.6589 RMSE:0.5966 0.7378 0.7197 Tau:0.7114 0.5620 0.3751\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 205 Step: 3075 Index:0.7058 R2:0.7906 0.7058 0.6407 RMSE:0.6548 0.7662 0.7590 Tau:0.7171 0.5505 0.3720\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 206 Step: 3090 Index:0.6893 R2:0.7914 0.6893 0.6650 RMSE:0.6100 0.7624 0.7408 Tau:0.7082 0.5620 0.3805\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch: 207 Step: 3105 Index:0.7007 R2:0.7937 0.7007 0.6599 RMSE:0.6225 0.7661 0.7597 Tau:0.7104 0.5505 0.3813\n",
      "Epoch: 208 Step: 3120 Index:0.7272 R2:0.7829 0.7272 0.6076 RMSE:0.7100 0.7877 0.8398 Tau:0.7134 0.5620 0.3661\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 209 Step: 3135 Index:0.6736 R2:0.7901 0.6736 0.6744 RMSE:0.6094 0.7697 0.7002 Tau:0.7052 0.5216 0.3634\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 210 Step: 3150 Index:0.7083 R2:0.7985 0.7083 0.6576 RMSE:0.6023 0.7302 0.7185 Tau:0.7160 0.5620 0.3739\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 211 Step: 3165 Index:0.7102 R2:0.7974 0.7102 0.6589 RMSE:0.5984 0.7321 0.7320 Tau:0.7095 0.5620 0.3751\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 212 Step: 3180 Index:0.7182 R2:0.7964 0.7182 0.6493 RMSE:0.7021 0.8054 0.8016 Tau:0.7204 0.5735 0.3700\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 213 Step: 3195 Index:0.6953 R2:0.7940 0.6953 0.6660 RMSE:0.6428 0.7686 0.7246 Tau:0.7154 0.5620 0.3762\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 214 Step: 3210 Index:0.7000 R2:0.7974 0.7000 0.6626 RMSE:0.6032 0.7521 0.7400 Tau:0.7083 0.5620 0.3782\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 215 Step: 3225 Index:0.7179 R2:0.8032 0.7179 0.6572 RMSE:0.5873 0.7170 0.7218 Tau:0.7165 0.5908 0.3759\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 216 Step: 3240 Index:0.7171 R2:0.8045 0.7171 0.6646 RMSE:0.6061 0.7283 0.7169 Tau:0.7222 0.6139 0.3770\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 217 Step: 3255 Index:0.7177 R2:0.8045 0.7177 0.6675 RMSE:0.6280 0.7420 0.7244 Tau:0.7240 0.6254 0.3727\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 218 Step: 3270 Index:0.7127 R2:0.8042 0.7127 0.6675 RMSE:0.5852 0.7215 0.7078 Tau:0.7186 0.6254 0.3786\n",
      "Epoch: 219 Step: 3285 Index:0.7348 R2:0.8004 0.7348 0.6395 RMSE:0.6026 0.7023 0.7432 Tau:0.7224 0.5966 0.3723\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 220 Step: 3300 Index:0.7053 R2:0.8053 0.7053 0.6762 RMSE:0.5844 0.7302 0.6981 Tau:0.7159 0.5620 0.3755\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 221 Step: 3315 Index:0.7241 R2:0.8034 0.7241 0.6527 RMSE:0.5950 0.7205 0.7416 Tau:0.7212 0.5735 0.3801\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 222 Step: 3330 Index:0.7230 R2:0.8071 0.7230 0.6664 RMSE:0.5928 0.7260 0.7326 Tau:0.7197 0.5851 0.3766\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 223 Step: 3345 Index:0.7017 R2:0.8020 0.7017 0.6722 RMSE:0.6068 0.7436 0.7110 Tau:0.7096 0.5562 0.3567\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 224 Step: 3360 Index:0.7281 R2:0.8074 0.7281 0.6581 RMSE:0.5801 0.7046 0.7235 Tau:0.7173 0.5908 0.3739\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 225 Step: 3375 Index:0.7285 R2:0.8115 0.7285 0.6652 RMSE:0.6034 0.7209 0.7244 Tau:0.7217 0.6254 0.3720\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 226 Step: 3390 Index:0.7175 R2:0.8110 0.7175 0.6758 RMSE:0.6157 0.7442 0.7210 Tau:0.7242 0.6081 0.3751\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 227 Step: 3405 Index:0.7220 R2:0.8110 0.7220 0.6652 RMSE:0.5735 0.7090 0.7128 Tau:0.7245 0.5966 0.3829\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 228 Step: 3420 Index:0.7258 R2:0.8105 0.7258 0.6714 RMSE:0.5698 0.7036 0.7051 Tau:0.7199 0.6023 0.3696\n",
      "Epoch: 229 Step: 3435 Index:0.7385 R2:0.8156 0.7385 0.6667 RMSE:0.5684 0.6897 0.7093 Tau:0.7238 0.6312 0.3669\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 230 Step: 3450 Index:0.7150 R2:0.8069 0.7150 0.6606 RMSE:0.5905 0.7199 0.7148 Tau:0.7223 0.6139 0.3821\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 231 Step: 3465 Index:0.7284 R2:0.8134 0.7284 0.6621 RMSE:0.5701 0.7012 0.7161 Tau:0.7270 0.6254 0.3840\n",
      "Epoch: 232 Step: 3480 Index:0.7409 R2:0.8177 0.7409 0.6623 RMSE:0.5938 0.7019 0.7226 Tau:0.7330 0.6312 0.3794\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 233 Step: 3495 Index:0.7402 R2:0.8170 0.7402 0.6645 RMSE:0.5774 0.6929 0.7140 Tau:0.7279 0.6254 0.3778\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 234 Step: 3510 Index:0.7271 R2:0.8178 0.7271 0.6786 RMSE:0.5639 0.7041 0.7013 Tau:0.7245 0.6139 0.3829\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 235 Step: 3525 Index:0.7263 R2:0.8188 0.7263 0.6801 RMSE:0.5720 0.7085 0.6949 Tau:0.7297 0.6196 0.3809\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 236 Step: 3540 Index:0.7364 R2:0.8178 0.7364 0.6673 RMSE:0.5877 0.7092 0.7164 Tau:0.7306 0.6427 0.3809\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 237 Step: 3555 Index:0.7328 R2:0.8212 0.7328 0.6790 RMSE:0.5601 0.6954 0.6957 Tau:0.7309 0.6196 0.3794\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 238 Step: 3570 Index:0.7339 R2:0.8202 0.7339 0.6775 RMSE:0.5754 0.7143 0.7260 Tau:0.7265 0.6081 0.3817\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 239 Step: 3585 Index:0.7367 R2:0.8242 0.7367 0.6818 RMSE:0.5692 0.6954 0.6939 Tau:0.7343 0.6312 0.3794\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 240 Step: 3600 Index:0.7353 R2:0.8229 0.7353 0.6798 RMSE:0.5577 0.6927 0.6943 Tau:0.7343 0.6196 0.3840\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 241 Step: 3615 Index:0.7090 R2:0.8080 0.7090 0.6794 RMSE:0.6002 0.7539 0.7116 Tau:0.7220 0.5966 0.3762\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 242 Step: 3630 Index:0.7375 R2:0.8189 0.7375 0.6588 RMSE:0.5879 0.7044 0.7220 Tau:0.7346 0.6427 0.3868\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch: 243 Step: 3645 Index:0.7240 R2:0.8245 0.7240 0.6873 RMSE:0.5578 0.7128 0.7009 Tau:0.7337 0.6139 0.3879\n",
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch: 244 Step: 3660 Index:0.7371 R2:0.8265 0.7371 0.6775 RMSE:0.5577 0.6923 0.6967 Tau:0.7377 0.6427 0.3875\n",
      "EarlyStopping counter: 13 out of 30\n",
      "Epoch: 245 Step: 3675 Index:0.7294 R2:0.8262 0.7294 0.6846 RMSE:0.5695 0.7115 0.6933 Tau:0.7382 0.6254 0.3860\n",
      "EarlyStopping counter: 14 out of 30\n",
      "Epoch: 246 Step: 3690 Index:0.7350 R2:0.8264 0.7350 0.6835 RMSE:0.6067 0.7327 0.7163 Tau:0.7366 0.6369 0.3848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 247 Step: 3705 Index:0.7429 R2:0.8279 0.7429 0.6751 RMSE:0.6256 0.7348 0.7425 Tau:0.7400 0.6542 0.3801\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 248 Step: 3720 Index:0.7204 R2:0.8247 0.7204 0.6976 RMSE:0.5963 0.7341 0.6898 Tau:0.7334 0.6081 0.3875\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 249 Step: 3735 Index:0.7224 R2:0.8238 0.7224 0.6870 RMSE:0.5685 0.7243 0.7048 Tau:0.7341 0.6196 0.3930\n",
      "Epoch: 250 Step: 3750 Index:0.7489 R2:0.8285 0.7489 0.6738 RMSE:0.5461 0.6734 0.7012 Tau:0.7304 0.6312 0.3829\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 251 Step: 3765 Index:0.7453 R2:0.8295 0.7453 0.6772 RMSE:0.5451 0.6789 0.6979 Tau:0.7351 0.6196 0.3883\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 252 Step: 3780 Index:0.7428 R2:0.8270 0.7428 0.6774 RMSE:0.6046 0.7140 0.7179 Tau:0.7412 0.6542 0.3914\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 253 Step: 3795 Index:0.7344 R2:0.8305 0.7344 0.6940 RMSE:0.5532 0.7074 0.7040 Tau:0.7347 0.6196 0.3911\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 254 Step: 3810 Index:0.7379 R2:0.8333 0.7379 0.6940 RMSE:0.5621 0.6977 0.6840 Tau:0.7426 0.6254 0.3879\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 255 Step: 3825 Index:0.7291 R2:0.8306 0.7291 0.6843 RMSE:0.5671 0.7297 0.7213 Tau:0.7363 0.6196 0.3930\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 256 Step: 3840 Index:0.7144 R2:0.8289 0.7144 0.6976 RMSE:0.5672 0.7235 0.6784 Tau:0.7344 0.6139 0.3891\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 257 Step: 3855 Index:0.7287 R2:0.8277 0.7287 0.6883 RMSE:0.5866 0.7459 0.7417 Tau:0.7327 0.6139 0.3903\n",
      "Epoch: 258 Step: 3870 Index:0.7512 R2:0.8276 0.7512 0.6493 RMSE:0.6096 0.7101 0.7600 Tau:0.7408 0.6485 0.3918\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 259 Step: 3885 Index:0.7424 R2:0.8369 0.7424 0.6887 RMSE:0.5682 0.6942 0.6933 Tau:0.7460 0.6312 0.3922\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 260 Step: 3900 Index:0.7423 R2:0.8349 0.7423 0.6818 RMSE:0.5386 0.6837 0.6958 Tau:0.7405 0.6369 0.3989\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 261 Step: 3915 Index:0.7342 R2:0.8345 0.7342 0.6969 RMSE:0.5391 0.6986 0.6875 Tau:0.7383 0.6139 0.3950\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 262 Step: 3930 Index:0.7469 R2:0.8373 0.7469 0.6840 RMSE:0.5769 0.7048 0.7108 Tau:0.7435 0.6023 0.3875\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 263 Step: 3945 Index:0.7457 R2:0.8375 0.7457 0.6885 RMSE:0.5385 0.6800 0.6852 Tau:0.7429 0.6081 0.3903\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 264 Step: 3960 Index:0.7403 R2:0.8354 0.7403 0.6832 RMSE:0.5418 0.6871 0.6908 Tau:0.7461 0.6369 0.3950\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 265 Step: 3975 Index:0.7374 R2:0.8341 0.7374 0.6777 RMSE:0.5368 0.6901 0.7014 Tau:0.7435 0.6369 0.3992\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 266 Step: 3990 Index:0.7451 R2:0.8409 0.7451 0.6887 RMSE:0.5424 0.6832 0.6861 Tau:0.7475 0.6254 0.3899\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 267 Step: 4005 Index:0.7364 R2:0.8380 0.7364 0.6877 RMSE:0.5946 0.7291 0.7110 Tau:0.7460 0.6369 0.3957\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 268 Step: 4020 Index:0.7477 R2:0.8401 0.7477 0.6903 RMSE:0.5262 0.6761 0.6874 Tau:0.7476 0.6081 0.3911\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch: 269 Step: 4035 Index:0.7437 R2:0.8412 0.7437 0.6908 RMSE:0.5923 0.7190 0.7091 Tau:0.7492 0.6369 0.3903\n",
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch: 270 Step: 4050 Index:0.7369 R2:0.8410 0.7369 0.6913 RMSE:0.5251 0.6909 0.6874 Tau:0.7436 0.6312 0.3942\n",
      "EarlyStopping counter: 13 out of 30\n",
      "Epoch: 271 Step: 4065 Index:0.7472 R2:0.8414 0.7472 0.6802 RMSE:0.5239 0.6770 0.6983 Tau:0.7412 0.6369 0.3950\n",
      "EarlyStopping counter: 14 out of 30\n",
      "Epoch: 272 Step: 4080 Index:0.7337 R2:0.8410 0.7337 0.6956 RMSE:0.5489 0.7231 0.7107 Tau:0.7456 0.6023 0.3957\n",
      "Epoch: 273 Step: 4095 Index:0.7662 R2:0.8362 0.7662 0.6724 RMSE:0.5448 0.6684 0.7293 Tau:0.7422 0.6485 0.3950\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 274 Step: 4110 Index:0.7475 R2:0.8407 0.7475 0.6825 RMSE:0.5287 0.6753 0.6931 Tau:0.7501 0.6427 0.3992\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 275 Step: 4125 Index:0.7490 R2:0.8451 0.7490 0.6957 RMSE:0.5745 0.6987 0.6971 Tau:0.7539 0.6196 0.3883\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 276 Step: 4140 Index:0.7548 R2:0.8443 0.7548 0.6741 RMSE:0.5243 0.6734 0.7111 Tau:0.7520 0.6542 0.3992\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 277 Step: 4155 Index:0.7489 R2:0.8458 0.7489 0.6896 RMSE:0.5539 0.7198 0.7318 Tau:0.7461 0.6139 0.3926\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 278 Step: 4170 Index:0.7449 R2:0.8446 0.7449 0.6780 RMSE:0.5181 0.6786 0.6992 Tau:0.7472 0.6312 0.3938\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 279 Step: 4185 Index:0.7422 R2:0.8366 0.7422 0.6639 RMSE:0.5395 0.6840 0.7145 Tau:0.7516 0.6427 0.3953\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 280 Step: 4200 Index:0.7573 R2:0.8496 0.7573 0.6885 RMSE:0.5535 0.6823 0.7025 Tau:0.7553 0.6485 0.3840\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 281 Step: 4215 Index:0.7573 R2:0.8495 0.7573 0.6795 RMSE:0.5173 0.6623 0.6950 Tau:0.7543 0.6427 0.3914\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 282 Step: 4230 Index:0.7421 R2:0.8488 0.7421 0.6909 RMSE:0.5144 0.6823 0.6832 Tau:0.7520 0.6312 0.3950\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 283 Step: 4245 Index:0.7428 R2:0.8490 0.7428 0.6903 RMSE:0.5095 0.6814 0.6860 Tau:0.7486 0.6081 0.3903\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch: 284 Step: 4260 Index:0.7461 R2:0.8528 0.7461 0.6942 RMSE:0.5126 0.6830 0.6840 Tau:0.7566 0.6485 0.3950\n",
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch: 285 Step: 4275 Index:0.7500 R2:0.8526 0.7500 0.6938 RMSE:0.5073 0.6754 0.6850 Tau:0.7530 0.6254 0.3957\n",
      "EarlyStopping counter: 13 out of 30\n",
      "Epoch: 286 Step: 4290 Index:0.7394 R2:0.8488 0.7394 0.6981 RMSE:0.5164 0.6976 0.7013 Tau:0.7472 0.6254 0.3989\n",
      "EarlyStopping counter: 14 out of 30\n",
      "Epoch: 287 Step: 4305 Index:0.7518 R2:0.8547 0.7518 0.6900 RMSE:0.5111 0.6786 0.6928 Tau:0.7553 0.6427 0.3953\n",
      "EarlyStopping counter: 15 out of 30\n",
      "Epoch: 288 Step: 4320 Index:0.7283 R2:0.8511 0.7283 0.7024 RMSE:0.5250 0.7062 0.6713 Tau:0.7516 0.6139 0.3985\n",
      "EarlyStopping counter: 16 out of 30\n",
      "Epoch: 289 Step: 4335 Index:0.7540 R2:0.8537 0.7540 0.6864 RMSE:0.5521 0.6942 0.7053 Tau:0.7576 0.6427 0.3946\n",
      "EarlyStopping counter: 17 out of 30\n",
      "Epoch: 290 Step: 4350 Index:0.7543 R2:0.8556 0.7543 0.6991 RMSE:0.5178 0.6708 0.6739 Tau:0.7596 0.6369 0.3899\n",
      "EarlyStopping counter: 18 out of 30\n",
      "Epoch: 291 Step: 4365 Index:0.7502 R2:0.8529 0.7502 0.6860 RMSE:0.5111 0.6718 0.6883 Tau:0.7588 0.6658 0.3996\n",
      "EarlyStopping counter: 19 out of 30\n",
      "Epoch: 292 Step: 4380 Index:0.7600 R2:0.8556 0.7600 0.6921 RMSE:0.5024 0.6591 0.6827 Tau:0.7565 0.6542 0.3950\n",
      "EarlyStopping counter: 20 out of 30\n",
      "Epoch: 293 Step: 4395 Index:0.7561 R2:0.8537 0.7561 0.6966 RMSE:0.5240 0.6905 0.7052 Tau:0.7514 0.6485 0.3903\n",
      "EarlyStopping counter: 21 out of 30\n",
      "Epoch: 294 Step: 4410 Index:0.7468 R2:0.8554 0.7468 0.6875 RMSE:0.5034 0.6762 0.6891 Tau:0.7597 0.6600 0.4004\n",
      "EarlyStopping counter: 22 out of 30\n",
      "Epoch: 295 Step: 4425 Index:0.7587 R2:0.8555 0.7587 0.6800 RMSE:0.5219 0.6888 0.7249 Tau:0.7614 0.6715 0.3977\n",
      "Epoch: 296 Step: 4440 Index:0.7664 R2:0.8586 0.7664 0.6682 RMSE:0.5226 0.6586 0.7137 Tau:0.7624 0.6715 0.3868\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 297 Step: 4455 Index:0.7336 R2:0.8588 0.7336 0.6934 RMSE:0.5022 0.6940 0.6799 Tau:0.7562 0.6369 0.3930\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 298 Step: 4470 Index:0.7641 R2:0.8605 0.7641 0.6668 RMSE:0.5277 0.6672 0.7213 Tau:0.7637 0.6715 0.3879\n",
      "Epoch: 299 Step: 4485 Index:0.7667 R2:0.8630 0.7667 0.6793 RMSE:0.4927 0.6541 0.6981 Tau:0.7619 0.6715 0.3907\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 300 Step: 4500 Index:0.7522 R2:0.8638 0.7522 0.7004 RMSE:0.5165 0.7063 0.7052 Tau:0.7612 0.6542 0.3930\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 301 Step: 4515 Index:0.7576 R2:0.8612 0.7576 0.6842 RMSE:0.4895 0.6640 0.6956 Tau:0.7599 0.6542 0.3946\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 302 Step: 4530 Index:0.7495 R2:0.8606 0.7495 0.6861 RMSE:0.4978 0.6854 0.7049 Tau:0.7517 0.6485 0.3973\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 303 Step: 4545 Index:0.7572 R2:0.8639 0.7572 0.6707 RMSE:0.5043 0.6645 0.7045 Tau:0.7628 0.6773 0.3977\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 304 Step: 4560 Index:0.7423 R2:0.8493 0.7423 0.6568 RMSE:0.7018 0.8047 0.8233 Tau:0.7504 0.6485 0.3992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 305 Step: 4575 Index:0.7437 R2:0.8586 0.7437 0.6934 RMSE:0.5532 0.6962 0.6974 Tau:0.7519 0.6081 0.3778\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 306 Step: 4590 Index:0.7462 R2:0.8585 0.7462 0.6731 RMSE:0.5034 0.6797 0.7028 Tau:0.7564 0.6369 0.3981\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 307 Step: 4605 Index:0.7257 R2:0.8382 0.7257 0.6484 RMSE:0.5418 0.7179 0.7357 Tau:0.7452 0.6254 0.4109\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 308 Step: 4620 Index:0.7505 R2:0.8361 0.7505 0.6607 RMSE:0.6195 0.7605 0.7897 Tau:0.7396 0.5908 0.3805\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 309 Step: 4635 Index:0.6974 R2:0.8429 0.6974 0.7001 RMSE:0.5991 0.7777 0.7084 Tau:0.7493 0.6023 0.3992\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch: 310 Step: 4650 Index:0.7380 R2:0.8558 0.7380 0.6548 RMSE:0.4999 0.6954 0.7345 Tau:0.7587 0.6715 0.4043\n",
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch: 311 Step: 4665 Index:0.7455 R2:0.8610 0.7455 0.6715 RMSE:0.5162 0.6843 0.7113 Tau:0.7669 0.6369 0.3977\n",
      "EarlyStopping counter: 13 out of 30\n",
      "Epoch: 312 Step: 4680 Index:0.7540 R2:0.8654 0.7540 0.6659 RMSE:0.5012 0.6684 0.7122 Tau:0.7666 0.6715 0.3977\n",
      "EarlyStopping counter: 14 out of 30\n",
      "Epoch: 313 Step: 4695 Index:0.7595 R2:0.8678 0.7595 0.6705 RMSE:0.4850 0.6663 0.7069 Tau:0.7657 0.6542 0.3918\n",
      "EarlyStopping counter: 15 out of 30\n",
      "Epoch: 314 Step: 4710 Index:0.7580 R2:0.8679 0.7580 0.6763 RMSE:0.4807 0.6651 0.7015 Tau:0.7654 0.6658 0.3942\n",
      "EarlyStopping counter: 16 out of 30\n",
      "Epoch: 315 Step: 4725 Index:0.7560 R2:0.8691 0.7560 0.6753 RMSE:0.4867 0.6639 0.6998 Tau:0.7700 0.6715 0.3965\n",
      "EarlyStopping counter: 17 out of 30\n",
      "Epoch: 316 Step: 4740 Index:0.7429 R2:0.8687 0.7429 0.6928 RMSE:0.4803 0.6830 0.6827 Tau:0.7649 0.6369 0.3981\n",
      "EarlyStopping counter: 18 out of 30\n",
      "Epoch: 317 Step: 4755 Index:0.7631 R2:0.8645 0.7631 0.6579 RMSE:0.4831 0.6544 0.7230 Tau:0.7642 0.6888 0.3926\n",
      "EarlyStopping counter: 19 out of 30\n",
      "Epoch: 318 Step: 4770 Index:0.7200 R2:0.8575 0.7200 0.6894 RMSE:0.5108 0.7197 0.6941 Tau:0.7644 0.6427 0.4016\n",
      "EarlyStopping counter: 20 out of 30\n",
      "Epoch: 319 Step: 4785 Index:0.6139 R2:0.7995 0.6139 0.6987 RMSE:0.6212 0.8405 0.6864 Tau:0.7261 0.6600 0.4363\n",
      "EarlyStopping counter: 21 out of 30\n",
      "Epoch: 320 Step: 4800 Index:0.7071 R2:0.8483 0.7071 0.6893 RMSE:0.5112 0.7292 0.6851 Tau:0.7543 0.6254 0.4047\n",
      "EarlyStopping counter: 22 out of 30\n",
      "Epoch: 321 Step: 4815 Index:0.7468 R2:0.8554 0.7468 0.6697 RMSE:0.4986 0.6786 0.7072 Tau:0.7614 0.6658 0.4012\n",
      "EarlyStopping counter: 23 out of 30\n",
      "Epoch: 322 Step: 4830 Index:0.7436 R2:0.8641 0.7436 0.6971 RMSE:0.4893 0.6831 0.6787 Tau:0.7601 0.6369 0.3981\n",
      "EarlyStopping counter: 24 out of 30\n",
      "Epoch: 323 Step: 4845 Index:0.7374 R2:0.8657 0.7374 0.7056 RMSE:0.5013 0.7212 0.6957 Tau:0.7582 0.6254 0.4031\n",
      "EarlyStopping counter: 25 out of 30\n",
      "Epoch: 324 Step: 4860 Index:0.7356 R2:0.8495 0.7356 0.6738 RMSE:0.5106 0.6986 0.7219 Tau:0.7536 0.6427 0.3911\n",
      "EarlyStopping counter: 26 out of 30\n",
      "Epoch: 325 Step: 4875 Index:0.7311 R2:0.8619 0.7311 0.6979 RMSE:0.4986 0.7080 0.6820 Tau:0.7657 0.6542 0.4098\n",
      "EarlyStopping counter: 27 out of 30\n",
      "Epoch: 326 Step: 4890 Index:0.7524 R2:0.8649 0.7524 0.7013 RMSE:0.4910 0.6729 0.6707 Tau:0.7623 0.6715 0.3942\n",
      "EarlyStopping counter: 28 out of 30\n",
      "Epoch: 327 Step: 4905 Index:0.7256 R2:0.8566 0.7256 0.7087 RMSE:0.5092 0.7108 0.6703 Tau:0.7577 0.6369 0.3969\n",
      "EarlyStopping counter: 29 out of 30\n",
      "Epoch: 328 Step: 4920 Index:0.7294 R2:0.8512 0.7294 0.6776 RMSE:0.5445 0.7192 0.7273 Tau:0.7536 0.6369 0.3782\n",
      "EarlyStopping counter: 30 out of 30\n",
      "Epoch: 329 Step: 4935 Index:0.7250 R2:0.8600 0.7250 0.6770 RMSE:0.4894 0.7101 0.7083 Tau:0.7580 0.6600 0.4184\n"
     ]
    }
   ],
   "source": [
    "# train_f_list=[]\n",
    "# train_mse_list=[]\n",
    "# train_r2_list=[]\n",
    "# test_f_list=[]\n",
    "# test_mse_list=[]\n",
    "# test_r2_list=[]\n",
    "# val_f_list=[]\n",
    "# val_mse_list=[]\n",
    "# val_r2_list=[]\n",
    "# epoch_list=[]\n",
    "# train_predict_list=[]\n",
    "# test_predict_list=[]\n",
    "# val_predict_list=[]\n",
    "# train_y_list=[]\n",
    "# test_y_list=[]\n",
    "# val_y_list=[]\n",
    "# train_d_list=[]\n",
    "# test_d_list=[]\n",
    "# val_d_list=[]\n",
    "\n",
    "epoch = 0\n",
    "optimizer_list = [optimizer, optimizer_AFSE, optimizer_GRN]\n",
    "max_epoch = 1000\n",
    "while epoch < max_epoch:\n",
    "    train(model, amodel, gmodel, train_df, test_df, optimizer_list, loss_function, epoch)\n",
    "#     print(train_df.shape,test_df.shape)\n",
    "    train_d, train_f, train_r2, train_MSE, train_predict, reconstruction_loss, one_hot_loss, interger_loss,binary_loss = eval(model, amodel, gmodel, train_df,output_feature=True,return_GRN_loss=True)\n",
    "    train_predict = np.array(train_predict)\n",
    "    train_WTI = weighted_top_index(train_df, train_predict, len(train_df))\n",
    "    train_tau, _ = scipy.stats.kendalltau(train_predict,train_df[tasks[0]].values.astype(float).tolist())\n",
    "    val_d, val_f, val_r2, val_MSE, val_predict, val_reconstruction_loss, val_one_hot_loss, val_interger_loss,val_binary_loss = eval(model, amodel, gmodel, val_df,output_feature=True,return_GRN_loss=True)\n",
    "    val_predict = np.array(val_predict)\n",
    "    val_WTI = weighted_top_index(val_df, val_predict, len(val_df))\n",
    "    val_AP = AP(val_df, val_predict, len(val_df))\n",
    "    val_tau, _ = scipy.stats.kendalltau(val_predict,val_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "    test_d, test_f, test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df,output_feature=True)\n",
    "    test_predict = np.array(test_predict)\n",
    "    test_WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "#     test_AP = AP(test_df, test_predict, test_active)\n",
    "    test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    k_list = [int(len(test_df)*0.01),int(len(test_df)*0.03),int(len(test_df)*0.1),10,30,100]\n",
    "    topk_list =[]\n",
    "    false_positive_rate_list = []\n",
    "    for k in k_list:\n",
    "        a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "        topk_list.append(a)\n",
    "        false_positive_rate_list.append(b)\n",
    "    \n",
    "    epoch = epoch + 1\n",
    "    global_step = epoch * int(np.max([len(train_df),len(test_df)])/batch_size)\n",
    "    logger.add_scalar('val/WTI', val_WTI, global_step)\n",
    "    logger.add_scalar('val/AP', val_AP, global_step)\n",
    "    logger.add_scalar('val/r2', val_r2, global_step)\n",
    "    logger.add_scalar('val/RMSE', val_MSE**0.5, global_step)\n",
    "    logger.add_scalar('val/Tau', val_tau, global_step)\n",
    "#     logger.add_scalar('test/TAP', test_AP, global_step)\n",
    "    logger.add_scalar('test/r2', test_r2_a, global_step)\n",
    "    logger.add_scalar('test/RMSE', test_MSE_a**0.5, global_step)\n",
    "    logger.add_scalar('test/Tau', test_tau, global_step)\n",
    "    logger.add_scalar('val/GRN', reconstruction_loss, global_step)\n",
    "    logger.add_scalar('test/EF0.01', topk_list[0], global_step)\n",
    "    logger.add_scalar('test/EF0.03', topk_list[1], global_step)\n",
    "    logger.add_scalar('test/EF0.1', topk_list[2], global_step)\n",
    "    logger.add_scalar('test/EF10', topk_list[3], global_step)\n",
    "    logger.add_scalar('test/EF30', topk_list[4], global_step)\n",
    "    logger.add_scalar('test/EF100', topk_list[5], global_step)\n",
    "    \n",
    "#     train_mse_list.append(train_MSE**0.5)\n",
    "#     train_r2_list.append(train_r2)\n",
    "#     val_mse_list.append(val_MSE**0.5)  \n",
    "#     val_r2_list.append(val_r2)\n",
    "#     train_f_list.append(train_f)\n",
    "#     val_f_list.append(val_f)\n",
    "#     test_f_list.append(test_f)\n",
    "#     epoch_list.append(epoch)\n",
    "#     train_predict_list.append(train_predict.flatten())\n",
    "#     test_predict_list.append(test_predict.flatten())\n",
    "#     val_predict_list.append(val_predict.flatten())\n",
    "#     train_y_list.append(train_df[tasks[0]].values)\n",
    "#     val_y_list.append(val_df[tasks[0]].values)\n",
    "#     test_y_list.append(test_df[tasks[0]].values)\n",
    "#     train_d_list.append(train_d)\n",
    "#     val_d_list.append(val_d)\n",
    "#     test_d_list.append(test_d)\n",
    "\n",
    "    stop_index = val_r2\n",
    "    early_stop = stopper.step(stop_index, model)\n",
    "    early_stop = stopper_afse.step(stop_index, amodel, if_print=False)\n",
    "    early_stop = stopper_generate.step(stop_index, gmodel, if_print=False)\n",
    "#     print('epoch {:d}/{:d}, validation {} {:.4f}, {} {:.4f},best validation {r2} {:.4f}'.format(epoch, total_epoch, 'r2', val_r2, 'mse:',val_MSE, stopper.best_score))\n",
    "    print('Epoch:',epoch, 'Step:', global_step, 'Index:%.4f'%stop_index, 'R2:%.4f'%train_r2,'%.4f'%val_r2,'%.4f'%test_r2_a, 'RMSE:%.4f'%train_MSE**0.5, '%.4f'%val_MSE**0.5, \n",
    "          '%.4f'%test_MSE_a**0.5, 'Tau:%.4f'%train_tau,'%.4f'%val_tau,'%.4f'%test_tau)#, 'Tau:%.4f'%val_tau,'%.4f'%test_tau,'GRN:%.4f'%reconstruction_loss,'%.4f'%val_reconstruction_loss\n",
    "    if early_stop:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopper.load_checkpoint(model)\n",
    "stopper_afse.load_checkpoint(amodel)\n",
    "stopper_generate.load_checkpoint(gmodel)\n",
    "    \n",
    "test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df)\n",
    "test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "test_r2_ina, test_MSE_ina, test_predict_ina = eval(model, amodel, gmodel, test_df[test_active:].reset_index(drop=True))\n",
    "    \n",
    "test_predict = np.array(test_predict)\n",
    "test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "\n",
    "k_list = [int(len(test_df)*0.01),int(len(test_df)*0.05),int(len(test_df)*0.1),int(len(test_df)*0.15),int(len(test_df)*0.2),int(len(test_df)*0.25),\n",
    "          int(len(test_df)*0.3),int(len(test_df)*0.4),int(len(test_df)*0.5),50,100,150,200,250,300]\n",
    "topk_list =[]\n",
    "false_positive_rate_list = []\n",
    "for k in k_list:\n",
    "    a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "    topk_list.append(a)\n",
    "    false_positive_rate_list.append(b)\n",
    "WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "ap = AP(test_df, test_predict, test_active)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 329 r2:0.6793 RMSE:0.6981 WTI:0.3439 AP:0.5135 Tau:0.3907 \n",
      " \n",
      " Top-1:0.0000 Top-1-fp:1.0000 \n",
      " Top-5:0.5000 Top-5-fp:0.5000 \n",
      " Top-10:0.3077 Top-10-fp:0.6154 \n",
      " Top-15:0.5263 Top-15-fp:0.4737 \n",
      " Top-20:0.5200 Top-20-fp:0.5000 \n",
      " Top-25:0.6800 Top-25-fp:0.4848 \n",
      " Top-30:0.7600 Top-30-fp:0.5128 \n",
      " Top-40:0.8400 Top-40-fp:0.6038 \n",
      " Top-50:0.9200 Top-50-fp:0.6515 \n",
      " \n",
      " Top50:0.8400 Top50-fp:0.5800 \n",
      " Top100:0.9600 Top100-fp:0.7600 \n",
      " Top150:1.0000 Top150-fp:0.7200 \n",
      " Top200:1.0000 Top200-fp:0.5400 \n",
      " Top250:1.0000 Top250-fp:0.4320 \n",
      " Top300:1.0000 Top300-fp:0.3600 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(' epoch:',epoch,'r2:%.4f'%test_r2_a,'RMSE:%.4f'%test_MSE_a**0.5,'WTI:%.4f'%WTI,'AP:%.4f'%ap,'Tau:%.4f'%test_tau,'\\n','\\n',\n",
    "      'Top-1:%.4f'%topk_list[0],'Top-1-fp:%.4f'%false_positive_rate_list[0],'\\n',\n",
    "      'Top-5:%.4f'%topk_list[1],'Top-5-fp:%.4f'%false_positive_rate_list[1],'\\n',\n",
    "      'Top-10:%.4f'%topk_list[2],'Top-10-fp:%.4f'%false_positive_rate_list[2],'\\n',\n",
    "      'Top-15:%.4f'%topk_list[3],'Top-15-fp:%.4f'%false_positive_rate_list[3],'\\n',\n",
    "      'Top-20:%.4f'%topk_list[4],'Top-20-fp:%.4f'%false_positive_rate_list[4],'\\n',\n",
    "      'Top-25:%.4f'%topk_list[5],'Top-25-fp:%.4f'%false_positive_rate_list[5],'\\n',\n",
    "      'Top-30:%.4f'%topk_list[6],'Top-30-fp:%.4f'%false_positive_rate_list[6],'\\n',\n",
    "      'Top-40:%.4f'%topk_list[7],'Top-40-fp:%.4f'%false_positive_rate_list[7],'\\n',\n",
    "      'Top-50:%.4f'%topk_list[8],'Top-50-fp:%.4f'%false_positive_rate_list[8],'\\n','\\n',\n",
    "      'Top50:%.4f'%topk_list[9],'Top50-fp:%.4f'%false_positive_rate_list[9],'\\n',\n",
    "      'Top100:%.4f'%topk_list[10],'Top100-fp:%.4f'%false_positive_rate_list[10],'\\n',\n",
    "      'Top150:%.4f'%topk_list[11],'Top150-fp:%.4f'%false_positive_rate_list[11],'\\n',\n",
    "      'Top200:%.4f'%topk_list[12],'Top200-fp:%.4f'%false_positive_rate_list[12],'\\n',\n",
    "      'Top250:%.4f'%topk_list[13],'Top250-fp:%.4f'%false_positive_rate_list[13],'\\n',\n",
    "      'Top300:%.4f'%topk_list[14],'Top300-fp:%.4f'%false_positive_rate_list[14],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('target_file:',train_filename)\n",
    "# print('inactive_file:',test_filename)\n",
    "# np.savez(result_dir, epoch_list, train_f_list, train_d_list, \n",
    "#          train_predict_list, train_y_list, val_f_list, val_d_list, val_predict_list, val_y_list, test_f_list, \n",
    "#          test_d_list, test_predict_list, test_y_list)\n",
    "# sim_space = np.load(result_dir+'.npz')\n",
    "# print(sim_space['arr_10'].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
