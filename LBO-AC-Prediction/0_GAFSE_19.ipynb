{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import math\n",
    "torch.manual_seed(8)\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP.AttentiveLayers_Sim_copy import Fingerprint, GRN, AFSE\n",
    "from AttentiveFP import Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set()\n",
    "from IPython.display import SVG, display\n",
    "import sascorer\n",
    "from AttentiveFP.utils import EarlyStopping\n",
    "from AttentiveFP.utils import Meter\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "import AttentiveFP.Featurizer\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IC50_O43614_1_420\n",
      "model_file/0_GAFSE_IC50_O43614_1_420_run_0\n"
     ]
    }
   ],
   "source": [
    "train_filename = \"./data/benchmark/IC50_O43614_1_420_train.csv\"\n",
    "test_filename = \"./data/benchmark/IC50_O43614_1_420_test.csv\"\n",
    "test_active = 420\n",
    "val_rate = 0.06\n",
    "random_seed = 2023\n",
    "file_list1 = train_filename.split('/')\n",
    "file1 = file_list1[-1]\n",
    "file1 = file1[:-10]\n",
    "number = '_run_0'\n",
    "model_file = \"model_file/0_GAFSE_\"+file1+number\n",
    "log_dir = f'log/{\"0_GAFSE_\"+file1}'+number\n",
    "result_dir = './result/0_GAFSE_'+file1+number\n",
    "print(file1)\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              smiles     value\n",
      "0  CC1=CC(=C(C=C1)N2N=CC=N2)C(=O)N3CCCC3C4=NC(=NO... -1.602060\n",
      "1  COC1=C(C=CC=C1F)C2=NOC(=N2)C3CCCN3C(=O)C4=C(C=... -0.954243\n",
      "2  CC1=CC=CC(=C1)C2=C(N=CO2)C(=O)NC3=CN(N=C3)CCN4... -2.705008\n",
      "3  CC1CC(N(C1=O)CC2=CC3=C(C=C2)OC4=CC=CC=C43)C5=C... -0.778151\n",
      "4  CC1CN(C(CO1)CC2=CC(=CC=C2)N3N=CC=N3)C(=O)C4=C(... -1.982271\n",
      "number of all smiles:  1879\n",
      "number of successfully processed smiles:  1879\n",
      "                                              smiles     value  \\\n",
      "0  CC1=CC(=C(C=C1)N2N=CC=N2)C(=O)N3CCCC3C4=NC(=NO... -1.602060   \n",
      "1  COC1=C(C=CC=C1F)C2=NOC(=N2)C3CCCN3C(=O)C4=C(C=... -0.954243   \n",
      "2  CC1=CC=CC(=C1)C2=C(N=CO2)C(=O)NC3=CN(N=C3)CCN4... -2.705008   \n",
      "3  CC1CC(N(C1=O)CC2=CC3=C(C=C2)OC4=CC=CC=C43)C5=C... -0.778151   \n",
      "4  CC1CN(C(CO1)CC2=CC(=CC=C2)N3N=CC=N3)C(=O)C4=C(... -1.982271   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0  Cc1ccc(-n2nccn2)c(C(=O)N2CCCC2c2nc(-c3c(C)cccc...  \n",
      "1  COc1c(F)cccc1-c1noc(C2CCCN2C(=O)c2cc(Cl)ccc2-n...  \n",
      "2  Cc1cccc(-c2ocnc2C(=O)Nc2cnn(CCn3ccc4cc(Cl)ccc4...  \n",
      "3    COc1cccc(F)c1C1CC(C)C(=O)N1Cc1ccc2oc3ccccc3c2c1  \n",
      "4  CC1CN(C(=O)c2cc(Cl)ccc2-n2nccn2)C(Cc2cccc(-n3n...  \n"
     ]
    }
   ],
   "source": [
    "# task_name = 'Malaria Bioactivity'\n",
    "tasks = ['value']\n",
    "\n",
    "# train_filename = \"../data/active_inactive/median_active/EC50/Q99500.csv\"\n",
    "feature_filename = train_filename.replace('.csv','.pickle')\n",
    "filename = train_filename.replace('.csv','')\n",
    "prefix_filename = train_filename.split('/')[-1].replace('.csv','')\n",
    "train_df = pd.read_csv(train_filename, header=0, names = [\"smiles\",\"value\"],usecols=[0,1])\n",
    "# train_df = train_df[1:]\n",
    "# train_df = train_df.drop(0,axis=1,inplace=False) \n",
    "print(train_df[:5])\n",
    "# print(train_df.iloc(1))\n",
    "def add_canonical_smiles(train_df):\n",
    "    smilesList = train_df.smiles.values\n",
    "    print(\"number of all smiles: \",len(smilesList))\n",
    "    atom_num_dist = []\n",
    "    remained_smiles = []\n",
    "    canonical_smiles_list = []\n",
    "    for smiles in smilesList:\n",
    "        try:        \n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            atom_num_dist.append(len(mol.GetAtoms()))\n",
    "            remained_smiles.append(smiles)\n",
    "            canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "        except:\n",
    "            print(smiles)\n",
    "            pass\n",
    "    print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "    train_df = train_df[train_df[\"smiles\"].isin(remained_smiles)]\n",
    "    train_df['cano_smiles'] =canonical_smiles_list\n",
    "    return train_df\n",
    "# print(train_df)\n",
    "train_df = add_canonical_smiles(train_df)\n",
    "\n",
    "print(train_df.head())\n",
    "# plt.figure(figsize=(5, 3))\n",
    "# sns.set(font_scale=1.5)\n",
    "# ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "# plt.tight_layout()\n",
    "# # plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "# plt.show()\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "\n",
    "p_dropout= 0.03\n",
    "fingerprint_dim = 100\n",
    "\n",
    "weight_decay = 4.3 # also known as l2_regularization_lambda\n",
    "learning_rate = 4\n",
    "radius = 2 # default: 2\n",
    "T = 1\n",
    "per_task_output_units_num = 1 # for regression model\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  821\n",
      "number of successfully processed smiles:  821\n",
      "(821, 3)\n",
      "                                              smiles     value  \\\n",
      "0  C1COCC(N1C(=O)C2=CC=CC=C2N3N=CC=N3)CC4=CC=CC(=... -3.276921   \n",
      "1  CCOC1=C(C=CC=C1F)C2=NOC(=N2)C3CCCN3C(=O)C4=C(C... -0.845098   \n",
      "2  CC1=C(C=CC=C1OC)C2=NC(=NO2)C3CCCN3C(=O)C4=C(C=... -2.000000   \n",
      "3  CC1CN(C(CO1)CC2=CC(=CC=C2)N3N=CC=N3)C(=O)C4=C(... -1.968483   \n",
      "4  C1CC(C(C1)NC(=O)C2=CC=CC=C2N3C=CC=N3)NC4=NC5=C... -3.633468   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0  O=C(c1ccccc1-n1nccn1)N1CCOCC1Cc1cccc(-c2ncccn2)c1  \n",
      "1  CCOc1c(F)cccc1-c1noc(C2CCCN2C(=O)c2cc(C)ccc2-n...  \n",
      "2  COc1cccc(-c2nc(C3CCCN3C(=O)c3ccc(Cl)cc3-n3nccn...  \n",
      "3  CC1CN(C(=O)c2cccc(Cl)c2-n2nccn2)C(Cc2cccc(-n3n...  \n",
      "4     O=C(NC1CCCC1Nc1nc2ccc(F)cc2s1)c1ccccc1-n1cccn1  \n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_filename,header=0,names=[\"smiles\",\"value\"],usecols=[0,1])\n",
    "test_df = add_canonical_smiles(test_df)\n",
    "for l in test_df[\"cano_smiles\"]:\n",
    "    if l in train_df[\"cano_smiles\"]:\n",
    "        print(\"same smiles:\",l)\n",
    "        \n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/benchmark/IC50_O43614_1_420_train.pickle\n",
      "./data/benchmark/IC50_O43614_1_420_train\n",
      "2700\n",
      "feature dicts file saved as ./data/benchmark/IC50_O43614_1_420_train.pickle\n"
     ]
    }
   ],
   "source": [
    "print(feature_filename)\n",
    "print(filename)\n",
    "total_df = pd.concat([train_df,test_df],axis=0)\n",
    "total_smilesList = total_df['smiles'].values\n",
    "print(len(total_smilesList))\n",
    "# if os.path.isfile(feature_filename):\n",
    "#     feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "# else:\n",
    "#     feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "feature_dicts = save_smiles_dicts(total_smilesList,filename)\n",
    "remained_df = total_df[total_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = total_df.drop(remained_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1766, 3) (113, 3) (821, 3)\n"
     ]
    }
   ],
   "source": [
    "val_df = train_df.sample(frac=val_rate,random_state=random_seed)\n",
    "train_df = train_df.drop(val_df.index)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "train_df = train_df[train_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df[val_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df[test_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "print(train_df.shape,val_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([total_df[\"cano_smiles\"].values[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "loss_function = nn.MSELoss()\n",
    "model = Fingerprint(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "amodel = AFSE(fingerprint_dim, output_units_num, p_dropout)\n",
    "gmodel = GRN(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, p_dropout)\n",
    "model.cuda()\n",
    "amodel.cuda()\n",
    "gmodel.cuda()\n",
    "\n",
    "# optimizer = optim.Adam([\n",
    "# {'params': model.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# {'params': gmodel.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# ])\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "optimizer_AFSE = optim.Adam(params=amodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# optimizer_AFSE = optim.SGD(params=amodel.parameters(), lr = 0.01, momentum=0.9)\n",
    "\n",
    "optimizer_GRN = optim.Adam(params=gmodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# tensorboard = SummaryWriter(log_dir=\"runs/\"+start_time+\"_\"+prefix_filename+\"_\"+str(fingerprint_dim)+\"_\"+str(p_dropout))\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "# print(params)\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def sorted_show_pik(dataset, p, k, k_predict, i, acc):\n",
    "    p_value = dataset[tasks[0]].astype(float).tolist()\n",
    "    x = np.arange(0,len(dataset),1)\n",
    "#     print('plt',dataset.head(),p[:10],k_predict,k)\n",
    "#     plt.figure()\n",
    "#     fig, ax1 = plt.subplots()\n",
    "#     ax1.grid(False)\n",
    "#     ax2 = ax1.twinx()\n",
    "#     plt.grid(False)\n",
    "    plt.scatter(x,p,marker='.',s=6,color='r',label='predict')\n",
    "#     plt.ylabel('predict')\n",
    "    plt.scatter(x,p_value,s=6,marker=',',color='blue',label='p_value')\n",
    "    plt.axvline(x=k-1,ls=\"-\",c=\"black\")#添加垂直直线\n",
    "    k_value = np.ones(len(dataset))\n",
    "# #     print(EC50[k-1])\n",
    "    k_value = k_value*k_predict\n",
    "    plt.plot(x,k_value,'-',color='black')\n",
    "    plt.ylabel('p_value')\n",
    "    plt.title(\"epoch: {},  top-k recall: {}\".format(i,acc))\n",
    "    plt.legend(loc=3,fontsize=5)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def topk_acc2(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "    \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    k_true = true_sort[tasks[0]].values[k-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('k_true: ',type(k_true),k_true)\n",
    "#     print('k_true: ',k_true,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=k_true,'acc_num: ',len(df3[df3['predict'].values>=k_true]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k)\n",
    "    acc = len(df3[df3[tasks[0]].values>=k_true])/k #预测值前k个中真实排在前k个的个数/k\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/k\n",
    "    if k>active_num:\n",
    "        min_active = true_sort[tasks[0]].values[active_num-1]\n",
    "        acc = len(df3[df3[tasks[0]].values>=min_active])/k\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "def topk_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "        \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个，因为后面的全是-4.1\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    min_active = true_sort[tasks[0]].values[active_num-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('min_active: ',type(min_active),min_active)\n",
    "#     print('min_active: ',min_active,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=min_active,'acc_num: ',len(df3[df3['predict'].values>=min_active]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k,'active_num: ',active_num)\n",
    "    acc = len(df3[df3[tasks[0]].values>-4.1])/active_num #预测值前k个中真实排在前active_num个的个数/active_num\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/active_num\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "    \n",
    "def topk_acc_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    if k>active_num:\n",
    "        return topk_recall(df, predict, k, active_num, show_flag, i)\n",
    "    return topk_acc2(df,predict,k, active_num,show_flag,i)\n",
    "\n",
    "def weighted_top_index(df, predict, active_num):\n",
    "    weighted_acc_list=[]\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        acc, fp = topk_acc_recall(df, predict, k, active_num)\n",
    "        weight = (len(df)-k)/len(df)\n",
    "#         print('weight=',weight,'acc=',acc)\n",
    "        weighted_acc_list.append(acc*weight)#\n",
    "    weighted_acc_list = np.array(weighted_acc_list)\n",
    "#     print('weighted_acc_list=',weighted_acc_list)\n",
    "    return np.sum(weighted_acc_list)/weighted_acc_list.shape[0]\n",
    "\n",
    "def AP(df, predict, active_num):\n",
    "    prec = []\n",
    "    rec = []\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        prec_k, fp1 = topk_acc2(df,predict,k, active_num)\n",
    "        rec_k, fp2 = topk_recall(df, predict, k, active_num)\n",
    "        prec.append(prec_k)\n",
    "        rec.append(rec_k)\n",
    "    # 取所有不同的recall对应的点处的精度值做平均\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.], rec, [1.]))\n",
    "    mpre = np.concatenate(([0.], prec, [0.]))\n",
    "\n",
    "    # 计算包络线，从后往前取最大保证precise非减\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # 找出所有检测结果中recall不同的点\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "#     print(prec)\n",
    "#     print('prec='+str(prec)+'\\n\\n'+'rec='+str(rec))\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    # 用recall的间隔对精度作加权平均\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_r2(y,predict):\n",
    "#     print(y)\n",
    "#     print(predict)\n",
    "    y = torch.FloatTensor(y).reshape(-1,1)\n",
    "    predict = torch.FloatTensor(predict).reshape(-1,1)\n",
    "    y_mean = torch.mean(y)\n",
    "    predict_mean = torch.mean(predict)\n",
    "    \n",
    "    y1 = torch.pow(torch.mm((y-y_mean).t(),(predict-predict_mean)),2)\n",
    "    y2 = torch.mm((y-y_mean).t(),(y-y_mean))*torch.mm((predict-predict_mean).t(),(predict-predict_mean))\n",
    "#     print(y1,y2)\n",
    "    return y1/y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def l2_norm(input, dim):\n",
    "    norm = torch.norm(input, dim=dim, keepdim=True)\n",
    "    output = torch.div(input, norm+1e-6)\n",
    "    return output\n",
    "\n",
    "def normalize_perturbation(d,dim=-1):\n",
    "    output = l2_norm(d, dim)\n",
    "    return output\n",
    "\n",
    "def tanh(x):\n",
    "    return (torch.exp(x)-torch.exp(-x))/(torch.exp(x)+torch.exp(-x))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "def perturb_feature(f, model, alpha=1, lamda=10**-learning_rate, output_lr=False, output_plr=False, y=None):\n",
    "    mol_prediction = model(feature=f, d=0)\n",
    "    pred = mol_prediction.detach()\n",
    "#     f = torch.div(f, torch.norm(f, dim=-1, keepdim=True)+1e-9)\n",
    "    eps = 1e-6 * normalize_perturbation(torch.randn(f.shape))\n",
    "    eps = Variable(eps, requires_grad=True)\n",
    "    # Predict on randomly perturbed image\n",
    "    eps_p = model(feature=f, d=eps.cuda())\n",
    "    eps_p_ = model(feature=f, d=-eps.cuda())\n",
    "    p_aux = nn.Sigmoid()(eps_p/(pred+1e-6))\n",
    "    p_aux_ = nn.Sigmoid()(eps_p_/(pred+1e-6))\n",
    "#     loss = nn.BCELoss()(abs(p_aux),torch.ones_like(p_aux))+nn.BCELoss()(abs(p_aux_),torch.ones_like(p_aux_))\n",
    "    loss = loss_function(p_aux,torch.ones_like(p_aux))+loss_function(p_aux_,torch.ones_like(p_aux_))\n",
    "    loss.backward(retain_graph=True)\n",
    "\n",
    "    # Based on perturbed image, get direction of greatest error\n",
    "    eps_adv = eps.grad#/10**-learning_rate\n",
    "    optimizer_AFSE.zero_grad()\n",
    "    # Use that direction as adversarial perturbation\n",
    "    eps_adv_normed = normalize_perturbation(eps_adv)\n",
    "    d_adv = lamda * eps_adv_normed.cuda()\n",
    "    if output_lr:\n",
    "        f_p, max_lr = model(feature=f, d=d_adv, output_lr=output_lr)\n",
    "    f_p = model(feature=f, d=d_adv)\n",
    "    f_p_ = model(feature=f, d=-d_adv)\n",
    "    p = nn.Sigmoid()(f_p/(pred+1e-6))\n",
    "    p_ = nn.Sigmoid()(f_p_/(pred+1e-6))\n",
    "    vat_loss = loss_function(p,torch.ones_like(p))+loss_function(p_,torch.ones_like(p_))\n",
    "    if output_lr:\n",
    "        if output_plr:\n",
    "            loss = loss_function(mol_prediction,y)\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer_AFSE.zero_grad()\n",
    "            punish_lr = torch.norm(torch.mean(eps.grad,0))\n",
    "            return eps_adv, d_adv, vat_loss, mol_prediction, max_lr, punish_lr\n",
    "        return eps_adv, d_adv, vat_loss, mol_prediction, max_lr\n",
    "    return eps_adv, d_adv, vat_loss, mol_prediction\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "\n",
    "def d_loss(f, pred, model, y_val):\n",
    "    diff_loss = 0\n",
    "    length = len(pred)\n",
    "    for i in range(length):\n",
    "        for j in range(length):\n",
    "            if j == i:\n",
    "                continue\n",
    "            pred_diff = model(feature_only=True, feature1=f[i], feature2=f[j])\n",
    "            true_diff = y_val[i] - y_val[j]\n",
    "            diff_loss += loss_function(pred_diff, torch.Tensor([true_diff]).view(-1,1))\n",
    "    diff_loss = diff_loss/(length*(length-1))\n",
    "    return diff_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CE(x,y):\n",
    "    c = 0\n",
    "    l = len(y)\n",
    "    for i in range(l):\n",
    "        if y[i]==1:\n",
    "            c += 1\n",
    "    w1 = (l-c)/l\n",
    "    w0 = c/l\n",
    "    loss = -w1*y*torch.log(x+1e-6)-w0*(1-y)*torch.log(1-x+1e-6)\n",
    "    loss = loss.mean(-1)\n",
    "    return loss\n",
    "\n",
    "def weighted_CE_loss(x,y):\n",
    "    weight = 1/(y.detach().float().mean(0)+1e-9)\n",
    "    weighted_CE = nn.CrossEntropyLoss(weight=weight)\n",
    "#     atom_weights = (atom_weights-min(atom_weights))/(max(atom_weights)-min(atom_weights))\n",
    "    return weighted_CE(x, torch.argmax(y,-1))\n",
    "\n",
    "def generate_loss_function(refer_atom_list, x_atom, validity_mask, atom_list):\n",
    "    [a,b,c] = x_atom.shape\n",
    "    reconstruction_loss = 0\n",
    "    counter = 0\n",
    "    validity_mask = torch.from_numpy(validity_mask).cuda()\n",
    "    for i in range(a):\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        reconstruction_loss += weighted_CE_loss(refer_atom_list[i,:l,:16], x_atom[i,:l,:16]) - \\\n",
    "                        ((validity_mask[i,:l]*torch.log(1-atom_list[i,:l,:16]+1e-9)).sum(-1)/(validity_mask[i,:l].sum(-1)+1e-9)).mean(-1).mean(-1)\n",
    "        counter += 1\n",
    "    reconstruction_loss = reconstruction_loss/counter\n",
    "    return reconstruction_loss\n",
    "\n",
    "\n",
    "def train(model, amodel, gmodel, dataset, test_df, optimizer_list, loss_function, epoch):\n",
    "    model.train()\n",
    "    amodel.train()\n",
    "    gmodel.train()\n",
    "    optimizer, optimizer_AFSE, optimizer_GRN = optimizer_list\n",
    "    np.random.seed(epoch)\n",
    "    max_len = np.max([len(dataset),len(test_df)])\n",
    "    valList = np.arange(0,max_len)\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, max_len, batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[batch%len(dataset),:]\n",
    "        batch_test = test_df.loc[batch%len(test_df),:]\n",
    "        global_step = epoch * len(batch_list) + counter\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        smiles_list_test = batch_test.cano_smiles.values\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        x_atom_test, x_bonds_test, x_atom_index_test, x_bond_index_test, x_mask_test, smiles_to_rdkit_list_test = get_smiles_array(smiles_list_test,feature_dicts)\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                  torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),\n",
    "                                                  mol_feature=mol_feature,activated_features=activated_features.detach())\n",
    "        \n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        \n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        eps_adv, d_adv, vat_loss, mol_prediction, conv_lr, punish_lr = perturb_feature(mol_feature, amodel, alpha=1, \n",
    "                                                                                       lamda=10**-learning_rate, output_lr=True, \n",
    "                                                                                       output_plr=True, y=torch.Tensor(y_val).view(-1,1)) # 10**-learning_rate     \n",
    "        regression_loss = loss_function(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "        atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "                                      torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/1e-6,activated_features=activated_features.detach())\n",
    "        success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(smiles_list, x_atom, \n",
    "                            bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "                                                     refer_atom_list, refer_bond_list,topn=1)\n",
    "        reconstruction_loss = generate_loss_function(refer_atom_list, x_atom, validity_mask, atom_list)\n",
    "        x_atom_test = torch.Tensor(x_atom_test)\n",
    "        x_bonds_test = torch.Tensor(x_bonds_test)\n",
    "        x_bond_index_test = torch.cuda.LongTensor(x_bond_index_test)\n",
    "        \n",
    "        bond_neighbor_test = [x_bonds_test[i][x_bond_index_test[i]] for i in range(len(batch_test))]\n",
    "        bond_neighbor_test = torch.stack(bond_neighbor_test, dim=0)\n",
    "        activated_features_test, mol_feature_test = model(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "                                                          torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),\n",
    "                                                          torch.Tensor(x_mask_test),output_activated_features=True)\n",
    "#         mol_feature_test = torch.div(mol_feature_test, torch.norm(mol_feature_test, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features_test = torch.div(activated_features_test, torch.norm(activated_features_test, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_test, d_test, test_vat_loss, mol_prediction_test = perturb_feature(mol_feature_test, amodel, \n",
    "                                                                                    alpha=1, lamda=10**-learning_rate)\n",
    "        atom_list_test, bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),torch.cuda.LongTensor(x_atom_index_test),\n",
    "                                                torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "                                                mol_feature=mol_feature_test+d_test/1e-6,activated_features=activated_features_test.detach())\n",
    "        refer_atom_list_test, refer_bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "                                                            torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "                                                            mol_feature=mol_feature_test,activated_features=activated_features_test.detach())\n",
    "        success_smiles_batch_test, modified_smiles_test, success_batch_test, total_batch_test, reconstruction_test, validity_test, validity_mask_test = modify_atoms(smiles_list_test, x_atom_test, \n",
    "                            bond_neighbor_test, atom_list_test, bond_list_test,smiles_list_test,smiles_to_rdkit_list_test,\n",
    "                                                     refer_atom_list_test, refer_bond_list_test,topn=1)\n",
    "        test_reconstruction_loss = generate_loss_function(atom_list_test, x_atom_test, validity_mask_test, atom_list_test)\n",
    "        \n",
    "        if vat_loss>1 or test_vat_loss>1:\n",
    "            vat_loss = 1*(vat_loss/(vat_loss+1e-6).item())\n",
    "            test_vat_loss = 1*(test_vat_loss/(test_vat_loss+1e-6).item())\n",
    "        \n",
    "        logger.add_scalar('loss/regression', regression_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE', vat_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE_test', test_vat_loss, global_step)\n",
    "        logger.add_scalar('loss/GRN', reconstruction_loss, global_step)\n",
    "        logger.add_scalar('loss/GRN_test', test_reconstruction_loss, global_step)\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_AFSE.zero_grad()\n",
    "        optimizer_GRN.zero_grad()\n",
    "        loss =  regression_loss + 0.6 * (vat_loss + test_vat_loss) + reconstruction_loss + test_reconstruction_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_AFSE.step()\n",
    "        optimizer_GRN.step()\n",
    "\n",
    "        \n",
    "def clear_atom_map(mol):\n",
    "    [a.ClearProp('molAtomMapNumber') for a  in mol.GetAtoms()]\n",
    "    return mol\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "        \n",
    "def modify_atoms(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list,refer_atom_list, refer_bond_list,topn=1,viz=False):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    refer_atom_list = refer_atom_list.cpu().detach().numpy()\n",
    "    refer_bond_list = refer_bond_list.cpu().detach().numpy()\n",
    "    atom_symbol_sorted = np.argsort(x_atom[:,:,:16], axis=-1)\n",
    "    atom_symbol_generated_sorted = np.argsort(atom_list[:,:,:16], axis=-1)\n",
    "    generate_confidence_sorted = np.sort(atom_list[:,:,:16], axis=-1)\n",
    "    modified_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    confidence_threshold = 0.001\n",
    "    validity_mask = np.zeros_like(atom_list[:,:,:16])\n",
    "    symbol_list = ['B','C','N','O','F','Si','P','S','Cl','As','Se','Br','Te','I','At','other']\n",
    "    symbol_to_rdkit = [4,6,7,8,9,14,15,16,17,33,34,35,52,53,85,0]\n",
    "    for i in range(len(atom_list)):\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        first_run_flag = True\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "        mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "        counter = 0\n",
    "        for j in range(l): \n",
    "            if mol.GetAtomWithIdx(int(smiles_to_rdkit_list[cano_smiles][j])).GetAtomicNum() == \\\n",
    "                symbol_to_rdkit[refer_atom_list[i,j,:16].argmax(-1)]:\n",
    "                counter += 1\n",
    "#             print(f'atom#{smiles_to_rdkit_list[cano_smiles][j]}(f):',{symbol_list[k]: np.around(refer_atom_list[i,j,k],3) for k in range(16)},\n",
    "#                   f'\\natom#{smiles_to_rdkit_list[cano_smiles][j]}(f+d):',{symbol_list[k]: np.around(atom_list[i,j,k],3) for k in range(16)},\n",
    "#                  '\\n------------------------------------------------------------------------------------------------------------')\n",
    "#         print('预测为每个原子的平均概率：\\n',np.around(atom_list[i,:l,:16].mean(1),2))\n",
    "#         print('预测为每个原子的最大概率：\\n',np.around(atom_list[i,:l,:16].max(1),2))\n",
    "        if counter == l:\n",
    "            success_reconstruction += 1\n",
    "        while not flag==topn:\n",
    "            if rank == 16:\n",
    "                rank = 0\n",
    "                top_idx += 1\n",
    "            if top_idx == l:\n",
    "#                 print('没有满足条件的分子生成。')\n",
    "                flag += 1\n",
    "                continue\n",
    "#             if np.sum((atom_symbol_sorted[i,:l,-1]!=atom_symbol_generated_sorted[i,:l,-1-rank]).astype(int))==0:\n",
    "#                 print(f'根据预测的第{rank}大概率的原子构成的分子与原分子一致，原子位重置为0，生成下一个元素……')\n",
    "#                 rank += 1\n",
    "#                 top_idx = 0\n",
    "#                 generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "#                                              x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "#             print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            if rank == 0:\n",
    "                generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "                                             x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "            atom_symbol_generated = np.argsort(atom_list[i,generate_index,:16]-\\\n",
    "                                                    refer_atom_list[i,generate_index,:16] -\\\n",
    "                                                    x_atom[i,generate_index,:16])[-1-rank]\n",
    "            if atom_symbol_generated==x_atom[i,generate_index,:16].argmax(-1):\n",
    "#                 print('生成了相同元素，生成下一个元素……')\n",
    "                rank += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            if np.sort(atom_list[i,generate_index,:16]-\\\n",
    "                refer_atom_list[i,generate_index,:16] -\\\n",
    "                x_atom[i,generate_index,:16])[-1-rank]<confidence_threshold:\n",
    "#                 print(f'原子位{generate_rdkit_index}生成{symbol_list[atom_symbol_generated]}元素的置信度小于{confidence_threshold}，寻找下一个原子位……')\n",
    "                top_idx += 1\n",
    "                rank = 0\n",
    "                continue\n",
    "#             if symbol_to_rdkit[atom_symbol_generated]==6:\n",
    "#                 print('生成了不推荐的C元素')\n",
    "#                 rank += 1\n",
    "#                 continue\n",
    "            mol.GetAtomWithIdx(int(generate_rdkit_index)).SetAtomicNum(symbol_to_rdkit[atom_symbol_generated])\n",
    "            print_mol = mol\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                if first_run_flag == True:\n",
    "                    success_validity += 1\n",
    "                total[flag] += 1\n",
    "                if Chem.MolToSmiles(clear_atom_map(print_mol))==y_smiles[i]:\n",
    "                    success[flag] +=1\n",
    "#                     print('Congratulations!', success, total)\n",
    "                    success_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "#                 print(\"修改前的分子：\", smiles[i])\n",
    "#                 display(mol_init)\n",
    "                modified_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 print(f\"将第{generate_rdkit_index}个原子修改为{symbol_list[atom_symbol_generated]}的分子：\", Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 display(mol_with_atom_index(mol))\n",
    "                mol_y = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "#                 print(\"高活性分子：\", y_smiles[i])\n",
    "#                 display(mol_y)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "#                 print(f\"第{generate_rdkit_index}个原子符号修改为{symbol_list[atom_symbol_generated]}不符合规范，生成下一个元素……\")\n",
    "                validity_mask[i,generate_index,atom_symbol_generated] = 1\n",
    "                rank += 1\n",
    "                first_run_flag = False\n",
    "    return success_smiles, modified_smiles, success, total, success_reconstruction, success_validity, validity_mask\n",
    "\n",
    "def modify_bonds(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    modified_smiles = []\n",
    "    for i in range(len(bond_neighbor)):\n",
    "        l = (bond_neighbor[i].sum(-1).sum(-1)!=0).sum(-1)\n",
    "        bond_type_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        bond_type_generated_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        generate_confidence_sorted = np.sort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        while not flag==3:\n",
    "            cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "            if np.sum((bond_type_sorted[i,:,-1]!=bond_type_generated_sorted[:,:,-1-rank]).astype(int))==0:\n",
    "                rank += 1\n",
    "                top_idx = 0\n",
    "            print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            bond_type = bond_type_sorted[i,:,-1]\n",
    "            bond_type_generated = bond_type_generated_sorted[:,:,-1-rank]\n",
    "            generate_confidence = generate_confidence_sorted[:,:,-1-rank]\n",
    "#             print(np.sort(generate_confidence + \\\n",
    "#                                     (atom_symbol!=atom_symbol_generated).astype(int), axis=-1))\n",
    "            generate_index = np.argsort(generate_confidence + \n",
    "                                (bond_type!=bond_type_generated).astype(int), axis=-1)[-1-top_idx]\n",
    "            bond_type_generated_one = bond_type_generated[generate_index]\n",
    "            mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "            if generate_index >= len(smiles_to_rdkit_list[cano_smiles]):\n",
    "                top_idx += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            mol.GetBondWithIdx(int(generate_rdkit_index)).SetBondType(bond_type_generated_one)\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "                print(\"修改前的分子：\")\n",
    "                display(mol_init)\n",
    "                modified_smiles.append(mol)\n",
    "                print(f\"将第{generate_rdkit_index}个键修改为{atom_symbol_generated}的分子：\")\n",
    "                display(mol)\n",
    "                mol = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "                print(\"高活性分子：\")\n",
    "                display(mol)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "                print(f\"第{generate_rdkit_index}个原子符号修改为{atom_symbol_generated}不符合规范\")\n",
    "                top_idx += 1\n",
    "    return modified_smiles\n",
    "        \n",
    "def eval(model, amodel, gmodel, dataset, topn=1, output_feature=False, generate=False, modify_atom=True,return_GRN_loss=False, viz=False):\n",
    "    model.eval()\n",
    "    amodel.eval()\n",
    "    gmodel.eval()\n",
    "    predict_list = []\n",
    "    test_MSE_list = []\n",
    "    r2_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    feature_list = []\n",
    "    d_list = []\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    generated_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    reconstruction_loss, one_hot_loss, interger_loss, binary_loss = [0,0,0,0]\n",
    "    \n",
    "# #     取dataset中排序后的第k个\n",
    "#     sorted_dataset = dataset.sort_values(by=tasks[0],ascending=False)\n",
    "#     k_df = sorted_dataset.iloc[[k-1]]\n",
    "#     k_smiles = k_df['cano_smiles'].values\n",
    "#     k_value = k_df[tasks[0]].values.astype(float)    \n",
    "    \n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch) \n",
    "#     print(batch_list)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "#         print(type(batch))\n",
    "        batch_df = dataset.loc[batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        matched_smiles_list = smiles_list\n",
    "#         print(batch_df)\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "#         print(type(y_val))\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(matched_smiles_list,feature_dicts)\n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        lamda=10**-learning_rate\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_adv, d_adv, vat_loss, mol_prediction = perturb_feature(mol_feature, amodel, alpha=1, lamda=lamda)\n",
    "#         print(mol_feature,d_adv)\n",
    "        atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),\n",
    "                                      torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "                                      torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/(1e-6),activated_features=activated_features)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),mol_feature=mol_feature,activated_features=activated_features)\n",
    "        if generate:\n",
    "            if modify_atom:\n",
    "                success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(matched_smiles_list, x_atom, \n",
    "                            bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "                                                     refer_atom_list, refer_bond_list,topn=topn,viz=viz)\n",
    "            else:\n",
    "                modified_smiles = modify_bonds(matched_smiles_list, x_atom, bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list)\n",
    "            generated_smiles.extend(modified_smiles)\n",
    "            success_smiles.extend(success_smiles_batch)\n",
    "#             for n in range(topn):\n",
    "#                 success[n] += success_batch[n]\n",
    "#                 total[n] += total_batch[n]\n",
    "#                 print('congratulations:',success,total)\n",
    "            success_reconstruction += reconstruction\n",
    "            success_validity += validity\n",
    "            reconstruction_loss, one_hot_loss, interger_loss, binary_loss = generate_loss_function(refer_atom_list, x_atom, refer_bond_list, bond_neighbor, validity_mask, atom_list, bond_list)\n",
    "        d = d_adv.cpu().detach().numpy().tolist()\n",
    "        d_list.extend(d)\n",
    "        mol_feature_output = mol_feature.cpu().detach().numpy().tolist()\n",
    "        feature_list.extend(mol_feature_output)\n",
    "#         MAE = F.l1_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')   \n",
    "#         print(type(mol_prediction))\n",
    "        \n",
    "        MSE = F.mse_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')\n",
    "#         r2 = caculate_r2(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "# #         r2_list.extend(r2.cpu().detach().numpy())\n",
    "#         if r2!=r2:\n",
    "#             r2 = torch.tensor(0)\n",
    "#         r2_list.append(r2.item())\n",
    "#         predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         print(x_mask[:2],atoms_prediction.shape, mol_prediction,MSE)\n",
    "        predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         test_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n",
    "        test_MSE_list.extend(MSE.data.view(-1,1).cpu().numpy())\n",
    "#     print(r2_list)\n",
    "    if generate:\n",
    "        generated_num = len(generated_smiles)\n",
    "        eval_num = len(dataset)\n",
    "        unique = generated_num\n",
    "        novelty = generated_num\n",
    "        for i in range(generated_num):\n",
    "            for j in range(generated_num-i-1):\n",
    "                if generated_smiles[i]==generated_smiles[i+j+1]:\n",
    "                    unique -= 1\n",
    "            for k in range(eval_num):\n",
    "                if generated_smiles[i]==dataset['smiles'].values[k]:\n",
    "                    novelty -= 1\n",
    "        unique_rate = unique/(generated_num+1e-9)\n",
    "        novelty_rate = novelty/(generated_num+1e-9)\n",
    "#         print(f'successfully/total generated molecules =', {f'Top-{i+1}': f'{success[i]}/{total[i]}' for i in range(topn)})\n",
    "        return success_reconstruction/len(dataset), success_validity/len(dataset), unique_rate, novelty_rate, success_smiles, generated_smiles, caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    if return_GRN_loss:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list,reconstruction_loss, one_hot_loss, interger_loss,binary_loss\n",
    "    if output_feature:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    return caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "\n",
    "epoch = 0\n",
    "max_epoch = 1000\n",
    "batch_size = 10\n",
    "patience = 30\n",
    "stopper = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_model.pth')\n",
    "stopper_afse = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_amodel.pth')\n",
    "stopper_generate = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_gmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log/0_GAFSE_IC50_O43614_1_420_run_0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "now = datetime.datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "if os.path.isdir(log_dir):\n",
    "    for files in os.listdir(log_dir):\n",
    "        os.remove(log_dir+\"/\"+files)\n",
    "    os.rmdir(log_dir)\n",
    "logger = SummaryWriter(log_dir)\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3170695/3510960041.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  y = torch.FloatTensor(y).reshape(-1,1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Step: 176 Index:0.0863 R2:0.0140 0.0863 0.0008 RMSE:0.9632 1.0245 0.9282 Tau:-0.0707 -0.1671 -0.2015\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 2 Step: 352 Index:0.0119 R2:0.0303 0.0119 0.0390 RMSE:0.9204 0.9695 0.8903 Tau:0.1373 0.1097 0.0606\n",
      "Epoch: 3 Step: 528 Index:0.1622 R2:0.1390 0.1622 0.1151 RMSE:0.8848 0.9228 0.8652 Tau:0.2526 0.2973 0.2687\n",
      "Epoch: 4 Step: 704 Index:0.2297 R2:0.1856 0.2297 0.1371 RMSE:0.8589 0.8876 0.8537 Tau:0.2871 0.3425 0.3853\n",
      "Epoch: 5 Step: 880 Index:0.2783 R2:0.2068 0.2783 0.1504 RMSE:0.8454 0.8574 0.8413 Tau:0.3017 0.3669 0.4480\n",
      "Epoch: 6 Step: 1056 Index:0.3041 R2:0.2200 0.3041 0.1633 RMSE:0.8426 0.8541 0.8455 Tau:0.3113 0.3777 0.4631\n",
      "Epoch: 7 Step: 1232 Index:0.3418 R2:0.2388 0.3418 0.1820 RMSE:0.8719 0.8807 0.8753 Tau:0.3238 0.3967 0.4856\n",
      "Epoch: 8 Step: 1408 Index:0.3572 R2:0.2517 0.3572 0.1920 RMSE:0.8492 0.8517 0.8559 Tau:0.3330 0.4037 0.5031\n",
      "Epoch: 9 Step: 1584 Index:0.3838 R2:0.2655 0.3838 0.2103 RMSE:0.8166 0.8064 0.8137 Tau:0.3426 0.4163 0.5274\n",
      "Epoch: 10 Step: 1760 Index:0.4045 R2:0.2781 0.4045 0.2283 RMSE:0.8124 0.7956 0.8077 Tau:0.3520 0.4287 0.5366\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 11 Step: 1936 Index:0.4017 R2:0.2877 0.4017 0.2391 RMSE:0.7900 0.7727 0.7924 Tau:0.3580 0.4281 0.5330\n",
      "Epoch: 12 Step: 2112 Index:0.4083 R2:0.3031 0.4083 0.2597 RMSE:0.8100 0.7913 0.8037 Tau:0.3704 0.4160 0.5449\n",
      "Epoch: 13 Step: 2288 Index:0.4130 R2:0.3163 0.4130 0.2799 RMSE:0.7780 0.7709 0.7731 Tau:0.3796 0.4211 0.5491\n",
      "Epoch: 14 Step: 2464 Index:0.4293 R2:0.3205 0.4293 0.2870 RMSE:0.7822 0.7675 0.7789 Tau:0.3844 0.4512 0.5492\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 15 Step: 2640 Index:0.4020 R2:0.3316 0.4020 0.2910 RMSE:0.7646 0.7638 0.7651 Tau:0.3899 0.4227 0.5492\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 16 Step: 2816 Index:0.4179 R2:0.3448 0.4179 0.3127 RMSE:0.7595 0.7581 0.7534 Tau:0.3988 0.4477 0.5576\n",
      "Epoch: 17 Step: 2992 Index:0.4420 R2:0.3465 0.4420 0.3132 RMSE:0.7602 0.7380 0.7546 Tau:0.4009 0.4670 0.5673\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 18 Step: 3168 Index:0.4232 R2:0.3486 0.4232 0.3197 RMSE:0.8959 0.9134 0.8988 Tau:0.4013 0.4670 0.5522\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 19 Step: 3344 Index:0.4271 R2:0.3599 0.4271 0.3308 RMSE:0.7485 0.7457 0.7423 Tau:0.4096 0.4639 0.5661\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 20 Step: 3520 Index:0.4268 R2:0.3599 0.4268 0.3280 RMSE:0.7573 0.7468 0.7515 Tau:0.4102 0.4556 0.5712\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 21 Step: 3696 Index:0.3804 R2:0.3501 0.3804 0.3224 RMSE:0.7542 0.7752 0.7485 Tau:0.4055 0.4271 0.5579\n",
      "Epoch: 22 Step: 3872 Index:0.4425 R2:0.3664 0.4425 0.3445 RMSE:0.7485 0.7433 0.7412 Tau:0.4136 0.4737 0.5761\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 23 Step: 4048 Index:0.4366 R2:0.3741 0.4366 0.3488 RMSE:0.7436 0.7357 0.7354 Tau:0.4206 0.4749 0.5794\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 24 Step: 4224 Index:0.4165 R2:0.3813 0.4165 0.3589 RMSE:0.7405 0.7607 0.7326 Tau:0.4265 0.4559 0.5751\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 25 Step: 4400 Index:0.4236 R2:0.3818 0.4236 0.3479 RMSE:0.7423 0.7461 0.7383 Tau:0.4277 0.4556 0.5813\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 26 Step: 4576 Index:0.4038 R2:0.3809 0.4038 0.3550 RMSE:0.7389 0.7589 0.7294 Tau:0.4319 0.4547 0.5794\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 27 Step: 4752 Index:0.3517 R2:0.3605 0.3517 0.3364 RMSE:0.8717 0.9298 0.8755 Tau:0.4186 0.4182 0.5630\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 28 Step: 4928 Index:0.4207 R2:0.3909 0.4207 0.3679 RMSE:0.7292 0.7468 0.7226 Tau:0.4338 0.4623 0.5808\n",
      "Epoch: 29 Step: 5104 Index:0.4459 R2:0.3902 0.4459 0.3684 RMSE:0.7428 0.7360 0.7311 Tau:0.4306 0.4791 0.5861\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 30 Step: 5280 Index:0.4395 R2:0.4050 0.4395 0.3751 RMSE:0.7242 0.7404 0.7192 Tau:0.4435 0.4702 0.5909\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 31 Step: 5456 Index:0.4399 R2:0.4092 0.4399 0.3855 RMSE:0.7192 0.7361 0.7117 Tau:0.4457 0.4692 0.5961\n",
      "Epoch: 32 Step: 5632 Index:0.4637 R2:0.4121 0.4637 0.3946 RMSE:0.7174 0.7198 0.7061 Tau:0.4448 0.4901 0.5970\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 33 Step: 5808 Index:0.4307 R2:0.4150 0.4307 0.3862 RMSE:0.7156 0.7420 0.7152 Tau:0.4482 0.4677 0.5944\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 34 Step: 5984 Index:0.4580 R2:0.4207 0.4580 0.4016 RMSE:0.7163 0.7246 0.7034 Tau:0.4507 0.4838 0.5974\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 35 Step: 6160 Index:0.4555 R2:0.4238 0.4555 0.3980 RMSE:0.7641 0.7919 0.7684 Tau:0.4508 0.4825 0.5962\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 36 Step: 6336 Index:0.4420 R2:0.4300 0.4420 0.3983 RMSE:0.7075 0.7301 0.7048 Tau:0.4590 0.4686 0.6005\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 37 Step: 6512 Index:0.4456 R2:0.4334 0.4456 0.4007 RMSE:0.7321 0.7465 0.7241 Tau:0.4625 0.4705 0.6031\n",
      "Epoch: 38 Step: 6688 Index:0.4780 R2:0.4452 0.4780 0.4151 RMSE:0.6969 0.7096 0.6941 Tau:0.4671 0.5025 0.6092\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 39 Step: 6864 Index:0.4542 R2:0.4494 0.4542 0.4237 RMSE:0.6992 0.7229 0.6924 Tau:0.4703 0.4892 0.6058\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 40 Step: 7040 Index:0.4739 R2:0.4517 0.4739 0.4219 RMSE:0.7779 0.8115 0.7848 Tau:0.4670 0.4914 0.6039\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 41 Step: 7216 Index:0.4280 R2:0.4519 0.4280 0.4230 RMSE:0.7115 0.7681 0.7164 Tau:0.4798 0.4943 0.6090\n",
      "Epoch: 42 Step: 7392 Index:0.4793 R2:0.4668 0.4793 0.4370 RMSE:0.7343 0.7696 0.7433 Tau:0.4832 0.5167 0.6107\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 43 Step: 7568 Index:0.4684 R2:0.4769 0.4684 0.4400 RMSE:0.6755 0.7126 0.6796 Tau:0.4880 0.4977 0.6146\n",
      "Epoch: 44 Step: 7744 Index:0.4907 R2:0.4872 0.4907 0.4533 RMSE:0.6768 0.7017 0.6733 Tau:0.4960 0.5104 0.6211\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 45 Step: 7920 Index:0.4832 R2:0.4904 0.4832 0.4537 RMSE:0.6811 0.7236 0.6917 Tau:0.4978 0.5247 0.6164\n",
      "Epoch: 46 Step: 8096 Index:0.5061 R2:0.4929 0.5061 0.4490 RMSE:0.6691 0.6929 0.6771 Tau:0.5007 0.5297 0.6251\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 47 Step: 8272 Index:0.5037 R2:0.4996 0.5037 0.4638 RMSE:0.6714 0.7046 0.6826 Tau:0.5044 0.5164 0.6229\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 48 Step: 8448 Index:0.4845 R2:0.5050 0.4845 0.4658 RMSE:0.6575 0.7025 0.6646 Tau:0.5105 0.5183 0.6211\n",
      "Epoch: 49 Step: 8624 Index:0.5133 R2:0.5171 0.5133 0.4748 RMSE:0.6576 0.6926 0.6659 Tau:0.5153 0.5373 0.6261\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 50 Step: 8800 Index:0.4744 R2:0.5015 0.4744 0.4654 RMSE:0.7100 0.7696 0.7300 Tau:0.5009 0.5076 0.6058\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 51 Step: 8976 Index:0.4773 R2:0.5065 0.4773 0.4446 RMSE:0.6605 0.7156 0.6867 Tau:0.5073 0.4860 0.6262\n",
      "Epoch: 52 Step: 9152 Index:0.5256 R2:0.5257 0.5256 0.4801 RMSE:0.6461 0.6751 0.6546 Tau:0.5227 0.5459 0.6323\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 53 Step: 9328 Index:0.5075 R2:0.5283 0.5075 0.4756 RMSE:0.6423 0.6873 0.6595 Tau:0.5207 0.5316 0.6255\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 54 Step: 9504 Index:0.4937 R2:0.5330 0.4937 0.4776 RMSE:0.6420 0.7013 0.6627 Tau:0.5240 0.5095 0.6264\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 55 Step: 9680 Index:0.5153 R2:0.5411 0.5153 0.4927 RMSE:0.6478 0.6872 0.6529 Tau:0.5335 0.5468 0.6366\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 56 Step: 9856 Index:0.5056 R2:0.5394 0.5056 0.4913 RMSE:0.6562 0.6980 0.6588 Tau:0.5317 0.5304 0.6299\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 57 Step: 10032 Index:0.5048 R2:0.5483 0.5048 0.4924 RMSE:0.6313 0.6908 0.6489 Tau:0.5354 0.5269 0.6354\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 58 Step: 10208 Index:0.4982 R2:0.5388 0.4982 0.5008 RMSE:0.6360 0.6959 0.6469 Tau:0.5292 0.5263 0.6251\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 59 Step: 10384 Index:0.5007 R2:0.5440 0.5007 0.5002 RMSE:0.6359 0.6976 0.6499 Tau:0.5339 0.5370 0.6273\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 60 Step: 10560 Index:0.5184 R2:0.5493 0.5184 0.5035 RMSE:0.6302 0.6776 0.6392 Tau:0.5355 0.5326 0.6322\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 61 Step: 10736 Index:0.5072 R2:0.5592 0.5072 0.5115 RMSE:0.6455 0.6981 0.6500 Tau:0.5425 0.5205 0.6291\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 62 Step: 10912 Index:0.4965 R2:0.5641 0.4965 0.5081 RMSE:0.6173 0.6921 0.6368 Tau:0.5475 0.5129 0.6357\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch: 63 Step: 11088 Index:0.4917 R2:0.5578 0.4917 0.5032 RMSE:0.6236 0.6955 0.6411 Tau:0.5410 0.5145 0.6216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch: 64 Step: 11264 Index:0.4869 R2:0.5705 0.4869 0.5113 RMSE:0.6407 0.7303 0.6639 Tau:0.5529 0.5335 0.6329\n",
      "EarlyStopping counter: 13 out of 30\n",
      "Epoch: 65 Step: 11440 Index:0.5062 R2:0.5770 0.5062 0.5162 RMSE:0.6131 0.6928 0.6387 Tau:0.5545 0.5275 0.6372\n",
      "EarlyStopping counter: 14 out of 30\n",
      "Epoch: 66 Step: 11616 Index:0.5166 R2:0.5812 0.5166 0.5159 RMSE:0.6075 0.6824 0.6368 Tau:0.5599 0.5516 0.6420\n",
      "EarlyStopping counter: 15 out of 30\n",
      "Epoch: 67 Step: 11792 Index:0.4817 R2:0.5584 0.4817 0.5206 RMSE:0.6290 0.7125 0.6397 Tau:0.5432 0.5091 0.6177\n",
      "EarlyStopping counter: 16 out of 30\n",
      "Epoch: 68 Step: 11968 Index:0.5229 R2:0.5799 0.5229 0.5232 RMSE:0.6119 0.6804 0.6316 Tau:0.5583 0.5462 0.6353\n",
      "EarlyStopping counter: 17 out of 30\n",
      "Epoch: 69 Step: 12144 Index:0.5141 R2:0.5793 0.5141 0.5094 RMSE:0.6075 0.6849 0.6410 Tau:0.5557 0.5456 0.6435\n",
      "EarlyStopping counter: 18 out of 30\n",
      "Epoch: 70 Step: 12320 Index:0.4998 R2:0.5876 0.4998 0.5301 RMSE:0.6257 0.7203 0.6543 Tau:0.5630 0.5386 0.6339\n",
      "EarlyStopping counter: 19 out of 30\n",
      "Epoch: 71 Step: 12496 Index:0.5006 R2:0.5657 0.5006 0.4929 RMSE:0.6432 0.7208 0.6809 Tau:0.5474 0.5392 0.6426\n",
      "Epoch: 72 Step: 12672 Index:0.5423 R2:0.5831 0.5423 0.5241 RMSE:0.6173 0.6676 0.6320 Tau:0.5609 0.5554 0.6442\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 73 Step: 12848 Index:0.5155 R2:0.5958 0.5155 0.5240 RMSE:0.6010 0.6841 0.6283 Tau:0.5678 0.5468 0.6413\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 74 Step: 13024 Index:0.4843 R2:0.5818 0.4843 0.5241 RMSE:0.6096 0.7106 0.6373 Tau:0.5589 0.5114 0.6253\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 75 Step: 13200 Index:0.5219 R2:0.5998 0.5219 0.5312 RMSE:0.6060 0.6937 0.6415 Tau:0.5705 0.5570 0.6402\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 76 Step: 13376 Index:0.5198 R2:0.6039 0.5198 0.5270 RMSE:0.6757 0.7601 0.7187 Tau:0.5739 0.5557 0.6494\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 77 Step: 13552 Index:0.5117 R2:0.6007 0.5117 0.5264 RMSE:0.5932 0.6863 0.6321 Tau:0.5699 0.5405 0.6439\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 78 Step: 13728 Index:0.5026 R2:0.6036 0.5026 0.5361 RMSE:0.6156 0.7180 0.6524 Tau:0.5714 0.5196 0.6379\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 79 Step: 13904 Index:0.5213 R2:0.6062 0.5213 0.5349 RMSE:0.5884 0.6799 0.6243 Tau:0.5720 0.5351 0.6406\n",
      "Epoch: 80 Step: 14080 Index:0.5507 R2:0.5985 0.5507 0.5398 RMSE:0.6046 0.6665 0.6272 Tau:0.5730 0.5611 0.6397\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 81 Step: 14256 Index:0.5197 R2:0.6062 0.5197 0.5407 RMSE:0.5953 0.6839 0.6210 Tau:0.5753 0.5301 0.6324\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 82 Step: 14432 Index:0.5200 R2:0.6123 0.5200 0.5392 RMSE:0.5840 0.6783 0.6193 Tau:0.5839 0.5589 0.6475\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 83 Step: 14608 Index:0.5013 R2:0.6176 0.5013 0.5498 RMSE:0.5875 0.6942 0.6137 Tau:0.5836 0.5329 0.6492\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 84 Step: 14784 Index:0.5064 R2:0.6051 0.5064 0.5474 RMSE:0.6211 0.7248 0.6549 Tau:0.5720 0.5282 0.6300\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 85 Step: 14960 Index:0.5283 R2:0.6084 0.5283 0.5182 RMSE:0.6220 0.7107 0.6724 Tau:0.5764 0.5573 0.6411\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 86 Step: 15136 Index:0.5102 R2:0.6262 0.5102 0.5491 RMSE:0.6109 0.7217 0.6571 Tau:0.5897 0.5361 0.6447\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 87 Step: 15312 Index:0.5249 R2:0.6259 0.5249 0.5381 RMSE:0.6116 0.7135 0.6661 Tau:0.5902 0.5630 0.6525\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 88 Step: 15488 Index:0.5367 R2:0.6259 0.5367 0.5380 RMSE:0.5839 0.6781 0.6367 Tau:0.5920 0.5687 0.6567\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 89 Step: 15664 Index:0.5139 R2:0.6206 0.5139 0.5355 RMSE:0.5906 0.6968 0.6381 Tau:0.5873 0.5392 0.6356\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 90 Step: 15840 Index:0.5280 R2:0.6328 0.5280 0.5445 RMSE:0.5724 0.6717 0.6153 Tau:0.5919 0.5389 0.6432\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch: 91 Step: 16016 Index:0.5453 R2:0.6247 0.5453 0.5423 RMSE:0.5744 0.6599 0.6186 Tau:0.5920 0.5776 0.6586\n",
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch: 92 Step: 16192 Index:0.4949 R2:0.5991 0.4949 0.5393 RMSE:0.6324 0.7387 0.6706 Tau:0.5700 0.5114 0.6184\n",
      "EarlyStopping counter: 13 out of 30\n",
      "Epoch: 93 Step: 16368 Index:0.5260 R2:0.6286 0.5260 0.5480 RMSE:0.6450 0.7415 0.6928 Tau:0.5969 0.5677 0.6515\n",
      "EarlyStopping counter: 14 out of 30\n",
      "Epoch: 94 Step: 16544 Index:0.5404 R2:0.6414 0.5404 0.5511 RMSE:0.5678 0.6699 0.6190 Tau:0.6015 0.5630 0.6550\n",
      "EarlyStopping counter: 15 out of 30\n",
      "Epoch: 95 Step: 16720 Index:0.5391 R2:0.6436 0.5391 0.5580 RMSE:0.5758 0.6810 0.6267 Tau:0.6011 0.5620 0.6499\n",
      "Epoch: 96 Step: 16896 Index:0.5540 R2:0.6401 0.5540 0.5510 RMSE:0.5808 0.6656 0.6177 Tau:0.5998 0.5687 0.6593\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 97 Step: 17072 Index:0.5509 R2:0.6377 0.5509 0.5359 RMSE:0.5628 0.6543 0.6212 Tau:0.5969 0.5658 0.6562\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 98 Step: 17248 Index:0.5330 R2:0.6413 0.5330 0.5540 RMSE:0.5651 0.6711 0.6103 Tau:0.6019 0.5700 0.6496\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 99 Step: 17424 Index:0.5373 R2:0.6363 0.5373 0.5326 RMSE:0.6281 0.7239 0.6878 Tau:0.5963 0.5573 0.6503\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 100 Step: 17600 Index:0.5383 R2:0.6387 0.5383 0.5410 RMSE:0.5691 0.6668 0.6199 Tau:0.5966 0.5630 0.6514\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 101 Step: 17776 Index:0.5251 R2:0.6445 0.5251 0.5527 RMSE:0.5752 0.6821 0.6101 Tau:0.6018 0.5364 0.6391\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 102 Step: 17952 Index:0.5522 R2:0.6541 0.5522 0.5539 RMSE:0.5554 0.6560 0.6059 Tau:0.6089 0.5589 0.6487\n",
      "Epoch: 103 Step: 18128 Index:0.5614 R2:0.6507 0.5614 0.5504 RMSE:0.5758 0.6668 0.6373 Tau:0.6052 0.5684 0.6486\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 104 Step: 18304 Index:0.5468 R2:0.6433 0.5468 0.5428 RMSE:0.5615 0.6622 0.6300 Tau:0.5969 0.5560 0.6549\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 105 Step: 18480 Index:0.5450 R2:0.6588 0.5450 0.5574 RMSE:0.5582 0.6627 0.6073 Tau:0.6131 0.5665 0.6572\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 106 Step: 18656 Index:0.5533 R2:0.6598 0.5533 0.5554 RMSE:0.5475 0.6532 0.6059 Tau:0.6120 0.5570 0.6582\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 107 Step: 18832 Index:0.5441 R2:0.6532 0.5441 0.5418 RMSE:0.5951 0.7003 0.6702 Tau:0.6083 0.5671 0.6577\n",
      "Epoch: 108 Step: 19008 Index:0.5662 R2:0.6579 0.5662 0.5627 RMSE:0.5830 0.6755 0.6462 Tau:0.6094 0.5655 0.6544\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 109 Step: 19184 Index:0.5395 R2:0.6468 0.5395 0.5483 RMSE:0.5559 0.6651 0.6202 Tau:0.5976 0.5443 0.6443\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 110 Step: 19360 Index:0.5659 R2:0.6670 0.5659 0.5509 RMSE:0.5423 0.6449 0.6115 Tau:0.6179 0.5760 0.6599\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 111 Step: 19536 Index:0.5584 R2:0.6519 0.5584 0.5337 RMSE:0.5719 0.6687 0.6480 Tau:0.6050 0.5595 0.6598\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 112 Step: 19712 Index:0.5569 R2:0.6576 0.5569 0.5617 RMSE:0.6229 0.7223 0.6846 Tau:0.6108 0.5725 0.6491\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 113 Step: 19888 Index:0.5500 R2:0.6680 0.5500 0.5537 RMSE:0.5655 0.6773 0.6298 Tau:0.6218 0.5722 0.6566\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 114 Step: 20064 Index:0.4821 R2:0.6143 0.4821 0.4940 RMSE:0.6413 0.7594 0.7137 Tau:0.5794 0.5209 0.6452\n",
      "Epoch: 115 Step: 20240 Index:0.5808 R2:0.6636 0.5808 0.5467 RMSE:0.5460 0.6347 0.6162 Tau:0.6149 0.5890 0.6497\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 116 Step: 20416 Index:0.5657 R2:0.6687 0.5657 0.5507 RMSE:0.5444 0.6470 0.6094 Tau:0.6180 0.5690 0.6447\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 117 Step: 20592 Index:0.5537 R2:0.6693 0.5537 0.5575 RMSE:0.5576 0.6739 0.6306 Tau:0.6188 0.5551 0.6594\n",
      "Epoch: 118 Step: 20768 Index:0.5837 R2:0.6751 0.5837 0.5501 RMSE:0.5341 0.6304 0.6131 Tau:0.6250 0.5820 0.6611\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 119 Step: 20944 Index:0.5462 R2:0.6725 0.5462 0.5536 RMSE:0.5435 0.6643 0.6148 Tau:0.6237 0.5624 0.6560\n",
      "Epoch: 120 Step: 21120 Index:0.5983 R2:0.6782 0.5983 0.5627 RMSE:0.5310 0.6189 0.6033 Tau:0.6255 0.5966 0.6688\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 121 Step: 21296 Index:0.5814 R2:0.6842 0.5814 0.5584 RMSE:0.5340 0.6394 0.6149 Tau:0.6314 0.5921 0.6646\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 122 Step: 21472 Index:0.5586 R2:0.6762 0.5586 0.5554 RMSE:0.5407 0.6573 0.6191 Tau:0.6226 0.5548 0.6616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 123 Step: 21648 Index:0.5640 R2:0.6820 0.5640 0.5642 RMSE:0.5327 0.6456 0.6012 Tau:0.6273 0.5744 0.6594\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 124 Step: 21824 Index:0.5442 R2:0.6629 0.5442 0.5105 RMSE:0.5739 0.6844 0.6677 Tau:0.6158 0.5747 0.6511\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 125 Step: 22000 Index:0.5579 R2:0.6826 0.5579 0.5462 RMSE:0.5301 0.6503 0.6200 Tau:0.6279 0.5649 0.6467\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 126 Step: 22176 Index:0.5523 R2:0.6725 0.5523 0.5571 RMSE:0.6088 0.7184 0.6916 Tau:0.6217 0.5513 0.6588\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 127 Step: 22352 Index:0.5843 R2:0.6841 0.5843 0.5546 RMSE:0.5283 0.6320 0.6196 Tau:0.6309 0.5909 0.6627\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 128 Step: 22528 Index:0.5624 R2:0.6767 0.5624 0.5523 RMSE:0.5419 0.6549 0.6353 Tau:0.6209 0.5541 0.6442\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 129 Step: 22704 Index:0.5489 R2:0.6883 0.5489 0.5438 RMSE:0.5281 0.6599 0.6205 Tau:0.6362 0.5769 0.6479\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 130 Step: 22880 Index:0.5602 R2:0.6940 0.5602 0.5624 RMSE:0.5253 0.6542 0.6121 Tau:0.6361 0.5608 0.6570\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch: 131 Step: 23056 Index:0.5662 R2:0.6867 0.5662 0.5546 RMSE:0.5270 0.6433 0.6073 Tau:0.6323 0.5760 0.6595\n",
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch: 132 Step: 23232 Index:0.5780 R2:0.6854 0.5780 0.5565 RMSE:0.5356 0.6454 0.6095 Tau:0.6348 0.5833 0.6603\n",
      "EarlyStopping counter: 13 out of 30\n",
      "Epoch: 133 Step: 23408 Index:0.5830 R2:0.6936 0.5830 0.5658 RMSE:0.5171 0.6300 0.6053 Tau:0.6394 0.5845 0.6635\n",
      "EarlyStopping counter: 14 out of 30\n",
      "Epoch: 134 Step: 23584 Index:0.5553 R2:0.7008 0.5553 0.5590 RMSE:0.5161 0.6542 0.6119 Tau:0.6419 0.5601 0.6528\n",
      "EarlyStopping counter: 15 out of 30\n",
      "Epoch: 135 Step: 23760 Index:0.5933 R2:0.6959 0.5933 0.5526 RMSE:0.5221 0.6280 0.6097 Tau:0.6394 0.5975 0.6681\n",
      "EarlyStopping counter: 16 out of 30\n",
      "Epoch: 136 Step: 23936 Index:0.5955 R2:0.6672 0.5955 0.5608 RMSE:0.5454 0.6280 0.6196 Tau:0.6207 0.5899 0.6715\n",
      "EarlyStopping counter: 17 out of 30\n",
      "Epoch: 137 Step: 24112 Index:0.5756 R2:0.6878 0.5756 0.5522 RMSE:0.5312 0.6455 0.6269 Tau:0.6311 0.5649 0.6603\n",
      "EarlyStopping counter: 18 out of 30\n",
      "Epoch: 138 Step: 24288 Index:0.5863 R2:0.6929 0.5863 0.5566 RMSE:0.6019 0.7045 0.7023 Tau:0.6348 0.5766 0.6582\n",
      "EarlyStopping counter: 19 out of 30\n",
      "Epoch: 139 Step: 24464 Index:0.5713 R2:0.6973 0.5713 0.5407 RMSE:0.5491 0.6685 0.6447 Tau:0.6405 0.5696 0.6538\n",
      "Epoch: 140 Step: 24640 Index:0.6074 R2:0.6926 0.6074 0.5514 RMSE:0.5417 0.6310 0.6475 Tau:0.6387 0.5972 0.6635\n",
      "Epoch: 141 Step: 24816 Index:0.6218 R2:0.6932 0.6218 0.5553 RMSE:0.5567 0.6340 0.6319 Tau:0.6371 0.6238 0.6726\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 142 Step: 24992 Index:0.6138 R2:0.7044 0.6138 0.5520 RMSE:0.5284 0.6260 0.6292 Tau:0.6461 0.6058 0.6652\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 143 Step: 25168 Index:0.6065 R2:0.6974 0.6065 0.5450 RMSE:0.5767 0.6668 0.6723 Tau:0.6416 0.5985 0.6696\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 144 Step: 25344 Index:0.6028 R2:0.7027 0.6028 0.5499 RMSE:0.5109 0.6187 0.6147 Tau:0.6445 0.6013 0.6597\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 145 Step: 25520 Index:0.5661 R2:0.6880 0.5661 0.5237 RMSE:0.5220 0.6444 0.6391 Tau:0.6314 0.5611 0.6566\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 146 Step: 25696 Index:0.5874 R2:0.7045 0.5874 0.5533 RMSE:0.5601 0.6719 0.6756 Tau:0.6427 0.5760 0.6576\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 147 Step: 25872 Index:0.5822 R2:0.6763 0.5822 0.5278 RMSE:0.5739 0.6728 0.6876 Tau:0.6199 0.5649 0.6597\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 148 Step: 26048 Index:0.5834 R2:0.7104 0.5834 0.5512 RMSE:0.5054 0.6316 0.6141 Tau:0.6513 0.5734 0.6685\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 149 Step: 26224 Index:0.5827 R2:0.7158 0.5827 0.5603 RMSE:0.5553 0.6773 0.6673 Tau:0.6503 0.5833 0.6578\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 150 Step: 26400 Index:0.5830 R2:0.7128 0.5830 0.5400 RMSE:0.5057 0.6332 0.6233 Tau:0.6493 0.5779 0.6633\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 151 Step: 26576 Index:0.5762 R2:0.7097 0.5762 0.5489 RMSE:0.5120 0.6453 0.6265 Tau:0.6502 0.5864 0.6638\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch: 152 Step: 26752 Index:0.5525 R2:0.6790 0.5525 0.5082 RMSE:0.5626 0.6818 0.6679 Tau:0.6288 0.5582 0.6585\n",
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch: 153 Step: 26928 Index:0.5994 R2:0.7075 0.5994 0.5407 RMSE:0.5061 0.6177 0.6216 Tau:0.6458 0.5940 0.6627\n",
      "EarlyStopping counter: 13 out of 30\n",
      "Epoch: 154 Step: 27104 Index:0.6082 R2:0.7093 0.6082 0.5688 RMSE:0.5047 0.6111 0.6137 Tau:0.6450 0.5883 0.6666\n",
      "Epoch: 155 Step: 27280 Index:0.6237 R2:0.7178 0.6237 0.5437 RMSE:0.4988 0.6007 0.6177 Tau:0.6538 0.6146 0.6719\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 156 Step: 27456 Index:0.5956 R2:0.7070 0.5956 0.5610 RMSE:0.5140 0.6286 0.6283 Tau:0.6466 0.5744 0.6584\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 157 Step: 27632 Index:0.5888 R2:0.7093 0.5888 0.5511 RMSE:0.5331 0.6419 0.6321 Tau:0.6466 0.5807 0.6544\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 158 Step: 27808 Index:0.5825 R2:0.7161 0.5825 0.5544 RMSE:0.5418 0.6723 0.6513 Tau:0.6532 0.5757 0.6645\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 159 Step: 27984 Index:0.5950 R2:0.7160 0.5950 0.5462 RMSE:0.5260 0.6324 0.6191 Tau:0.6529 0.5845 0.6541\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 160 Step: 28160 Index:0.6216 R2:0.7284 0.6216 0.5549 RMSE:0.4957 0.6078 0.6104 Tau:0.6618 0.5937 0.6614\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 161 Step: 28336 Index:0.5863 R2:0.7149 0.5863 0.5481 RMSE:0.5048 0.6327 0.6172 Tau:0.6528 0.5627 0.6630\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 162 Step: 28512 Index:0.5988 R2:0.7195 0.5988 0.5318 RMSE:0.5169 0.6364 0.6416 Tau:0.6587 0.5893 0.6673\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 163 Step: 28688 Index:0.6158 R2:0.7151 0.6158 0.5495 RMSE:0.5151 0.6217 0.6351 Tau:0.6504 0.5921 0.6670\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 164 Step: 28864 Index:0.6105 R2:0.7160 0.6105 0.5492 RMSE:0.5044 0.6127 0.6165 Tau:0.6553 0.5867 0.6749\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 165 Step: 29040 Index:0.6180 R2:0.7371 0.6180 0.5738 RMSE:0.4808 0.6036 0.5985 Tau:0.6670 0.6000 0.6700\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch: 166 Step: 29216 Index:0.6216 R2:0.7338 0.6216 0.5603 RMSE:0.5008 0.6130 0.6147 Tau:0.6661 0.5991 0.6643\n",
      "Epoch: 167 Step: 29392 Index:0.6502 R2:0.7335 0.6502 0.5549 RMSE:0.5009 0.5948 0.6140 Tau:0.6668 0.6210 0.6688\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 168 Step: 29568 Index:0.6348 R2:0.7256 0.6348 0.5584 RMSE:0.4981 0.5977 0.6166 Tau:0.6605 0.6108 0.6641\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 169 Step: 29744 Index:0.6018 R2:0.7341 0.6018 0.5519 RMSE:0.5649 0.6886 0.7006 Tau:0.6669 0.5937 0.6633\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 170 Step: 29920 Index:0.6305 R2:0.7333 0.6305 0.5600 RMSE:0.4996 0.6074 0.6085 Tau:0.6662 0.6124 0.6676\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 171 Step: 30096 Index:0.6374 R2:0.7364 0.6374 0.5467 RMSE:0.5013 0.6079 0.6417 Tau:0.6698 0.6187 0.6723\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 172 Step: 30272 Index:0.6145 R2:0.7318 0.6145 0.5344 RMSE:0.4968 0.6164 0.6317 Tau:0.6653 0.6016 0.6639\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 173 Step: 30448 Index:0.6453 R2:0.7367 0.6453 0.5615 RMSE:0.4857 0.5849 0.6109 Tau:0.6663 0.6254 0.6692\n",
      "Epoch: 174 Step: 30624 Index:0.6604 R2:0.7250 0.6604 0.5703 RMSE:0.5001 0.5769 0.6045 Tau:0.6581 0.6282 0.6712\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 175 Step: 30800 Index:0.6120 R2:0.7144 0.6120 0.5507 RMSE:0.5193 0.6249 0.6408 Tau:0.6490 0.5937 0.6661\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 176 Step: 30976 Index:0.6215 R2:0.7331 0.6215 0.5469 RMSE:0.4989 0.6151 0.6440 Tau:0.6627 0.5902 0.6533\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 177 Step: 31152 Index:0.6348 R2:0.7316 0.6348 0.5646 RMSE:0.4940 0.5982 0.6127 Tau:0.6648 0.6070 0.6608\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 178 Step: 31328 Index:0.6170 R2:0.7353 0.6170 0.5465 RMSE:0.5395 0.6600 0.6734 Tau:0.6653 0.5855 0.6670\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 179 Step: 31504 Index:0.6294 R2:0.7452 0.6294 0.5539 RMSE:0.4954 0.6170 0.6361 Tau:0.6738 0.6083 0.6694\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 180 Step: 31680 Index:0.6555 R2:0.7343 0.6555 0.5614 RMSE:0.4819 0.5727 0.6104 Tau:0.6643 0.6156 0.6725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 181 Step: 31856 Index:0.6414 R2:0.7462 0.6414 0.5408 RMSE:0.4771 0.5904 0.6270 Tau:0.6750 0.6035 0.6663\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 182 Step: 32032 Index:0.6377 R2:0.7478 0.6377 0.5770 RMSE:0.4924 0.6098 0.6192 Tau:0.6764 0.6038 0.6671\n",
      "Epoch: 183 Step: 32208 Index:0.6741 R2:0.7342 0.6741 0.5665 RMSE:0.5043 0.5802 0.6324 Tau:0.6631 0.6298 0.6727\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 184 Step: 32384 Index:0.6699 R2:0.7528 0.6699 0.5660 RMSE:0.4719 0.5685 0.6103 Tau:0.6800 0.6257 0.6809\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 185 Step: 32560 Index:0.6342 R2:0.7393 0.6342 0.5481 RMSE:0.4817 0.5948 0.6175 Tau:0.6704 0.6146 0.6619\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 186 Step: 32736 Index:0.6238 R2:0.7347 0.6238 0.5656 RMSE:0.4859 0.6065 0.6262 Tau:0.6631 0.5956 0.6575\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 187 Step: 32912 Index:0.6466 R2:0.7348 0.6466 0.5610 RMSE:0.5186 0.6189 0.6502 Tau:0.6679 0.6222 0.6624\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 188 Step: 33088 Index:0.6199 R2:0.7405 0.6199 0.5656 RMSE:0.4928 0.6198 0.6438 Tau:0.6700 0.5991 0.6556\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 189 Step: 33264 Index:0.6519 R2:0.7548 0.6519 0.5610 RMSE:0.4724 0.5848 0.6082 Tau:0.6819 0.6184 0.6599\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 190 Step: 33440 Index:0.6535 R2:0.7432 0.6535 0.5730 RMSE:0.5102 0.6064 0.6423 Tau:0.6733 0.6181 0.6626\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 191 Step: 33616 Index:0.6620 R2:0.7613 0.6620 0.5641 RMSE:0.5030 0.6133 0.6541 Tau:0.6875 0.6298 0.6724\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 192 Step: 33792 Index:0.6465 R2:0.7556 0.6465 0.5577 RMSE:0.5115 0.6129 0.6248 Tau:0.6839 0.6038 0.6762\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 193 Step: 33968 Index:0.6719 R2:0.7509 0.6719 0.5735 RMSE:0.5467 0.6284 0.6878 Tau:0.6772 0.6305 0.6729\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch: 194 Step: 34144 Index:0.6739 R2:0.7549 0.6739 0.5640 RMSE:0.4890 0.5788 0.6168 Tau:0.6801 0.6270 0.6744\n",
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch: 195 Step: 34320 Index:0.6550 R2:0.7511 0.6550 0.5572 RMSE:0.4677 0.5730 0.6195 Tau:0.6781 0.6149 0.6682\n",
      "EarlyStopping counter: 13 out of 30\n",
      "Epoch: 196 Step: 34496 Index:0.6667 R2:0.7348 0.6667 0.5675 RMSE:0.5033 0.5865 0.6290 Tau:0.6678 0.6292 0.6722\n",
      "EarlyStopping counter: 14 out of 30\n",
      "Epoch: 197 Step: 34672 Index:0.6659 R2:0.7600 0.6659 0.5694 RMSE:0.4852 0.5794 0.6142 Tau:0.6856 0.6251 0.6683\n",
      "EarlyStopping counter: 15 out of 30\n",
      "Epoch: 198 Step: 34848 Index:0.6504 R2:0.7644 0.6504 0.5617 RMSE:0.4768 0.6000 0.6293 Tau:0.6878 0.6149 0.6677\n",
      "EarlyStopping counter: 16 out of 30\n",
      "Epoch: 199 Step: 35024 Index:0.6707 R2:0.7572 0.6707 0.5667 RMSE:0.4678 0.5677 0.6103 Tau:0.6819 0.6317 0.6690\n",
      "EarlyStopping counter: 17 out of 30\n",
      "Epoch: 200 Step: 35200 Index:0.6451 R2:0.7529 0.6451 0.5751 RMSE:0.4985 0.6169 0.6457 Tau:0.6762 0.6153 0.6631\n",
      "EarlyStopping counter: 18 out of 30\n",
      "Epoch: 201 Step: 35376 Index:0.6687 R2:0.7671 0.6687 0.5600 RMSE:0.4625 0.5742 0.6201 Tau:0.6897 0.6251 0.6732\n",
      "Epoch: 202 Step: 35552 Index:0.6766 R2:0.7547 0.6766 0.5670 RMSE:0.4793 0.5724 0.6342 Tau:0.6758 0.6298 0.6708\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 203 Step: 35728 Index:0.6544 R2:0.7669 0.6544 0.5749 RMSE:0.4620 0.5783 0.6036 Tau:0.6906 0.6168 0.6734\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 204 Step: 35904 Index:0.6466 R2:0.7561 0.6466 0.5603 RMSE:0.4925 0.5986 0.6314 Tau:0.6815 0.6149 0.6591\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 205 Step: 36080 Index:0.6506 R2:0.7564 0.6506 0.5360 RMSE:0.4848 0.5971 0.6635 Tau:0.6798 0.6149 0.6635\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 206 Step: 36256 Index:0.6744 R2:0.7614 0.6744 0.5676 RMSE:0.4964 0.5912 0.6164 Tau:0.6886 0.6320 0.6792\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 207 Step: 36432 Index:0.6595 R2:0.7678 0.6595 0.5573 RMSE:0.4550 0.5729 0.6141 Tau:0.6908 0.6149 0.6676\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 208 Step: 36608 Index:0.6735 R2:0.7580 0.6735 0.5612 RMSE:0.4730 0.5693 0.6188 Tau:0.6821 0.6263 0.6743\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 209 Step: 36784 Index:0.6708 R2:0.7631 0.6708 0.5676 RMSE:0.4654 0.5666 0.6252 Tau:0.6844 0.6241 0.6692\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 210 Step: 36960 Index:0.6460 R2:0.7671 0.6460 0.5500 RMSE:0.4619 0.5898 0.6206 Tau:0.6922 0.6146 0.6683\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 211 Step: 37136 Index:0.6577 R2:0.7637 0.6577 0.5623 RMSE:0.4556 0.5732 0.6206 Tau:0.6875 0.6219 0.6652\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 212 Step: 37312 Index:0.6620 R2:0.7687 0.6620 0.5757 RMSE:0.4549 0.5737 0.6007 Tau:0.6916 0.6156 0.6733\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch: 213 Step: 37488 Index:0.6322 R2:0.7544 0.6322 0.5649 RMSE:0.4639 0.5962 0.6262 Tau:0.6762 0.5953 0.6674\n",
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch: 214 Step: 37664 Index:0.6682 R2:0.7724 0.6682 0.5710 RMSE:0.4510 0.5637 0.6129 Tau:0.6930 0.6279 0.6787\n",
      "EarlyStopping counter: 13 out of 30\n",
      "Epoch: 215 Step: 37840 Index:0.6571 R2:0.7731 0.6571 0.5581 RMSE:0.4491 0.5768 0.6190 Tau:0.6967 0.6219 0.6683\n",
      "EarlyStopping counter: 14 out of 30\n",
      "Epoch: 216 Step: 38016 Index:0.6569 R2:0.7753 0.6569 0.5569 RMSE:0.4493 0.5798 0.6204 Tau:0.6963 0.6083 0.6679\n",
      "EarlyStopping counter: 15 out of 30\n",
      "Epoch: 217 Step: 38192 Index:0.6745 R2:0.7768 0.6745 0.5484 RMSE:0.4848 0.6012 0.6560 Tau:0.6990 0.6225 0.6686\n",
      "EarlyStopping counter: 16 out of 30\n",
      "Epoch: 218 Step: 38368 Index:0.6742 R2:0.7784 0.6742 0.5744 RMSE:0.4416 0.5576 0.6044 Tau:0.7007 0.6203 0.6791\n",
      "Epoch: 219 Step: 38544 Index:0.6813 R2:0.7660 0.6813 0.5601 RMSE:0.4792 0.5750 0.6572 Tau:0.6886 0.6260 0.6762\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 220 Step: 38720 Index:0.6671 R2:0.7681 0.6671 0.5734 RMSE:0.5019 0.6119 0.6668 Tau:0.6902 0.6235 0.6684\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 221 Step: 38896 Index:0.6509 R2:0.7667 0.6509 0.5426 RMSE:0.4649 0.5953 0.6497 Tau:0.6898 0.6086 0.6702\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 222 Step: 39072 Index:0.6643 R2:0.7746 0.6643 0.5593 RMSE:0.4930 0.5933 0.6391 Tau:0.6953 0.6130 0.6735\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 223 Step: 39248 Index:0.6325 R2:0.7706 0.6325 0.5407 RMSE:0.4569 0.6026 0.6351 Tau:0.6907 0.5877 0.6599\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 224 Step: 39424 Index:0.6747 R2:0.7882 0.6747 0.5697 RMSE:0.4419 0.5626 0.6046 Tau:0.7067 0.6289 0.6732\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 225 Step: 39600 Index:0.6802 R2:0.7683 0.6802 0.5591 RMSE:0.4587 0.5638 0.6287 Tau:0.6897 0.6320 0.6688\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 226 Step: 39776 Index:0.6681 R2:0.7864 0.6681 0.5532 RMSE:0.4377 0.5672 0.6204 Tau:0.7067 0.6267 0.6633\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 227 Step: 39952 Index:0.6638 R2:0.7829 0.6638 0.5408 RMSE:0.4581 0.5894 0.6493 Tau:0.7042 0.6298 0.6632\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 228 Step: 40128 Index:0.6653 R2:0.7848 0.6653 0.5681 RMSE:0.4392 0.5654 0.6103 Tau:0.7038 0.6168 0.6782\n",
      "Epoch: 229 Step: 40304 Index:0.6938 R2:0.7740 0.6938 0.5560 RMSE:0.4503 0.5460 0.6165 Tau:0.6964 0.6419 0.6745\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 230 Step: 40480 Index:0.6650 R2:0.7807 0.6650 0.5773 RMSE:0.4569 0.5883 0.6402 Tau:0.7015 0.6099 0.6785\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 231 Step: 40656 Index:0.6864 R2:0.7852 0.6864 0.5572 RMSE:0.4711 0.5747 0.6325 Tau:0.7055 0.6320 0.6810\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 232 Step: 40832 Index:0.6669 R2:0.7851 0.6669 0.5594 RMSE:0.4363 0.5653 0.6173 Tau:0.7033 0.6200 0.6739\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 233 Step: 41008 Index:0.6669 R2:0.7923 0.6669 0.5627 RMSE:0.4280 0.5665 0.6236 Tau:0.7111 0.6200 0.6785\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 234 Step: 41184 Index:0.6553 R2:0.7853 0.6553 0.5554 RMSE:0.4395 0.5746 0.6158 Tau:0.7058 0.5994 0.6750\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 235 Step: 41360 Index:0.6620 R2:0.7893 0.6620 0.5494 RMSE:0.4377 0.5769 0.6406 Tau:0.7069 0.6165 0.6700\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 236 Step: 41536 Index:0.6932 R2:0.7801 0.6932 0.5702 RMSE:0.4438 0.5423 0.6116 Tau:0.7028 0.6469 0.6778\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 237 Step: 41712 Index:0.6637 R2:0.7717 0.6637 0.5583 RMSE:0.4602 0.5685 0.6177 Tau:0.6984 0.6058 0.6638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 238 Step: 41888 Index:0.6729 R2:0.7907 0.6729 0.5417 RMSE:0.4354 0.5647 0.6301 Tau:0.7088 0.6238 0.6725\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 239 Step: 42064 Index:0.6680 R2:0.7975 0.6680 0.5588 RMSE:0.4268 0.5657 0.6145 Tau:0.7138 0.6238 0.6734\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch: 240 Step: 42240 Index:0.6656 R2:0.7911 0.6656 0.5574 RMSE:0.4279 0.5658 0.6255 Tau:0.7077 0.6130 0.6762\n",
      "Epoch: 241 Step: 42416 Index:0.6988 R2:0.7924 0.6988 0.5789 RMSE:0.4351 0.5390 0.6036 Tau:0.7100 0.6358 0.6790\n",
      "Epoch: 242 Step: 42592 Index:0.7023 R2:0.7931 0.7023 0.5651 RMSE:0.4275 0.5350 0.6176 Tau:0.7157 0.6396 0.6762\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 243 Step: 42768 Index:0.6720 R2:0.7833 0.6720 0.5561 RMSE:0.4370 0.5637 0.6381 Tau:0.7016 0.6187 0.6752\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 244 Step: 42944 Index:0.7021 R2:0.7966 0.7021 0.5588 RMSE:0.4352 0.5497 0.6468 Tau:0.7140 0.6362 0.6764\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 245 Step: 43120 Index:0.6748 R2:0.7934 0.6748 0.5574 RMSE:0.4259 0.5573 0.6398 Tau:0.7093 0.6181 0.6750\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 246 Step: 43296 Index:0.6903 R2:0.7944 0.6903 0.5540 RMSE:0.4368 0.5597 0.6550 Tau:0.7099 0.6330 0.6762\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 247 Step: 43472 Index:0.6991 R2:0.7996 0.6991 0.5611 RMSE:0.4271 0.5449 0.6264 Tau:0.7143 0.6441 0.6777\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 248 Step: 43648 Index:0.7008 R2:0.7898 0.7008 0.5642 RMSE:0.4283 0.5335 0.6254 Tau:0.7068 0.6444 0.6783\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 249 Step: 43824 Index:0.6705 R2:0.7918 0.6705 0.5554 RMSE:0.4757 0.6044 0.6829 Tau:0.7072 0.6219 0.6791\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 250 Step: 44000 Index:0.6367 R2:0.7884 0.6367 0.5275 RMSE:0.4453 0.6044 0.6562 Tau:0.7065 0.6032 0.6705\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 251 Step: 44176 Index:0.6929 R2:0.7990 0.6929 0.5517 RMSE:0.4774 0.5948 0.6959 Tau:0.7146 0.6349 0.6828\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 252 Step: 44352 Index:0.6515 R2:0.8003 0.6515 0.5674 RMSE:0.4212 0.5807 0.6207 Tau:0.7172 0.6067 0.6752\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch: 253 Step: 44528 Index:0.6757 R2:0.7995 0.6757 0.5423 RMSE:0.4434 0.5816 0.6751 Tau:0.7149 0.6286 0.6745\n",
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch: 254 Step: 44704 Index:0.6932 R2:0.7979 0.6932 0.5584 RMSE:0.4417 0.5583 0.6470 Tau:0.7139 0.6355 0.6781\n",
      "EarlyStopping counter: 13 out of 30\n",
      "Epoch: 255 Step: 44880 Index:0.6511 R2:0.7923 0.6511 0.5329 RMSE:0.5588 0.6915 0.7591 Tau:0.7109 0.6007 0.6721\n",
      "EarlyStopping counter: 14 out of 30\n",
      "Epoch: 256 Step: 45056 Index:0.6860 R2:0.8061 0.6860 0.5639 RMSE:0.4279 0.5650 0.6520 Tau:0.7210 0.6330 0.6848\n",
      "EarlyStopping counter: 15 out of 30\n",
      "Epoch: 257 Step: 45232 Index:0.6979 R2:0.7979 0.6979 0.5639 RMSE:0.4212 0.5378 0.6281 Tau:0.7142 0.6368 0.6769\n",
      "EarlyStopping counter: 16 out of 30\n",
      "Epoch: 258 Step: 45408 Index:0.6818 R2:0.8016 0.6818 0.5615 RMSE:0.4182 0.5503 0.6229 Tau:0.7180 0.6263 0.6666\n",
      "EarlyStopping counter: 17 out of 30\n",
      "Epoch: 259 Step: 45584 Index:0.6712 R2:0.7978 0.6712 0.5308 RMSE:0.4336 0.5745 0.6701 Tau:0.7165 0.6276 0.6721\n",
      "EarlyStopping counter: 18 out of 30\n",
      "Epoch: 260 Step: 45760 Index:0.6857 R2:0.7969 0.6857 0.5551 RMSE:0.4264 0.5489 0.6379 Tau:0.7138 0.6295 0.6820\n",
      "EarlyStopping counter: 19 out of 30\n",
      "Epoch: 261 Step: 45936 Index:0.6955 R2:0.8078 0.6955 0.5466 RMSE:0.4140 0.5437 0.6452 Tau:0.7209 0.6286 0.6791\n",
      "EarlyStopping counter: 20 out of 30\n",
      "Epoch: 262 Step: 46112 Index:0.6726 R2:0.8033 0.6726 0.5495 RMSE:0.4508 0.5976 0.6859 Tau:0.7200 0.6203 0.6806\n",
      "Epoch: 263 Step: 46288 Index:0.7166 R2:0.8091 0.7166 0.5585 RMSE:0.4147 0.5209 0.6245 Tau:0.7240 0.6472 0.6782\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 264 Step: 46464 Index:0.6908 R2:0.7981 0.6908 0.5530 RMSE:0.4242 0.5440 0.6265 Tau:0.7170 0.6365 0.6699\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 265 Step: 46640 Index:0.6773 R2:0.7965 0.6773 0.5408 RMSE:0.4234 0.5611 0.6505 Tau:0.7150 0.6289 0.6712\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 266 Step: 46816 Index:0.6885 R2:0.8052 0.6885 0.5569 RMSE:0.4248 0.5639 0.6529 Tau:0.7199 0.6390 0.6804\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 267 Step: 46992 Index:0.6766 R2:0.8129 0.6766 0.5549 RMSE:0.4802 0.6221 0.7002 Tau:0.7264 0.6320 0.6764\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 268 Step: 47168 Index:0.6949 R2:0.7975 0.6949 0.5476 RMSE:0.4279 0.5454 0.6278 Tau:0.7145 0.6324 0.6796\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 269 Step: 47344 Index:0.6928 R2:0.8127 0.6928 0.5621 RMSE:0.4046 0.5431 0.6393 Tau:0.7253 0.6384 0.6820\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 270 Step: 47520 Index:0.6976 R2:0.8112 0.6976 0.5356 RMSE:0.4152 0.5431 0.6489 Tau:0.7278 0.6393 0.6849\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 271 Step: 47696 Index:0.6744 R2:0.8042 0.6744 0.5588 RMSE:0.4215 0.5671 0.6390 Tau:0.7205 0.6225 0.6635\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 272 Step: 47872 Index:0.6819 R2:0.8088 0.6819 0.5386 RMSE:0.4388 0.5800 0.6836 Tau:0.7244 0.6241 0.6798\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 273 Step: 48048 Index:0.6647 R2:0.8030 0.6647 0.5396 RMSE:0.4446 0.5951 0.6720 Tau:0.7179 0.6187 0.6819\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch: 274 Step: 48224 Index:0.6997 R2:0.8094 0.6997 0.5396 RMSE:0.4170 0.5421 0.6378 Tau:0.7268 0.6447 0.6805\n",
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch: 275 Step: 48400 Index:0.6639 R2:0.8034 0.6639 0.5571 RMSE:0.4142 0.5676 0.6358 Tau:0.7199 0.6200 0.6755\n",
      "EarlyStopping counter: 13 out of 30\n",
      "Epoch: 276 Step: 48576 Index:0.6963 R2:0.8151 0.6963 0.5457 RMSE:0.4026 0.5385 0.6436 Tau:0.7272 0.6368 0.6790\n",
      "EarlyStopping counter: 14 out of 30\n",
      "Epoch: 277 Step: 48752 Index:0.6836 R2:0.8084 0.6836 0.5375 RMSE:0.4182 0.5597 0.6561 Tau:0.7254 0.6314 0.6775\n",
      "EarlyStopping counter: 15 out of 30\n",
      "Epoch: 278 Step: 48928 Index:0.6902 R2:0.8061 0.6902 0.5481 RMSE:0.4296 0.5586 0.6584 Tau:0.7232 0.6349 0.6866\n",
      "EarlyStopping counter: 16 out of 30\n",
      "Epoch: 279 Step: 49104 Index:0.6705 R2:0.8108 0.6705 0.5451 RMSE:0.4171 0.5728 0.6640 Tau:0.7252 0.6289 0.6789\n",
      "EarlyStopping counter: 17 out of 30\n",
      "Epoch: 280 Step: 49280 Index:0.6763 R2:0.7978 0.6763 0.5750 RMSE:0.4209 0.5555 0.6204 Tau:0.7146 0.6343 0.6733\n",
      "EarlyStopping counter: 18 out of 30\n",
      "Epoch: 281 Step: 49456 Index:0.6903 R2:0.8160 0.6903 0.5337 RMSE:0.4147 0.5536 0.6507 Tau:0.7319 0.6438 0.6763\n",
      "EarlyStopping counter: 19 out of 30\n",
      "Epoch: 282 Step: 49632 Index:0.6608 R2:0.8153 0.6608 0.5497 RMSE:0.4128 0.5812 0.6479 Tau:0.7291 0.6159 0.6722\n",
      "EarlyStopping counter: 20 out of 30\n",
      "Epoch: 283 Step: 49808 Index:0.7043 R2:0.8158 0.7043 0.5428 RMSE:0.4018 0.5350 0.6674 Tau:0.7272 0.6504 0.6823\n",
      "EarlyStopping counter: 21 out of 30\n",
      "Epoch: 284 Step: 49984 Index:0.6574 R2:0.8018 0.6574 0.5391 RMSE:0.4166 0.5716 0.6499 Tau:0.7183 0.6244 0.6827\n",
      "EarlyStopping counter: 22 out of 30\n",
      "Epoch: 285 Step: 50160 Index:0.6907 R2:0.8035 0.6907 0.5277 RMSE:0.4517 0.5692 0.6583 Tau:0.7214 0.6352 0.6865\n",
      "EarlyStopping counter: 23 out of 30\n",
      "Epoch: 286 Step: 50336 Index:0.6825 R2:0.8166 0.6825 0.5533 RMSE:0.4034 0.5595 0.6497 Tau:0.7286 0.6254 0.6771\n",
      "EarlyStopping counter: 24 out of 30\n",
      "Epoch: 287 Step: 50512 Index:0.6709 R2:0.8094 0.6709 0.5659 RMSE:0.4173 0.5690 0.6376 Tau:0.7237 0.6292 0.6749\n",
      "EarlyStopping counter: 25 out of 30\n",
      "Epoch: 288 Step: 50688 Index:0.7007 R2:0.8057 0.7007 0.5616 RMSE:0.4336 0.5454 0.6348 Tau:0.7207 0.6517 0.6777\n",
      "EarlyStopping counter: 26 out of 30\n",
      "Epoch: 289 Step: 50864 Index:0.6817 R2:0.8017 0.6817 0.5156 RMSE:0.4539 0.5905 0.7104 Tau:0.7191 0.6403 0.6793\n",
      "EarlyStopping counter: 27 out of 30\n",
      "Epoch: 290 Step: 51040 Index:0.6971 R2:0.8028 0.6971 0.5498 RMSE:0.4327 0.5593 0.6690 Tau:0.7203 0.6396 0.6765\n",
      "EarlyStopping counter: 28 out of 30\n",
      "Epoch: 291 Step: 51216 Index:0.6937 R2:0.8177 0.6937 0.5526 RMSE:0.4011 0.5403 0.6433 Tau:0.7306 0.6314 0.6831\n",
      "EarlyStopping counter: 29 out of 30\n",
      "Epoch: 292 Step: 51392 Index:0.6547 R2:0.7825 0.6547 0.5222 RMSE:0.4447 0.5752 0.6473 Tau:0.6987 0.6102 0.6655\n",
      "EarlyStopping counter: 30 out of 30\n",
      "Epoch: 293 Step: 51568 Index:0.6916 R2:0.8235 0.6916 0.5484 RMSE:0.4048 0.5580 0.6626 Tau:0.7393 0.6346 0.6808\n"
     ]
    }
   ],
   "source": [
    "# train_f_list=[]\n",
    "# train_mse_list=[]\n",
    "# train_r2_list=[]\n",
    "# test_f_list=[]\n",
    "# test_mse_list=[]\n",
    "# test_r2_list=[]\n",
    "# val_f_list=[]\n",
    "# val_mse_list=[]\n",
    "# val_r2_list=[]\n",
    "# epoch_list=[]\n",
    "# train_predict_list=[]\n",
    "# test_predict_list=[]\n",
    "# val_predict_list=[]\n",
    "# train_y_list=[]\n",
    "# test_y_list=[]\n",
    "# val_y_list=[]\n",
    "# train_d_list=[]\n",
    "# test_d_list=[]\n",
    "# val_d_list=[]\n",
    "\n",
    "epoch = 0\n",
    "optimizer_list = [optimizer, optimizer_AFSE, optimizer_GRN]\n",
    "max_epoch = 1000\n",
    "while epoch < max_epoch:\n",
    "    train(model, amodel, gmodel, train_df, test_df, optimizer_list, loss_function, epoch)\n",
    "#     print(train_df.shape,test_df.shape)\n",
    "    train_d, train_f, train_r2, train_MSE, train_predict, reconstruction_loss, one_hot_loss, interger_loss,binary_loss = eval(model, amodel, gmodel, train_df,output_feature=True,return_GRN_loss=True)\n",
    "    train_predict = np.array(train_predict)\n",
    "    train_WTI = weighted_top_index(train_df, train_predict, len(train_df))\n",
    "    train_tau, _ = scipy.stats.kendalltau(train_predict,train_df[tasks[0]].values.astype(float).tolist())\n",
    "    val_d, val_f, val_r2, val_MSE, val_predict, val_reconstruction_loss, val_one_hot_loss, val_interger_loss,val_binary_loss = eval(model, amodel, gmodel, val_df,output_feature=True,return_GRN_loss=True)\n",
    "    val_predict = np.array(val_predict)\n",
    "    val_WTI = weighted_top_index(val_df, val_predict, len(val_df))\n",
    "    val_AP = AP(val_df, val_predict, len(val_df))\n",
    "    val_tau, _ = scipy.stats.kendalltau(val_predict,val_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "    test_d, test_f, test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df,output_feature=True)\n",
    "    test_predict = np.array(test_predict)\n",
    "    test_WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "#     test_AP = AP(test_df, test_predict, test_active)\n",
    "    test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    k_list = [int(len(test_df)*0.01),int(len(test_df)*0.03),int(len(test_df)*0.1),10,30,100]\n",
    "    topk_list =[]\n",
    "    false_positive_rate_list = []\n",
    "    for k in k_list:\n",
    "        a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "        topk_list.append(a)\n",
    "        false_positive_rate_list.append(b)\n",
    "    \n",
    "    epoch = epoch + 1\n",
    "    global_step = epoch * int(np.max([len(train_df),len(test_df)])/batch_size)\n",
    "    logger.add_scalar('val/WTI', val_WTI, global_step)\n",
    "    logger.add_scalar('val/AP', val_AP, global_step)\n",
    "    logger.add_scalar('val/r2', val_r2, global_step)\n",
    "    logger.add_scalar('val/RMSE', val_MSE**0.5, global_step)\n",
    "    logger.add_scalar('val/Tau', val_tau, global_step)\n",
    "#     logger.add_scalar('test/TAP', test_AP, global_step)\n",
    "    logger.add_scalar('test/r2', test_r2_a, global_step)\n",
    "    logger.add_scalar('test/RMSE', test_MSE_a**0.5, global_step)\n",
    "    logger.add_scalar('test/Tau', test_tau, global_step)\n",
    "    logger.add_scalar('val/GRN', reconstruction_loss, global_step)\n",
    "    logger.add_scalar('test/EF0.01', topk_list[0], global_step)\n",
    "    logger.add_scalar('test/EF0.03', topk_list[1], global_step)\n",
    "    logger.add_scalar('test/EF0.1', topk_list[2], global_step)\n",
    "    logger.add_scalar('test/EF10', topk_list[3], global_step)\n",
    "    logger.add_scalar('test/EF30', topk_list[4], global_step)\n",
    "    logger.add_scalar('test/EF100', topk_list[5], global_step)\n",
    "    \n",
    "#     train_mse_list.append(train_MSE**0.5)\n",
    "#     train_r2_list.append(train_r2)\n",
    "#     val_mse_list.append(val_MSE**0.5)  \n",
    "#     val_r2_list.append(val_r2)\n",
    "#     train_f_list.append(train_f)\n",
    "#     val_f_list.append(val_f)\n",
    "#     test_f_list.append(test_f)\n",
    "#     epoch_list.append(epoch)\n",
    "#     train_predict_list.append(train_predict.flatten())\n",
    "#     test_predict_list.append(test_predict.flatten())\n",
    "#     val_predict_list.append(val_predict.flatten())\n",
    "#     train_y_list.append(train_df[tasks[0]].values)\n",
    "#     val_y_list.append(val_df[tasks[0]].values)\n",
    "#     test_y_list.append(test_df[tasks[0]].values)\n",
    "#     train_d_list.append(train_d)\n",
    "#     val_d_list.append(val_d)\n",
    "#     test_d_list.append(test_d)\n",
    "\n",
    "    stop_index = val_r2\n",
    "    early_stop = stopper.step(stop_index, model)\n",
    "    early_stop = stopper_afse.step(stop_index, amodel, if_print=False)\n",
    "    early_stop = stopper_generate.step(stop_index, gmodel, if_print=False)\n",
    "#     print('epoch {:d}/{:d}, validation {} {:.4f}, {} {:.4f},best validation {r2} {:.4f}'.format(epoch, total_epoch, 'r2', val_r2, 'mse:',val_MSE, stopper.best_score))\n",
    "    print('Epoch:',epoch, 'Step:', global_step, 'Index:%.4f'%stop_index, 'R2:%.4f'%train_r2,'%.4f'%val_r2,'%.4f'%test_r2_a, 'RMSE:%.4f'%train_MSE**0.5, '%.4f'%val_MSE**0.5, \n",
    "          '%.4f'%test_MSE_a**0.5, 'Tau:%.4f'%train_tau,'%.4f'%val_tau,'%.4f'%test_tau)#, 'Tau:%.4f'%val_tau,'%.4f'%test_tau,'GRN:%.4f'%reconstruction_loss,'%.4f'%val_reconstruction_loss\n",
    "    if early_stop:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopper.load_checkpoint(model)\n",
    "stopper_afse.load_checkpoint(amodel)\n",
    "stopper_generate.load_checkpoint(gmodel)\n",
    "    \n",
    "test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df)\n",
    "test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "test_r2_ina, test_MSE_ina, test_predict_ina = eval(model, amodel, gmodel, test_df[test_active:].reset_index(drop=True))\n",
    "    \n",
    "test_predict = np.array(test_predict)\n",
    "test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "\n",
    "k_list = [int(len(test_df)*0.01),int(len(test_df)*0.05),int(len(test_df)*0.1),int(len(test_df)*0.15),int(len(test_df)*0.2),int(len(test_df)*0.25),\n",
    "          int(len(test_df)*0.3),int(len(test_df)*0.4),int(len(test_df)*0.5),50,100,150,200,250,300]\n",
    "topk_list =[]\n",
    "false_positive_rate_list = []\n",
    "for k in k_list:\n",
    "    a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "    topk_list.append(a)\n",
    "    false_positive_rate_list.append(b)\n",
    "WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "ap = AP(test_df, test_predict, test_active)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 293 r2:0.5585 RMSE:0.6245 WTI:0.3904 AP:0.8736 Tau:0.6782 \n",
      " \n",
      " Top-1:0.5000 Top-1-fp:0.0000 \n",
      " Top-5:0.5610 Top-5-fp:0.0000 \n",
      " Top-10:0.5976 Top-10-fp:0.0366 \n",
      " Top-15:0.7236 Top-15-fp:0.0244 \n",
      " Top-20:0.7317 Top-20-fp:0.0183 \n",
      " Top-25:0.7756 Top-25-fp:0.0244 \n",
      " Top-30:0.8293 Top-30-fp:0.0366 \n",
      " Top-40:0.8567 Top-40-fp:0.0793 \n",
      " Top-50:0.8634 Top-50-fp:0.1293 \n",
      " \n",
      " Top50:0.6000 Top50-fp:0.0200 \n",
      " Top100:0.6300 Top100-fp:0.0300 \n",
      " Top150:0.7267 Top150-fp:0.0200 \n",
      " Top200:0.7650 Top200-fp:0.0250 \n",
      " Top250:0.8280 Top250-fp:0.0360 \n",
      " Top300:0.8333 Top300-fp:0.0600 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(' epoch:',epoch,'r2:%.4f'%test_r2_a,'RMSE:%.4f'%test_MSE_a**0.5,'WTI:%.4f'%WTI,'AP:%.4f'%ap,'Tau:%.4f'%test_tau,'\\n','\\n',\n",
    "      'Top-1:%.4f'%topk_list[0],'Top-1-fp:%.4f'%false_positive_rate_list[0],'\\n',\n",
    "      'Top-5:%.4f'%topk_list[1],'Top-5-fp:%.4f'%false_positive_rate_list[1],'\\n',\n",
    "      'Top-10:%.4f'%topk_list[2],'Top-10-fp:%.4f'%false_positive_rate_list[2],'\\n',\n",
    "      'Top-15:%.4f'%topk_list[3],'Top-15-fp:%.4f'%false_positive_rate_list[3],'\\n',\n",
    "      'Top-20:%.4f'%topk_list[4],'Top-20-fp:%.4f'%false_positive_rate_list[4],'\\n',\n",
    "      'Top-25:%.4f'%topk_list[5],'Top-25-fp:%.4f'%false_positive_rate_list[5],'\\n',\n",
    "      'Top-30:%.4f'%topk_list[6],'Top-30-fp:%.4f'%false_positive_rate_list[6],'\\n',\n",
    "      'Top-40:%.4f'%topk_list[7],'Top-40-fp:%.4f'%false_positive_rate_list[7],'\\n',\n",
    "      'Top-50:%.4f'%topk_list[8],'Top-50-fp:%.4f'%false_positive_rate_list[8],'\\n','\\n',\n",
    "      'Top50:%.4f'%topk_list[9],'Top50-fp:%.4f'%false_positive_rate_list[9],'\\n',\n",
    "      'Top100:%.4f'%topk_list[10],'Top100-fp:%.4f'%false_positive_rate_list[10],'\\n',\n",
    "      'Top150:%.4f'%topk_list[11],'Top150-fp:%.4f'%false_positive_rate_list[11],'\\n',\n",
    "      'Top200:%.4f'%topk_list[12],'Top200-fp:%.4f'%false_positive_rate_list[12],'\\n',\n",
    "      'Top250:%.4f'%topk_list[13],'Top250-fp:%.4f'%false_positive_rate_list[13],'\\n',\n",
    "      'Top300:%.4f'%topk_list[14],'Top300-fp:%.4f'%false_positive_rate_list[14],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('target_file:',train_filename)\n",
    "# print('inactive_file:',test_filename)\n",
    "# np.savez(result_dir, epoch_list, train_f_list, train_d_list, \n",
    "#          train_predict_list, train_y_list, val_f_list, val_d_list, val_predict_list, val_y_list, test_f_list, \n",
    "#          test_d_list, test_predict_list, test_y_list)\n",
    "# sim_space = np.load(result_dir+'.npz')\n",
    "# print(sim_space['arr_10'].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
