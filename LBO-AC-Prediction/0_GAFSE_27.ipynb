{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import math\n",
    "torch.manual_seed(8)\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP.AttentiveLayers_Sim_copy import Fingerprint, GRN, AFSE\n",
    "from AttentiveFP import Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set()\n",
    "from IPython.display import SVG, display\n",
    "import sascorer\n",
    "from AttentiveFP.utils import EarlyStopping\n",
    "from AttentiveFP.utils import Meter\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "import AttentiveFP.Featurizer\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ki_P29275_1_400\n",
      "model_file/0_GAFSE_Ki_P29275_1_400_run_0\n"
     ]
    }
   ],
   "source": [
    "train_filename = \"./data/benchmark/Ki_P29275_1_400_train.csv\"\n",
    "test_filename = \"./data/benchmark/Ki_P29275_1_400_test.csv\"\n",
    "test_active = 400\n",
    "val_rate = 0.2\n",
    "random_seed = 68\n",
    "file_list1 = train_filename.split('/')\n",
    "file1 = file_list1[-1]\n",
    "file1 = file1[:-10]\n",
    "number = '_run_0'\n",
    "model_file = \"model_file/0_GAFSE_\"+file1+number\n",
    "log_dir = f'log/{\"0_GAFSE_\"+file1}'+number\n",
    "result_dir = './result/0_GAFSE_'+file1+number\n",
    "print(file1)\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              smiles     value\n",
      "0  CCN1C(=O)C2=C(NC1=O)N=C(N2)C3=CC=C(C=C3)S(=O)(... -0.198657\n",
      "1  CCCN1C2=C(C(=O)N(C1=O)CCC)NC(=C2Cl)C3=CC=C(C=C... -2.149988\n",
      "2  CCCN1C2=C(C(=O)N(C1=O)CCC)NC(=C2)C3=CC=C(C=C3)... -0.889918\n",
      "3  CN1C2=C(C(=O)N(C1=O)C)NC(=C2)C3=CC=C(C=C3)OCC(... -1.350054\n",
      "4          CC1=C(C(N2C=CN=C2N1)C3=CSC=C3)C(=O)OC(C)C -2.927960\n",
      "number of all smiles:  1072\n",
      "number of successfully processed smiles:  1072\n",
      "                                              smiles     value  \\\n",
      "0  CCN1C(=O)C2=C(NC1=O)N=C(N2)C3=CC=C(C=C3)S(=O)(... -0.198657   \n",
      "1  CCCN1C2=C(C(=O)N(C1=O)CCC)NC(=C2Cl)C3=CC=C(C=C... -2.149988   \n",
      "2  CCCN1C2=C(C(=O)N(C1=O)CCC)NC(=C2)C3=CC=C(C=C3)... -0.889918   \n",
      "3  CN1C2=C(C(=O)N(C1=O)C)NC(=C2)C3=CC=C(C=C3)OCC(... -1.350054   \n",
      "4          CC1=C(C(N2C=CN=C2N1)C3=CSC=C3)C(=O)OC(C)C -2.927960   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0  CCn1c(=O)[nH]c2nc(-c3ccc(S(=O)(=O)N4CCN(Cc5ccc...  \n",
      "1  CCCn1c(=O)c2[nH]c(-c3ccc(OCC(=O)Nc4ccccc4F)cc3...  \n",
      "2  CCCn1c(=O)c2[nH]c(-c3ccc(OCC(=O)Nc4ccc(CS(=O)(...  \n",
      "3  Cn1c(=O)c2[nH]c(-c3ccc(OCC(=O)NC4CCc5ccccc54)c...  \n",
      "4              CC1=C(C(=O)OC(C)C)C(c2ccsc2)n2ccnc2N1  \n"
     ]
    }
   ],
   "source": [
    "# task_name = 'Malaria Bioactivity'\n",
    "tasks = ['value']\n",
    "\n",
    "# train_filename = \"../data/active_inactive/median_active/EC50/Q99500.csv\"\n",
    "feature_filename = train_filename.replace('.csv','.pickle')\n",
    "filename = train_filename.replace('.csv','')\n",
    "prefix_filename = train_filename.split('/')[-1].replace('.csv','')\n",
    "train_df = pd.read_csv(train_filename, header=0, names = [\"smiles\",\"value\"],usecols=[0,1])\n",
    "# train_df = train_df[1:]\n",
    "# train_df = train_df.drop(0,axis=1,inplace=False) \n",
    "print(train_df[:5])\n",
    "# print(train_df.iloc(1))\n",
    "def add_canonical_smiles(train_df):\n",
    "    smilesList = train_df.smiles.values\n",
    "    print(\"number of all smiles: \",len(smilesList))\n",
    "    atom_num_dist = []\n",
    "    remained_smiles = []\n",
    "    canonical_smiles_list = []\n",
    "    for smiles in smilesList:\n",
    "        try:        \n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            atom_num_dist.append(len(mol.GetAtoms()))\n",
    "            remained_smiles.append(smiles)\n",
    "            canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "        except:\n",
    "            print(smiles)\n",
    "            pass\n",
    "    print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "    train_df = train_df[train_df[\"smiles\"].isin(remained_smiles)]\n",
    "    train_df['cano_smiles'] =canonical_smiles_list\n",
    "    return train_df\n",
    "# print(train_df)\n",
    "train_df = add_canonical_smiles(train_df)\n",
    "\n",
    "print(train_df.head())\n",
    "# plt.figure(figsize=(5, 3))\n",
    "# sns.set(font_scale=1.5)\n",
    "# ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "# plt.tight_layout()\n",
    "# # plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "# plt.show()\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "\n",
    "p_dropout= 0.03\n",
    "fingerprint_dim = 100\n",
    "\n",
    "weight_decay = 4.3 # also known as l2_regularization_lambda\n",
    "learning_rate = 4\n",
    "radius = 2 # default: 2\n",
    "T = 1\n",
    "per_task_output_units_num = 1 # for regression model\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  1075\n",
      "number of successfully processed smiles:  1075\n",
      "(1075, 3)\n",
      "                                              smiles     value  \\\n",
      "0  CN1C2=C(C(=O)N(C1=O)C)NC(=C2)C3=C(C=C(C=C3)OCC... -3.190001   \n",
      "1  CCCN1C(=O)C2=C(NC1=O)N=C(N2)C3=CC=C(C=C3)S(=O)...  0.106793   \n",
      "2  CCCN1C2=C(C(=O)N(C1=O)CCC)NC(=N2)C3=CN(N=C3)CC... -1.301030   \n",
      "3            C1=COC(=C1)C2=NN3C(=N2)C4=C(NN=C4)N=C3N -1.707570   \n",
      "4  CC1=CC=C(O1)C2=CC(=NC(=N2)N)C(=O)NCC3=NC=CN3C(C)C -3.265761   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0  COc1cc(OCC(=O)O)ccc1-c1cc2c([nH]1)c(=O)n(C)c(=...  \n",
      "1  CCCn1c(=O)[nH]c2nc(-c3ccc(S(=O)(=O)N4CCN(Cc5cc...  \n",
      "2  CCCn1c(=O)c2[nH]c(-c3cnn(Cc4ccc(C(F)(F)F)cc4)c...  \n",
      "3                   Nc1nc2[nH]ncc2c2nc(-c3ccco3)nn12  \n",
      "4        Cc1ccc(-c2cc(C(=O)NCc3nccn3C(C)C)nc(N)n2)o1  \n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_filename,header=0,names=[\"smiles\",\"value\"],usecols=[0,1])\n",
    "test_df = add_canonical_smiles(test_df)\n",
    "for l in test_df[\"cano_smiles\"]:\n",
    "    if l in train_df[\"cano_smiles\"]:\n",
    "        print(\"same smiles:\",l)\n",
    "        \n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/benchmark/Ki_P29275_1_400_train.pickle\n",
      "./data/benchmark/Ki_P29275_1_400_train\n",
      "2147\n",
      "feature dicts file saved as ./data/benchmark/Ki_P29275_1_400_train.pickle\n"
     ]
    }
   ],
   "source": [
    "print(feature_filename)\n",
    "print(filename)\n",
    "total_df = pd.concat([train_df,test_df],axis=0)\n",
    "total_smilesList = total_df['smiles'].values\n",
    "print(len(total_smilesList))\n",
    "# if os.path.isfile(feature_filename):\n",
    "#     feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "# else:\n",
    "#     feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "feature_dicts = save_smiles_dicts(total_smilesList,filename)\n",
    "remained_df = total_df[total_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = total_df.drop(remained_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(858, 3) (214, 3) (1075, 3)\n"
     ]
    }
   ],
   "source": [
    "val_df = train_df.sample(frac=val_rate,random_state=random_seed)\n",
    "train_df = train_df.drop(val_df.index)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "train_df = train_df[train_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df[val_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df[test_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "print(train_df.shape,val_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([total_df[\"cano_smiles\"].values[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "loss_function = nn.MSELoss()\n",
    "model = Fingerprint(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "amodel = AFSE(fingerprint_dim, output_units_num, p_dropout)\n",
    "gmodel = GRN(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, p_dropout)\n",
    "model.cuda()\n",
    "amodel.cuda()\n",
    "gmodel.cuda()\n",
    "\n",
    "# optimizer = optim.Adam([\n",
    "# {'params': model.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# {'params': gmodel.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# ])\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "optimizer_AFSE = optim.Adam(params=amodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# optimizer_AFSE = optim.SGD(params=amodel.parameters(), lr = 0.01, momentum=0.9)\n",
    "\n",
    "optimizer_GRN = optim.Adam(params=gmodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# tensorboard = SummaryWriter(log_dir=\"runs/\"+start_time+\"_\"+prefix_filename+\"_\"+str(fingerprint_dim)+\"_\"+str(p_dropout))\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "# print(params)\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def sorted_show_pik(dataset, p, k, k_predict, i, acc):\n",
    "    p_value = dataset[tasks[0]].astype(float).tolist()\n",
    "    x = np.arange(0,len(dataset),1)\n",
    "#     print('plt',dataset.head(),p[:10],k_predict,k)\n",
    "#     plt.figure()\n",
    "#     fig, ax1 = plt.subplots()\n",
    "#     ax1.grid(False)\n",
    "#     ax2 = ax1.twinx()\n",
    "#     plt.grid(False)\n",
    "    plt.scatter(x,p,marker='.',s=6,color='r',label='predict')\n",
    "#     plt.ylabel('predict')\n",
    "    plt.scatter(x,p_value,s=6,marker=',',color='blue',label='p_value')\n",
    "    plt.axvline(x=k-1,ls=\"-\",c=\"black\")#添加垂直直线\n",
    "    k_value = np.ones(len(dataset))\n",
    "# #     print(EC50[k-1])\n",
    "    k_value = k_value*k_predict\n",
    "    plt.plot(x,k_value,'-',color='black')\n",
    "    plt.ylabel('p_value')\n",
    "    plt.title(\"epoch: {},  top-k recall: {}\".format(i,acc))\n",
    "    plt.legend(loc=3,fontsize=5)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def topk_acc2(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "    \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    k_true = true_sort[tasks[0]].values[k-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('k_true: ',type(k_true),k_true)\n",
    "#     print('k_true: ',k_true,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=k_true,'acc_num: ',len(df3[df3['predict'].values>=k_true]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k)\n",
    "    acc = len(df3[df3[tasks[0]].values>=k_true])/k #预测值前k个中真实排在前k个的个数/k\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/k\n",
    "    if k>active_num:\n",
    "        min_active = true_sort[tasks[0]].values[active_num-1]\n",
    "        acc = len(df3[df3[tasks[0]].values>=min_active])/k\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "def topk_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "        \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个，因为后面的全是-4.1\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    min_active = true_sort[tasks[0]].values[active_num-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('min_active: ',type(min_active),min_active)\n",
    "#     print('min_active: ',min_active,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=min_active,'acc_num: ',len(df3[df3['predict'].values>=min_active]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k,'active_num: ',active_num)\n",
    "    acc = len(df3[df3[tasks[0]].values>-4.1])/active_num #预测值前k个中真实排在前active_num个的个数/active_num\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/active_num\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "    \n",
    "def topk_acc_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    if k>active_num:\n",
    "        return topk_recall(df, predict, k, active_num, show_flag, i)\n",
    "    return topk_acc2(df,predict,k, active_num,show_flag,i)\n",
    "\n",
    "def weighted_top_index(df, predict, active_num):\n",
    "    weighted_acc_list=[]\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        acc, fp = topk_acc_recall(df, predict, k, active_num)\n",
    "        weight = (len(df)-k)/len(df)\n",
    "#         print('weight=',weight,'acc=',acc)\n",
    "        weighted_acc_list.append(acc*weight)#\n",
    "    weighted_acc_list = np.array(weighted_acc_list)\n",
    "#     print('weighted_acc_list=',weighted_acc_list)\n",
    "    return np.sum(weighted_acc_list)/weighted_acc_list.shape[0]\n",
    "\n",
    "def AP(df, predict, active_num):\n",
    "    prec = []\n",
    "    rec = []\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        prec_k, fp1 = topk_acc2(df,predict,k, active_num)\n",
    "        rec_k, fp2 = topk_recall(df, predict, k, active_num)\n",
    "        prec.append(prec_k)\n",
    "        rec.append(rec_k)\n",
    "    # 取所有不同的recall对应的点处的精度值做平均\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.], rec, [1.]))\n",
    "    mpre = np.concatenate(([0.], prec, [0.]))\n",
    "\n",
    "    # 计算包络线，从后往前取最大保证precise非减\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # 找出所有检测结果中recall不同的点\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "#     print(prec)\n",
    "#     print('prec='+str(prec)+'\\n\\n'+'rec='+str(rec))\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    # 用recall的间隔对精度作加权平均\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_r2(y,predict):\n",
    "#     print(y)\n",
    "#     print(predict)\n",
    "    y = torch.FloatTensor(y).reshape(-1,1)\n",
    "    predict = torch.FloatTensor(predict).reshape(-1,1)\n",
    "    y_mean = torch.mean(y)\n",
    "    predict_mean = torch.mean(predict)\n",
    "    \n",
    "    y1 = torch.pow(torch.mm((y-y_mean).t(),(predict-predict_mean)),2)\n",
    "    y2 = torch.mm((y-y_mean).t(),(y-y_mean))*torch.mm((predict-predict_mean).t(),(predict-predict_mean))\n",
    "#     print(y1,y2)\n",
    "    return y1/y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def l2_norm(input, dim):\n",
    "    norm = torch.norm(input, dim=dim, keepdim=True)\n",
    "    output = torch.div(input, norm+1e-6)\n",
    "    return output\n",
    "\n",
    "def normalize_perturbation(d,dim=-1):\n",
    "    output = l2_norm(d, dim)\n",
    "    return output\n",
    "\n",
    "def tanh(x):\n",
    "    return (torch.exp(x)-torch.exp(-x))/(torch.exp(x)+torch.exp(-x))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "def perturb_feature(f, model, alpha=1, lamda=10**-learning_rate, output_lr=False, output_plr=False, y=None):\n",
    "    mol_prediction = model(feature=f, d=0)\n",
    "    pred = mol_prediction.detach()\n",
    "#     f = torch.div(f, torch.norm(f, dim=-1, keepdim=True)+1e-9)\n",
    "    eps = 1e-6 * normalize_perturbation(torch.randn(f.shape))\n",
    "    eps = Variable(eps, requires_grad=True)\n",
    "    # Predict on randomly perturbed image\n",
    "    eps_p = model(feature=f, d=eps.cuda())\n",
    "    eps_p_ = model(feature=f, d=-eps.cuda())\n",
    "    p_aux = nn.Sigmoid()(eps_p/(pred+1e-6))\n",
    "    p_aux_ = nn.Sigmoid()(eps_p_/(pred+1e-6))\n",
    "#     loss = nn.BCELoss()(abs(p_aux),torch.ones_like(p_aux))+nn.BCELoss()(abs(p_aux_),torch.ones_like(p_aux_))\n",
    "    loss = loss_function(p_aux,torch.ones_like(p_aux))+loss_function(p_aux_,torch.ones_like(p_aux_))\n",
    "    loss.backward(retain_graph=True)\n",
    "\n",
    "    # Based on perturbed image, get direction of greatest error\n",
    "    eps_adv = eps.grad#/10**-learning_rate\n",
    "    optimizer_AFSE.zero_grad()\n",
    "    # Use that direction as adversarial perturbation\n",
    "    eps_adv_normed = normalize_perturbation(eps_adv)\n",
    "    d_adv = lamda * eps_adv_normed.cuda()\n",
    "    if output_lr:\n",
    "        f_p, max_lr = model(feature=f, d=d_adv, output_lr=output_lr)\n",
    "    f_p = model(feature=f, d=d_adv)\n",
    "    f_p_ = model(feature=f, d=-d_adv)\n",
    "    p = nn.Sigmoid()(f_p/(pred+1e-6))\n",
    "    p_ = nn.Sigmoid()(f_p_/(pred+1e-6))\n",
    "    vat_loss = loss_function(p,torch.ones_like(p))+loss_function(p_,torch.ones_like(p_))\n",
    "    if output_lr:\n",
    "        if output_plr:\n",
    "            loss = loss_function(mol_prediction,y)\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer_AFSE.zero_grad()\n",
    "            punish_lr = torch.norm(torch.mean(eps.grad,0))\n",
    "            return eps_adv, d_adv, vat_loss, mol_prediction, max_lr, punish_lr\n",
    "        return eps_adv, d_adv, vat_loss, mol_prediction, max_lr\n",
    "    return eps_adv, d_adv, vat_loss, mol_prediction\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "\n",
    "def d_loss(f, pred, model, y_val):\n",
    "    diff_loss = 0\n",
    "    length = len(pred)\n",
    "    for i in range(length):\n",
    "        for j in range(length):\n",
    "            if j == i:\n",
    "                continue\n",
    "            pred_diff = model(feature_only=True, feature1=f[i], feature2=f[j])\n",
    "            true_diff = y_val[i] - y_val[j]\n",
    "            diff_loss += loss_function(pred_diff, torch.Tensor([true_diff]).view(-1,1))\n",
    "    diff_loss = diff_loss/(length*(length-1))\n",
    "    return diff_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CE(x,y):\n",
    "    c = 0\n",
    "    l = len(y)\n",
    "    for i in range(l):\n",
    "        if y[i]==1:\n",
    "            c += 1\n",
    "    w1 = (l-c)/l\n",
    "    w0 = c/l\n",
    "    loss = -w1*y*torch.log(x+1e-6)-w0*(1-y)*torch.log(1-x+1e-6)\n",
    "    loss = loss.mean(-1)\n",
    "    return loss\n",
    "\n",
    "def weighted_CE_loss(x,y):\n",
    "    weight = 1/(y.detach().float().mean(0)+1e-9)\n",
    "    weighted_CE = nn.CrossEntropyLoss(weight=weight)\n",
    "#     atom_weights = (atom_weights-min(atom_weights))/(max(atom_weights)-min(atom_weights))\n",
    "    return weighted_CE(x, torch.argmax(y,-1))\n",
    "\n",
    "def generate_loss_function(refer_atom_list, x_atom, validity_mask, atom_list):\n",
    "    [a,b,c] = x_atom.shape\n",
    "    reconstruction_loss = 0\n",
    "    counter = 0\n",
    "    validity_mask = torch.from_numpy(validity_mask).cuda()\n",
    "    for i in range(a):\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        reconstruction_loss += weighted_CE_loss(refer_atom_list[i,:l,:16], x_atom[i,:l,:16]) - \\\n",
    "                        ((validity_mask[i,:l]*torch.log(1-atom_list[i,:l,:16]+1e-9)).sum(-1)/(validity_mask[i,:l].sum(-1)+1e-9)).mean(-1).mean(-1)\n",
    "        counter += 1\n",
    "    reconstruction_loss = reconstruction_loss/counter\n",
    "    return reconstruction_loss\n",
    "\n",
    "\n",
    "def train(model, amodel, gmodel, dataset, test_df, optimizer_list, loss_function, epoch):\n",
    "    model.train()\n",
    "    amodel.train()\n",
    "    gmodel.train()\n",
    "    optimizer, optimizer_AFSE, optimizer_GRN = optimizer_list\n",
    "    np.random.seed(epoch)\n",
    "    max_len = np.max([len(dataset),len(test_df)])\n",
    "    valList = np.arange(0,max_len)\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, max_len, batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[batch%len(dataset),:]\n",
    "        batch_test = test_df.loc[batch%len(test_df),:]\n",
    "        global_step = epoch * len(batch_list) + counter\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        smiles_list_test = batch_test.cano_smiles.values\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        x_atom_test, x_bonds_test, x_atom_index_test, x_bond_index_test, x_mask_test, smiles_to_rdkit_list_test = get_smiles_array(smiles_list_test,feature_dicts)\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                  torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),\n",
    "                                                  mol_feature=mol_feature,activated_features=activated_features.detach())\n",
    "        \n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        \n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        eps_adv, d_adv, vat_loss, mol_prediction, conv_lr, punish_lr = perturb_feature(mol_feature, amodel, alpha=1, \n",
    "                                                                                       lamda=10**-learning_rate, output_lr=True, \n",
    "                                                                                       output_plr=True, y=torch.Tensor(y_val).view(-1,1)) # 10**-learning_rate     \n",
    "        regression_loss = loss_function(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "        atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "                                      torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/1e-6,activated_features=activated_features.detach())\n",
    "        success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(smiles_list, x_atom, \n",
    "                            bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "                                                     refer_atom_list, refer_bond_list,topn=1)\n",
    "        reconstruction_loss = generate_loss_function(refer_atom_list, x_atom, validity_mask, atom_list)\n",
    "        x_atom_test = torch.Tensor(x_atom_test)\n",
    "        x_bonds_test = torch.Tensor(x_bonds_test)\n",
    "        x_bond_index_test = torch.cuda.LongTensor(x_bond_index_test)\n",
    "        \n",
    "        bond_neighbor_test = [x_bonds_test[i][x_bond_index_test[i]] for i in range(len(batch_test))]\n",
    "        bond_neighbor_test = torch.stack(bond_neighbor_test, dim=0)\n",
    "        activated_features_test, mol_feature_test = model(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "                                                          torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),\n",
    "                                                          torch.Tensor(x_mask_test),output_activated_features=True)\n",
    "#         mol_feature_test = torch.div(mol_feature_test, torch.norm(mol_feature_test, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features_test = torch.div(activated_features_test, torch.norm(activated_features_test, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_test, d_test, test_vat_loss, mol_prediction_test = perturb_feature(mol_feature_test, amodel, \n",
    "                                                                                    alpha=1, lamda=10**-learning_rate)\n",
    "        atom_list_test, bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),torch.cuda.LongTensor(x_atom_index_test),\n",
    "                                                torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "                                                mol_feature=mol_feature_test+d_test/1e-6,activated_features=activated_features_test.detach())\n",
    "        refer_atom_list_test, refer_bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "                                                            torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "                                                            mol_feature=mol_feature_test,activated_features=activated_features_test.detach())\n",
    "        success_smiles_batch_test, modified_smiles_test, success_batch_test, total_batch_test, reconstruction_test, validity_test, validity_mask_test = modify_atoms(smiles_list_test, x_atom_test, \n",
    "                            bond_neighbor_test, atom_list_test, bond_list_test,smiles_list_test,smiles_to_rdkit_list_test,\n",
    "                                                     refer_atom_list_test, refer_bond_list_test,topn=1)\n",
    "        test_reconstruction_loss = generate_loss_function(atom_list_test, x_atom_test, validity_mask_test, atom_list_test)\n",
    "        \n",
    "        if vat_loss>1 or test_vat_loss>1:\n",
    "            vat_loss = 1*(vat_loss/(vat_loss+1e-6).item())\n",
    "            test_vat_loss = 1*(test_vat_loss/(test_vat_loss+1e-6).item())\n",
    "        \n",
    "        logger.add_scalar('loss/regression', regression_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE', vat_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE_test', test_vat_loss, global_step)\n",
    "        logger.add_scalar('loss/GRN', reconstruction_loss, global_step)\n",
    "        logger.add_scalar('loss/GRN_test', test_reconstruction_loss, global_step)\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_AFSE.zero_grad()\n",
    "        optimizer_GRN.zero_grad()\n",
    "        loss =  regression_loss + 0.6 * (vat_loss + test_vat_loss) + reconstruction_loss + test_reconstruction_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_AFSE.step()\n",
    "        optimizer_GRN.step()\n",
    "\n",
    "        \n",
    "def clear_atom_map(mol):\n",
    "    [a.ClearProp('molAtomMapNumber') for a  in mol.GetAtoms()]\n",
    "    return mol\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "        \n",
    "def modify_atoms(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list,refer_atom_list, refer_bond_list,topn=1,viz=False):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    refer_atom_list = refer_atom_list.cpu().detach().numpy()\n",
    "    refer_bond_list = refer_bond_list.cpu().detach().numpy()\n",
    "    atom_symbol_sorted = np.argsort(x_atom[:,:,:16], axis=-1)\n",
    "    atom_symbol_generated_sorted = np.argsort(atom_list[:,:,:16], axis=-1)\n",
    "    generate_confidence_sorted = np.sort(atom_list[:,:,:16], axis=-1)\n",
    "    modified_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    confidence_threshold = 0.001\n",
    "    validity_mask = np.zeros_like(atom_list[:,:,:16])\n",
    "    symbol_list = ['B','C','N','O','F','Si','P','S','Cl','As','Se','Br','Te','I','At','other']\n",
    "    symbol_to_rdkit = [4,6,7,8,9,14,15,16,17,33,34,35,52,53,85,0]\n",
    "    for i in range(len(atom_list)):\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        first_run_flag = True\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "        mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "        counter = 0\n",
    "        for j in range(l): \n",
    "            if mol.GetAtomWithIdx(int(smiles_to_rdkit_list[cano_smiles][j])).GetAtomicNum() == \\\n",
    "                symbol_to_rdkit[refer_atom_list[i,j,:16].argmax(-1)]:\n",
    "                counter += 1\n",
    "#             print(f'atom#{smiles_to_rdkit_list[cano_smiles][j]}(f):',{symbol_list[k]: np.around(refer_atom_list[i,j,k],3) for k in range(16)},\n",
    "#                   f'\\natom#{smiles_to_rdkit_list[cano_smiles][j]}(f+d):',{symbol_list[k]: np.around(atom_list[i,j,k],3) for k in range(16)},\n",
    "#                  '\\n------------------------------------------------------------------------------------------------------------')\n",
    "#         print('预测为每个原子的平均概率：\\n',np.around(atom_list[i,:l,:16].mean(1),2))\n",
    "#         print('预测为每个原子的最大概率：\\n',np.around(atom_list[i,:l,:16].max(1),2))\n",
    "        if counter == l:\n",
    "            success_reconstruction += 1\n",
    "        while not flag==topn:\n",
    "            if rank == 16:\n",
    "                rank = 0\n",
    "                top_idx += 1\n",
    "            if top_idx == l:\n",
    "#                 print('没有满足条件的分子生成。')\n",
    "                flag += 1\n",
    "                continue\n",
    "#             if np.sum((atom_symbol_sorted[i,:l,-1]!=atom_symbol_generated_sorted[i,:l,-1-rank]).astype(int))==0:\n",
    "#                 print(f'根据预测的第{rank}大概率的原子构成的分子与原分子一致，原子位重置为0，生成下一个元素……')\n",
    "#                 rank += 1\n",
    "#                 top_idx = 0\n",
    "#                 generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "#                                              x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "#             print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            if rank == 0:\n",
    "                generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "                                             x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "            atom_symbol_generated = np.argsort(atom_list[i,generate_index,:16]-\\\n",
    "                                                    refer_atom_list[i,generate_index,:16] -\\\n",
    "                                                    x_atom[i,generate_index,:16])[-1-rank]\n",
    "            if atom_symbol_generated==x_atom[i,generate_index,:16].argmax(-1):\n",
    "#                 print('生成了相同元素，生成下一个元素……')\n",
    "                rank += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            if np.sort(atom_list[i,generate_index,:16]-\\\n",
    "                refer_atom_list[i,generate_index,:16] -\\\n",
    "                x_atom[i,generate_index,:16])[-1-rank]<confidence_threshold:\n",
    "#                 print(f'原子位{generate_rdkit_index}生成{symbol_list[atom_symbol_generated]}元素的置信度小于{confidence_threshold}，寻找下一个原子位……')\n",
    "                top_idx += 1\n",
    "                rank = 0\n",
    "                continue\n",
    "#             if symbol_to_rdkit[atom_symbol_generated]==6:\n",
    "#                 print('生成了不推荐的C元素')\n",
    "#                 rank += 1\n",
    "#                 continue\n",
    "            mol.GetAtomWithIdx(int(generate_rdkit_index)).SetAtomicNum(symbol_to_rdkit[atom_symbol_generated])\n",
    "            print_mol = mol\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                if first_run_flag == True:\n",
    "                    success_validity += 1\n",
    "                total[flag] += 1\n",
    "                if Chem.MolToSmiles(clear_atom_map(print_mol))==y_smiles[i]:\n",
    "                    success[flag] +=1\n",
    "#                     print('Congratulations!', success, total)\n",
    "                    success_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "#                 print(\"修改前的分子：\", smiles[i])\n",
    "#                 display(mol_init)\n",
    "                modified_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 print(f\"将第{generate_rdkit_index}个原子修改为{symbol_list[atom_symbol_generated]}的分子：\", Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 display(mol_with_atom_index(mol))\n",
    "                mol_y = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "#                 print(\"高活性分子：\", y_smiles[i])\n",
    "#                 display(mol_y)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "#                 print(f\"第{generate_rdkit_index}个原子符号修改为{symbol_list[atom_symbol_generated]}不符合规范，生成下一个元素……\")\n",
    "                validity_mask[i,generate_index,atom_symbol_generated] = 1\n",
    "                rank += 1\n",
    "                first_run_flag = False\n",
    "    return success_smiles, modified_smiles, success, total, success_reconstruction, success_validity, validity_mask\n",
    "\n",
    "def modify_bonds(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    modified_smiles = []\n",
    "    for i in range(len(bond_neighbor)):\n",
    "        l = (bond_neighbor[i].sum(-1).sum(-1)!=0).sum(-1)\n",
    "        bond_type_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        bond_type_generated_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        generate_confidence_sorted = np.sort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        while not flag==3:\n",
    "            cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "            if np.sum((bond_type_sorted[i,:,-1]!=bond_type_generated_sorted[:,:,-1-rank]).astype(int))==0:\n",
    "                rank += 1\n",
    "                top_idx = 0\n",
    "            print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            bond_type = bond_type_sorted[i,:,-1]\n",
    "            bond_type_generated = bond_type_generated_sorted[:,:,-1-rank]\n",
    "            generate_confidence = generate_confidence_sorted[:,:,-1-rank]\n",
    "#             print(np.sort(generate_confidence + \\\n",
    "#                                     (atom_symbol!=atom_symbol_generated).astype(int), axis=-1))\n",
    "            generate_index = np.argsort(generate_confidence + \n",
    "                                (bond_type!=bond_type_generated).astype(int), axis=-1)[-1-top_idx]\n",
    "            bond_type_generated_one = bond_type_generated[generate_index]\n",
    "            mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "            if generate_index >= len(smiles_to_rdkit_list[cano_smiles]):\n",
    "                top_idx += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            mol.GetBondWithIdx(int(generate_rdkit_index)).SetBondType(bond_type_generated_one)\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "                print(\"修改前的分子：\")\n",
    "                display(mol_init)\n",
    "                modified_smiles.append(mol)\n",
    "                print(f\"将第{generate_rdkit_index}个键修改为{atom_symbol_generated}的分子：\")\n",
    "                display(mol)\n",
    "                mol = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "                print(\"高活性分子：\")\n",
    "                display(mol)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "                print(f\"第{generate_rdkit_index}个原子符号修改为{atom_symbol_generated}不符合规范\")\n",
    "                top_idx += 1\n",
    "    return modified_smiles\n",
    "        \n",
    "def eval(model, amodel, gmodel, dataset, topn=1, output_feature=False, generate=False, modify_atom=True,return_GRN_loss=False, viz=False):\n",
    "    model.eval()\n",
    "    amodel.eval()\n",
    "    gmodel.eval()\n",
    "    predict_list = []\n",
    "    test_MSE_list = []\n",
    "    r2_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    feature_list = []\n",
    "    d_list = []\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    generated_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    reconstruction_loss, one_hot_loss, interger_loss, binary_loss = [0,0,0,0]\n",
    "    \n",
    "# #     取dataset中排序后的第k个\n",
    "#     sorted_dataset = dataset.sort_values(by=tasks[0],ascending=False)\n",
    "#     k_df = sorted_dataset.iloc[[k-1]]\n",
    "#     k_smiles = k_df['cano_smiles'].values\n",
    "#     k_value = k_df[tasks[0]].values.astype(float)    \n",
    "    \n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch) \n",
    "#     print(batch_list)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "#         print(type(batch))\n",
    "        batch_df = dataset.loc[batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        matched_smiles_list = smiles_list\n",
    "#         print(batch_df)\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "#         print(type(y_val))\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(matched_smiles_list,feature_dicts)\n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        lamda=10**-learning_rate\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_adv, d_adv, vat_loss, mol_prediction = perturb_feature(mol_feature, amodel, alpha=1, lamda=lamda)\n",
    "#         print(mol_feature,d_adv)\n",
    "        atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),\n",
    "                                      torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "                                      torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/(1e-6),activated_features=activated_features)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),mol_feature=mol_feature,activated_features=activated_features)\n",
    "        if generate:\n",
    "            if modify_atom:\n",
    "                success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(matched_smiles_list, x_atom, \n",
    "                            bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "                                                     refer_atom_list, refer_bond_list,topn=topn,viz=viz)\n",
    "            else:\n",
    "                modified_smiles = modify_bonds(matched_smiles_list, x_atom, bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list)\n",
    "            generated_smiles.extend(modified_smiles)\n",
    "            success_smiles.extend(success_smiles_batch)\n",
    "#             for n in range(topn):\n",
    "#                 success[n] += success_batch[n]\n",
    "#                 total[n] += total_batch[n]\n",
    "#                 print('congratulations:',success,total)\n",
    "            success_reconstruction += reconstruction\n",
    "            success_validity += validity\n",
    "            reconstruction_loss, one_hot_loss, interger_loss, binary_loss = generate_loss_function(refer_atom_list, x_atom, refer_bond_list, bond_neighbor, validity_mask, atom_list, bond_list)\n",
    "        d = d_adv.cpu().detach().numpy().tolist()\n",
    "        d_list.extend(d)\n",
    "        mol_feature_output = mol_feature.cpu().detach().numpy().tolist()\n",
    "        feature_list.extend(mol_feature_output)\n",
    "#         MAE = F.l1_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')   \n",
    "#         print(type(mol_prediction))\n",
    "        \n",
    "        MSE = F.mse_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')\n",
    "#         r2 = caculate_r2(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "# #         r2_list.extend(r2.cpu().detach().numpy())\n",
    "#         if r2!=r2:\n",
    "#             r2 = torch.tensor(0)\n",
    "#         r2_list.append(r2.item())\n",
    "#         predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         print(x_mask[:2],atoms_prediction.shape, mol_prediction,MSE)\n",
    "        predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         test_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n",
    "        test_MSE_list.extend(MSE.data.view(-1,1).cpu().numpy())\n",
    "#     print(r2_list)\n",
    "    if generate:\n",
    "        generated_num = len(generated_smiles)\n",
    "        eval_num = len(dataset)\n",
    "        unique = generated_num\n",
    "        novelty = generated_num\n",
    "        for i in range(generated_num):\n",
    "            for j in range(generated_num-i-1):\n",
    "                if generated_smiles[i]==generated_smiles[i+j+1]:\n",
    "                    unique -= 1\n",
    "            for k in range(eval_num):\n",
    "                if generated_smiles[i]==dataset['smiles'].values[k]:\n",
    "                    novelty -= 1\n",
    "        unique_rate = unique/(generated_num+1e-9)\n",
    "        novelty_rate = novelty/(generated_num+1e-9)\n",
    "#         print(f'successfully/total generated molecules =', {f'Top-{i+1}': f'{success[i]}/{total[i]}' for i in range(topn)})\n",
    "        return success_reconstruction/len(dataset), success_validity/len(dataset), unique_rate, novelty_rate, success_smiles, generated_smiles, caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    if return_GRN_loss:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list,reconstruction_loss, one_hot_loss, interger_loss,binary_loss\n",
    "    if output_feature:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    return caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "\n",
    "epoch = 0\n",
    "max_epoch = 1000\n",
    "batch_size = 10\n",
    "patience = 30\n",
    "stopper = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_model.pth')\n",
    "stopper_afse = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_amodel.pth')\n",
    "stopper_generate = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_gmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log/0_GAFSE_Ki_P29275_1_400_run_0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "now = datetime.datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "if os.path.isdir(log_dir):\n",
    "    for files in os.listdir(log_dir):\n",
    "        os.remove(log_dir+\"/\"+files)\n",
    "    os.rmdir(log_dir)\n",
    "logger = SummaryWriter(log_dir)\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2561932/3510960041.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  y = torch.FloatTensor(y).reshape(-1,1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Step: 107 Index:-1.3108 R2:0.1394 0.1013 0.1046 RMSE:1.1163 1.1020 1.1548 Tau:-0.2483 -0.2088 -0.0846\n",
      "Epoch: 2 Step: 214 Index:-0.6038 R2:0.2121 0.1910 0.1648 RMSE:0.9278 0.9094 0.9893 Tau:0.3135 0.3056 0.1959\n",
      "Epoch: 3 Step: 321 Index:-0.5432 R2:0.2461 0.2391 0.1730 RMSE:0.8903 0.8789 0.9763 Tau:0.3421 0.3357 0.2295\n",
      "Epoch: 4 Step: 428 Index:-0.5093 R2:0.2584 0.2505 0.1787 RMSE:0.8745 0.8465 0.9570 Tau:0.3495 0.3373 0.2331\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 5 Step: 535 Index:-0.5133 R2:0.2730 0.2671 0.1904 RMSE:0.8745 0.8643 0.9668 Tau:0.3616 0.3511 0.2452\n",
      "Epoch: 6 Step: 642 Index:-0.4653 R2:0.2867 0.2839 0.2001 RMSE:0.8447 0.8238 0.9382 Tau:0.3732 0.3584 0.2496\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 7 Step: 749 Index:-0.4765 R2:0.3020 0.2955 0.2150 RMSE:0.8520 0.8464 0.9513 Tau:0.3867 0.3699 0.2618\n",
      "Epoch: 8 Step: 856 Index:-0.4429 R2:0.3189 0.3106 0.2274 RMSE:0.8318 0.8226 0.9317 Tau:0.4009 0.3797 0.2711\n",
      "Epoch: 9 Step: 963 Index:-0.4208 R2:0.3331 0.3183 0.2410 RMSE:0.8249 0.8036 0.9162 Tau:0.4089 0.3828 0.2762\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 10 Step: 1070 Index:-0.4442 R2:0.3578 0.3427 0.2683 RMSE:0.8389 0.8415 0.9363 Tau:0.4280 0.3973 0.2952\n",
      "Epoch: 11 Step: 1177 Index:-0.4046 R2:0.3633 0.3319 0.2676 RMSE:0.8120 0.7978 0.9030 Tau:0.4283 0.3931 0.2957\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 12 Step: 1284 Index:-0.4324 R2:0.3900 0.3528 0.2967 RMSE:0.8228 0.8384 0.9223 Tau:0.4484 0.4060 0.3156\n",
      "Epoch: 13 Step: 1391 Index:-0.3722 R2:0.4051 0.3682 0.3100 RMSE:0.7969 0.7809 0.8817 Tau:0.4533 0.4088 0.3273\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 14 Step: 1498 Index:-0.4460 R2:0.4037 0.3514 0.3063 RMSE:0.8254 0.8499 0.9267 Tau:0.4538 0.4038 0.3274\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 15 Step: 1605 Index:-0.3952 R2:0.4160 0.3580 0.3179 RMSE:0.7854 0.8034 0.8853 Tau:0.4615 0.4081 0.3380\n",
      "Epoch: 16 Step: 1712 Index:-0.3598 R2:0.4367 0.3797 0.3408 RMSE:0.7674 0.7761 0.8616 Tau:0.4732 0.4162 0.3535\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 17 Step: 1819 Index:-0.3835 R2:0.4381 0.3786 0.3402 RMSE:0.7782 0.8005 0.8788 Tau:0.4747 0.4170 0.3523\n",
      "Epoch: 18 Step: 1926 Index:-0.3431 R2:0.4426 0.3908 0.3483 RMSE:0.7628 0.7614 0.8522 Tau:0.4747 0.4182 0.3529\n",
      "Epoch: 19 Step: 2033 Index:-0.3323 R2:0.4566 0.3908 0.3574 RMSE:0.7419 0.7583 0.8406 Tau:0.4849 0.4260 0.3659\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 20 Step: 2140 Index:-0.3553 R2:0.4608 0.3878 0.3608 RMSE:0.7464 0.7828 0.8526 Tau:0.4873 0.4275 0.3687\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 21 Step: 2247 Index:-0.3563 R2:0.4678 0.3933 0.3670 RMSE:0.7454 0.7841 0.8526 Tau:0.4900 0.4278 0.3665\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 22 Step: 2354 Index:-0.3453 R2:0.4765 0.3985 0.3712 RMSE:0.7367 0.7734 0.8453 Tau:0.4951 0.4281 0.3739\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 23 Step: 2461 Index:-0.3345 R2:0.4752 0.3874 0.3625 RMSE:0.7272 0.7639 0.8378 Tau:0.4952 0.4294 0.3674\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 24 Step: 2568 Index:-0.3522 R2:0.4838 0.3965 0.3701 RMSE:0.7342 0.7849 0.8522 Tau:0.5015 0.4327 0.3772\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 25 Step: 2675 Index:-0.3476 R2:0.4792 0.3915 0.3564 RMSE:0.7280 0.7811 0.8546 Tau:0.4985 0.4335 0.3699\n",
      "Epoch: 26 Step: 2782 Index:-0.3248 R2:0.4930 0.4039 0.3821 RMSE:0.7176 0.7602 0.8298 Tau:0.5061 0.4354 0.3818\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 27 Step: 2889 Index:-0.3445 R2:0.4852 0.3905 0.3614 RMSE:0.7185 0.7747 0.8464 Tau:0.5002 0.4302 0.3692\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 28 Step: 2996 Index:-0.3270 R2:0.5007 0.3981 0.3840 RMSE:0.7158 0.7605 0.8284 Tau:0.5104 0.4335 0.3897\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 29 Step: 3103 Index:-0.3351 R2:0.4975 0.3894 0.3722 RMSE:0.7092 0.7653 0.8319 Tau:0.5088 0.4302 0.3763\n",
      "Epoch: 30 Step: 3210 Index:-0.3188 R2:0.5068 0.4028 0.3968 RMSE:0.7070 0.7515 0.8140 Tau:0.5123 0.4327 0.3799\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 31 Step: 3317 Index:-0.3320 R2:0.5045 0.3987 0.3767 RMSE:0.7114 0.7649 0.8371 Tau:0.5127 0.4329 0.3903\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 32 Step: 3424 Index:-0.3226 R2:0.5148 0.4028 0.3912 RMSE:0.6968 0.7577 0.8205 Tau:0.5177 0.4351 0.3853\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 33 Step: 3531 Index:-0.3426 R2:0.5124 0.3900 0.3806 RMSE:0.7200 0.7730 0.8366 Tau:0.5185 0.4304 0.3868\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 34 Step: 3638 Index:-0.3217 R2:0.5190 0.4097 0.4057 RMSE:0.7025 0.7591 0.8176 Tau:0.5189 0.4374 0.3895\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 35 Step: 3745 Index:-0.3346 R2:0.5195 0.4034 0.4125 RMSE:0.7013 0.7640 0.8123 Tau:0.5177 0.4294 0.3854\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 36 Step: 3852 Index:-0.3289 R2:0.5257 0.3946 0.4031 RMSE:0.6908 0.7598 0.8099 Tau:0.5245 0.4310 0.3898\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 37 Step: 3959 Index:-0.3217 R2:0.5258 0.4049 0.4052 RMSE:0.6892 0.7588 0.8109 Tau:0.5244 0.4370 0.3858\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 38 Step: 4066 Index:-0.3623 R2:0.5305 0.4059 0.4102 RMSE:0.7124 0.7966 0.8410 Tau:0.5262 0.4343 0.3880\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 39 Step: 4173 Index:-0.3525 R2:0.5342 0.4075 0.4172 RMSE:0.7110 0.7875 0.8334 Tau:0.5276 0.4350 0.4066\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 40 Step: 4280 Index:-0.3580 R2:0.5330 0.4020 0.4229 RMSE:0.7126 0.7887 0.8272 Tau:0.5254 0.4307 0.4018\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch: 41 Step: 4387 Index:-0.3450 R2:0.5382 0.3975 0.4107 RMSE:0.6836 0.7771 0.8170 Tau:0.5312 0.4321 0.3900\n",
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch: 42 Step: 4494 Index:-0.4005 R2:0.5357 0.4052 0.4224 RMSE:0.7584 0.8324 0.8761 Tau:0.5251 0.4319 0.3942\n",
      "EarlyStopping counter: 13 out of 30\n",
      "Epoch: 43 Step: 4601 Index:-0.3298 R2:0.5423 0.4019 0.4107 RMSE:0.6793 0.7655 0.8126 Tau:0.5349 0.4357 0.4046\n",
      "EarlyStopping counter: 14 out of 30\n",
      "Epoch: 44 Step: 4708 Index:-0.3295 R2:0.5449 0.3941 0.4151 RMSE:0.6774 0.7612 0.8018 Tau:0.5352 0.4317 0.3979\n",
      "EarlyStopping counter: 15 out of 30\n",
      "Epoch: 45 Step: 4815 Index:-0.3831 R2:0.5460 0.3929 0.4160 RMSE:0.7680 0.8184 0.8610 Tau:0.5360 0.4354 0.3905\n",
      "EarlyStopping counter: 16 out of 30\n",
      "Epoch: 46 Step: 4922 Index:-0.3345 R2:0.5511 0.4006 0.4281 RMSE:0.6823 0.7675 0.8044 Tau:0.5365 0.4330 0.4040\n",
      "EarlyStopping counter: 17 out of 30\n",
      "Epoch: 47 Step: 5029 Index:-0.4029 R2:0.5526 0.4014 0.4086 RMSE:0.7501 0.8424 0.8897 Tau:0.5409 0.4395 0.4098\n",
      "EarlyStopping counter: 18 out of 30\n",
      "Epoch: 48 Step: 5136 Index:-0.3221 R2:0.5547 0.4021 0.4226 RMSE:0.6916 0.7632 0.8066 Tau:0.5404 0.4411 0.3885\n",
      "EarlyStopping counter: 19 out of 30\n",
      "Epoch: 49 Step: 5243 Index:-0.3204 R2:0.5557 0.4033 0.4160 RMSE:0.6663 0.7616 0.8038 Tau:0.5443 0.4412 0.4048\n",
      "EarlyStopping counter: 20 out of 30\n",
      "Epoch: 50 Step: 5350 Index:-0.3428 R2:0.5504 0.3938 0.4063 RMSE:0.6811 0.7772 0.8240 Tau:0.5405 0.4344 0.3974\n",
      "Epoch: 51 Step: 5457 Index:-0.3188 R2:0.5578 0.4109 0.4347 RMSE:0.6651 0.7589 0.7919 Tau:0.5413 0.4401 0.3929\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 52 Step: 5564 Index:-0.3294 R2:0.5563 0.4040 0.4240 RMSE:0.6684 0.7670 0.8016 Tau:0.5413 0.4376 0.3946\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 53 Step: 5671 Index:-0.3229 R2:0.5620 0.4047 0.4243 RMSE:0.6727 0.7650 0.8027 Tau:0.5455 0.4421 0.3939\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 54 Step: 5778 Index:-0.3971 R2:0.5691 0.4196 0.4341 RMSE:0.7513 0.8439 0.8838 Tau:0.5496 0.4468 0.4044\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 55 Step: 5885 Index:-0.3420 R2:0.5642 0.4057 0.4338 RMSE:0.6769 0.7820 0.8145 Tau:0.5449 0.4400 0.4011\n",
      "Epoch: 56 Step: 5992 Index:-0.3012 R2:0.5750 0.4144 0.4440 RMSE:0.6594 0.7456 0.7820 Tau:0.5541 0.4444 0.4149\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 57 Step: 6099 Index:-0.3159 R2:0.5748 0.4159 0.4406 RMSE:0.6586 0.7575 0.7938 Tau:0.5536 0.4416 0.4199\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 58 Step: 6206 Index:-0.3133 R2:0.5747 0.4123 0.4410 RMSE:0.6614 0.7577 0.7930 Tau:0.5565 0.4444 0.4214\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 59 Step: 6313 Index:-0.3188 R2:0.5767 0.4184 0.4398 RMSE:0.6557 0.7676 0.7996 Tau:0.5553 0.4488 0.4027\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 60 Step: 6420 Index:-0.3104 R2:0.5850 0.4273 0.4494 RMSE:0.6573 0.7602 0.7954 Tau:0.5597 0.4499 0.4095\n",
      "Epoch: 61 Step: 6527 Index:-0.3000 R2:0.5853 0.4204 0.4491 RMSE:0.6480 0.7457 0.7790 Tau:0.5600 0.4456 0.3989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 62 Step: 6634 Index:-0.3633 R2:0.5920 0.4266 0.4522 RMSE:0.7043 0.8113 0.8429 Tau:0.5642 0.4480 0.4145\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 63 Step: 6741 Index:-0.3082 R2:0.5832 0.4151 0.4409 RMSE:0.6467 0.7617 0.7915 Tau:0.5580 0.4535 0.3975\n",
      "Epoch: 64 Step: 6848 Index:-0.2967 R2:0.5818 0.4103 0.4268 RMSE:0.6527 0.7480 0.7943 Tau:0.5621 0.4513 0.4169\n",
      "Epoch: 65 Step: 6955 Index:-0.2903 R2:0.5932 0.4263 0.4539 RMSE:0.6555 0.7443 0.7813 Tau:0.5662 0.4540 0.4169\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 66 Step: 7062 Index:-0.3373 R2:0.5912 0.4315 0.4675 RMSE:0.6932 0.7889 0.8186 Tau:0.5609 0.4516 0.4279\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 67 Step: 7169 Index:-0.2993 R2:0.5929 0.4245 0.4602 RMSE:0.6432 0.7467 0.7737 Tau:0.5640 0.4474 0.4207\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 68 Step: 7276 Index:-0.2964 R2:0.6009 0.4278 0.4609 RMSE:0.6321 0.7456 0.7724 Tau:0.5692 0.4492 0.4159\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 69 Step: 7383 Index:-0.3080 R2:0.5946 0.4315 0.4544 RMSE:0.6449 0.7613 0.7936 Tau:0.5645 0.4533 0.4106\n",
      "Epoch: 70 Step: 7490 Index:-0.2868 R2:0.6000 0.4261 0.4505 RMSE:0.6365 0.7437 0.7804 Tau:0.5699 0.4569 0.4162\n",
      "Epoch: 71 Step: 7597 Index:-0.2867 R2:0.6058 0.4361 0.4658 RMSE:0.6386 0.7478 0.7777 Tau:0.5752 0.4611 0.4302\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 72 Step: 7704 Index:-0.3236 R2:0.5982 0.4264 0.4567 RMSE:0.6554 0.7755 0.8029 Tau:0.5667 0.4520 0.4213\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 73 Step: 7811 Index:-0.3523 R2:0.6036 0.4425 0.4670 RMSE:0.6922 0.8126 0.8366 Tau:0.5720 0.4603 0.4274\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 74 Step: 7918 Index:-0.2968 R2:0.6049 0.4411 0.4746 RMSE:0.6656 0.7572 0.7900 Tau:0.5720 0.4604 0.4305\n",
      "Epoch: 75 Step: 8025 Index:-0.2770 R2:0.6155 0.4535 0.4854 RMSE:0.6385 0.7430 0.7728 Tau:0.5770 0.4660 0.4310\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 76 Step: 8132 Index:-0.2963 R2:0.6145 0.4492 0.4823 RMSE:0.6504 0.7582 0.7846 Tau:0.5783 0.4619 0.4266\n",
      "Epoch: 77 Step: 8239 Index:-0.2720 R2:0.6168 0.4461 0.4732 RMSE:0.6422 0.7389 0.7730 Tau:0.5798 0.4669 0.4256\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 78 Step: 8346 Index:-0.3272 R2:0.6105 0.4393 0.4761 RMSE:0.6621 0.7850 0.8074 Tau:0.5727 0.4578 0.4278\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 79 Step: 8453 Index:-0.2789 R2:0.6130 0.4413 0.4700 RMSE:0.6331 0.7436 0.7776 Tau:0.5762 0.4648 0.4345\n",
      "Epoch: 80 Step: 8560 Index:-0.2596 R2:0.6179 0.4439 0.4769 RMSE:0.6239 0.7296 0.7619 Tau:0.5795 0.4701 0.4377\n",
      "Epoch: 81 Step: 8667 Index:-0.2502 R2:0.6303 0.4518 0.4766 RMSE:0.6241 0.7230 0.7610 Tau:0.5888 0.4728 0.4300\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 82 Step: 8774 Index:-0.2709 R2:0.6299 0.4530 0.4824 RMSE:0.6182 0.7380 0.7679 Tau:0.5890 0.4672 0.4365\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 83 Step: 8881 Index:-0.2616 R2:0.6358 0.4604 0.4842 RMSE:0.6210 0.7359 0.7716 Tau:0.5929 0.4743 0.4384\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 84 Step: 8988 Index:-0.2914 R2:0.6249 0.4607 0.4908 RMSE:0.6478 0.7610 0.7875 Tau:0.5848 0.4696 0.4403\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 85 Step: 9095 Index:-0.2781 R2:0.6284 0.4488 0.4669 RMSE:0.6398 0.7532 0.7928 Tau:0.5887 0.4751 0.4319\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 86 Step: 9202 Index:-0.2757 R2:0.6289 0.4536 0.4759 RMSE:0.6281 0.7432 0.7833 Tau:0.5866 0.4675 0.4241\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 87 Step: 9309 Index:-0.2664 R2:0.6356 0.4629 0.4856 RMSE:0.6194 0.7392 0.7732 Tau:0.5907 0.4728 0.4316\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 88 Step: 9416 Index:-0.2797 R2:0.6409 0.4585 0.4814 RMSE:0.6290 0.7548 0.7905 Tau:0.5941 0.4751 0.4391\n",
      "Epoch: 89 Step: 9523 Index:-0.2476 R2:0.6460 0.4584 0.4850 RMSE:0.6158 0.7242 0.7601 Tau:0.6008 0.4766 0.4424\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 90 Step: 9630 Index:-0.2520 R2:0.6382 0.4595 0.4886 RMSE:0.6174 0.7305 0.7640 Tau:0.5925 0.4785 0.4462\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 91 Step: 9737 Index:-0.2864 R2:0.6042 0.4511 0.4778 RMSE:0.6578 0.7551 0.7894 Tau:0.5758 0.4686 0.4408\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 92 Step: 9844 Index:-0.3366 R2:0.6322 0.4635 0.4911 RMSE:0.6965 0.8072 0.8381 Tau:0.5897 0.4706 0.4488\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 93 Step: 9951 Index:-0.2764 R2:0.6346 0.4646 0.4910 RMSE:0.6351 0.7469 0.7817 Tau:0.5908 0.4705 0.4335\n",
      "Epoch: 94 Step: 10058 Index:-0.2458 R2:0.6464 0.4750 0.5036 RMSE:0.6108 0.7255 0.7565 Tau:0.5991 0.4797 0.4494\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 95 Step: 10165 Index:-0.3022 R2:0.6409 0.4674 0.4940 RMSE:0.6606 0.7777 0.8107 Tau:0.5939 0.4755 0.4484\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 96 Step: 10272 Index:-0.2467 R2:0.6409 0.4546 0.4702 RMSE:0.6000 0.7241 0.7675 Tau:0.5956 0.4773 0.4362\n",
      "Epoch: 97 Step: 10379 Index:-0.2432 R2:0.6489 0.4715 0.4871 RMSE:0.6088 0.7275 0.7715 Tau:0.6021 0.4843 0.4450\n",
      "Epoch: 98 Step: 10486 Index:-0.2273 R2:0.6578 0.4737 0.5062 RMSE:0.5998 0.7078 0.7402 Tau:0.6065 0.4805 0.4474\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 99 Step: 10593 Index:-0.2283 R2:0.6562 0.4771 0.5017 RMSE:0.5968 0.7094 0.7460 Tau:0.6064 0.4811 0.4505\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 100 Step: 10700 Index:-0.2751 R2:0.6594 0.4791 0.4957 RMSE:0.6466 0.7642 0.8032 Tau:0.6081 0.4891 0.4514\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 101 Step: 10807 Index:-0.2615 R2:0.6510 0.4782 0.5088 RMSE:0.6228 0.7383 0.7703 Tau:0.5996 0.4768 0.4515\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 102 Step: 10914 Index:-0.2467 R2:0.6400 0.4599 0.4837 RMSE:0.6007 0.7176 0.7553 Tau:0.5959 0.4708 0.4252\n",
      "Epoch: 103 Step: 11021 Index:-0.2087 R2:0.6595 0.4924 0.5176 RMSE:0.5937 0.6994 0.7348 Tau:0.6072 0.4907 0.4525\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 104 Step: 11128 Index:-0.2320 R2:0.6663 0.4860 0.5021 RMSE:0.6003 0.7209 0.7627 Tau:0.6121 0.4889 0.4543\n",
      "Epoch: 105 Step: 11235 Index:-0.2072 R2:0.6719 0.4925 0.5152 RMSE:0.5747 0.6981 0.7334 Tau:0.6166 0.4910 0.4578\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 106 Step: 11342 Index:-0.2116 R2:0.6628 0.4837 0.5102 RMSE:0.5816 0.7010 0.7365 Tau:0.6100 0.4895 0.4557\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 107 Step: 11449 Index:-0.2453 R2:0.6585 0.4726 0.4969 RMSE:0.6008 0.7308 0.7690 Tau:0.6067 0.4855 0.4544\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 108 Step: 11556 Index:-0.2333 R2:0.6686 0.4900 0.5104 RMSE:0.6034 0.7288 0.7650 Tau:0.6130 0.4955 0.4528\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 109 Step: 11663 Index:-0.2158 R2:0.6653 0.4831 0.5071 RMSE:0.5890 0.7105 0.7472 Tau:0.6153 0.4946 0.4690\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 110 Step: 11770 Index:-0.2201 R2:0.6792 0.4959 0.5179 RMSE:0.5915 0.7151 0.7516 Tau:0.6213 0.4950 0.4635\n",
      "Epoch: 111 Step: 11877 Index:-0.1930 R2:0.6807 0.4933 0.5039 RMSE:0.5739 0.6960 0.7419 Tau:0.6261 0.5030 0.4631\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 112 Step: 11984 Index:-0.2008 R2:0.6756 0.4876 0.4991 RMSE:0.5710 0.6980 0.7441 Tau:0.6212 0.4972 0.4595\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 113 Step: 12091 Index:-0.1958 R2:0.6792 0.5015 0.5177 RMSE:0.5706 0.6954 0.7360 Tau:0.6216 0.4996 0.4621\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 114 Step: 12198 Index:-0.2386 R2:0.6827 0.4901 0.5140 RMSE:0.6057 0.7330 0.7666 Tau:0.6238 0.4944 0.4626\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 115 Step: 12305 Index:-0.2298 R2:0.6735 0.4916 0.5116 RMSE:0.6039 0.7258 0.7660 Tau:0.6165 0.4960 0.4629\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 116 Step: 12412 Index:-0.2521 R2:0.6687 0.4831 0.4940 RMSE:0.6278 0.7433 0.7840 Tau:0.6140 0.4912 0.4666\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 117 Step: 12519 Index:-0.1942 R2:0.6892 0.5002 0.5096 RMSE:0.5742 0.6956 0.7427 Tau:0.6290 0.5014 0.4629\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 118 Step: 12626 Index:-0.1970 R2:0.6813 0.4958 0.5119 RMSE:0.5645 0.6938 0.7358 Tau:0.6229 0.4968 0.4620\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 119 Step: 12733 Index:-0.2249 R2:0.6739 0.4931 0.5084 RMSE:0.5842 0.7143 0.7569 Tau:0.6171 0.4895 0.4576\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 120 Step: 12840 Index:-0.2458 R2:0.6810 0.4909 0.5050 RMSE:0.5947 0.7288 0.7732 Tau:0.6214 0.4831 0.4605\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 121 Step: 12947 Index:-0.2771 R2:0.6848 0.4909 0.5190 RMSE:0.6531 0.7696 0.7988 Tau:0.6248 0.4925 0.4660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch: 122 Step: 13054 Index:-0.2283 R2:0.6873 0.4928 0.5047 RMSE:0.6011 0.7342 0.7745 Tau:0.6305 0.5059 0.4689\n",
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch: 123 Step: 13161 Index:-0.1960 R2:0.6823 0.4946 0.5119 RMSE:0.5684 0.6916 0.7332 Tau:0.6230 0.4956 0.4675\n",
      "EarlyStopping counter: 13 out of 30\n",
      "Epoch: 124 Step: 13268 Index:-0.1974 R2:0.6979 0.4964 0.5112 RMSE:0.5568 0.6974 0.7386 Tau:0.6350 0.5000 0.4629\n",
      "Epoch: 125 Step: 13375 Index:-0.1896 R2:0.6946 0.5016 0.5271 RMSE:0.5628 0.6864 0.7215 Tau:0.6308 0.4968 0.4650\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 126 Step: 13482 Index:-0.1954 R2:0.6962 0.4909 0.5075 RMSE:0.5579 0.6935 0.7362 Tau:0.6332 0.4982 0.4643\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 127 Step: 13589 Index:-0.2068 R2:0.6986 0.5049 0.5105 RMSE:0.5677 0.7080 0.7574 Tau:0.6335 0.5011 0.4655\n",
      "Epoch: 128 Step: 13696 Index:-0.1872 R2:0.6977 0.4950 0.5077 RMSE:0.5584 0.6922 0.7363 Tau:0.6354 0.5050 0.4657\n",
      "Epoch: 129 Step: 13803 Index:-0.1828 R2:0.6965 0.5093 0.5202 RMSE:0.5513 0.6883 0.7332 Tau:0.6344 0.5055 0.4657\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 130 Step: 13910 Index:-0.2232 R2:0.6878 0.4829 0.4908 RMSE:0.5642 0.7065 0.7548 Tau:0.6295 0.4833 0.4565\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 131 Step: 14017 Index:-0.2217 R2:0.6996 0.5022 0.5285 RMSE:0.5651 0.7153 0.7434 Tau:0.6349 0.4936 0.4660\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 132 Step: 14124 Index:-0.1835 R2:0.7096 0.5072 0.5252 RMSE:0.5459 0.6839 0.7250 Tau:0.6419 0.5004 0.4658\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 133 Step: 14231 Index:-0.1917 R2:0.7037 0.5078 0.5241 RMSE:0.5690 0.7027 0.7486 Tau:0.6385 0.5110 0.4708\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 134 Step: 14338 Index:-0.2253 R2:0.7077 0.4939 0.5145 RMSE:0.5706 0.7217 0.7539 Tau:0.6387 0.4964 0.4628\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 135 Step: 14445 Index:-0.1923 R2:0.7131 0.5085 0.5201 RMSE:0.5578 0.6995 0.7419 Tau:0.6454 0.5072 0.4666\n",
      "Epoch: 136 Step: 14552 Index:-0.1711 R2:0.7116 0.5153 0.5202 RMSE:0.5386 0.6833 0.7341 Tau:0.6437 0.5122 0.4680\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 137 Step: 14659 Index:-0.1857 R2:0.7108 0.4929 0.5060 RMSE:0.5564 0.6931 0.7402 Tau:0.6468 0.5074 0.4636\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 138 Step: 14766 Index:-0.1915 R2:0.6992 0.4982 0.5086 RMSE:0.5504 0.6956 0.7387 Tau:0.6375 0.5041 0.4684\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 139 Step: 14873 Index:-0.1998 R2:0.6922 0.5132 0.5120 RMSE:0.5663 0.6997 0.7607 Tau:0.6280 0.4999 0.4654\n",
      "Epoch: 140 Step: 14980 Index:-0.1606 R2:0.7171 0.5218 0.5239 RMSE:0.5335 0.6745 0.7286 Tau:0.6474 0.5139 0.4672\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 141 Step: 15087 Index:-0.1915 R2:0.7101 0.5208 0.5246 RMSE:0.5573 0.7041 0.7526 Tau:0.6434 0.5126 0.4715\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 142 Step: 15194 Index:-0.1998 R2:0.7169 0.5104 0.5128 RMSE:0.5537 0.7062 0.7574 Tau:0.6509 0.5063 0.4726\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 143 Step: 15301 Index:-0.2701 R2:0.6619 0.4671 0.4601 RMSE:0.6279 0.7550 0.8071 Tau:0.6058 0.4849 0.4550\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 144 Step: 15408 Index:-0.1768 R2:0.7209 0.5103 0.5062 RMSE:0.5313 0.6866 0.7436 Tau:0.6514 0.5098 0.4659\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 145 Step: 15515 Index:-0.1687 R2:0.7223 0.5224 0.5289 RMSE:0.5432 0.6824 0.7287 Tau:0.6516 0.5138 0.4701\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 146 Step: 15622 Index:-0.1616 R2:0.7160 0.5245 0.5273 RMSE:0.5337 0.6749 0.7282 Tau:0.6447 0.5133 0.4728\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 147 Step: 15729 Index:-0.1728 R2:0.7269 0.5310 0.5221 RMSE:0.5413 0.6898 0.7474 Tau:0.6529 0.5169 0.4615\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 148 Step: 15836 Index:-0.1826 R2:0.7264 0.5220 0.5365 RMSE:0.5378 0.6934 0.7335 Tau:0.6523 0.5108 0.4761\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 149 Step: 15943 Index:-0.2229 R2:0.7165 0.5256 0.5218 RMSE:0.5974 0.7342 0.7805 Tau:0.6480 0.5113 0.4675\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 150 Step: 16050 Index:-0.1711 R2:0.7144 0.5199 0.4996 RMSE:0.5389 0.6767 0.7506 Tau:0.6472 0.5055 0.4635\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch: 151 Step: 16157 Index:-0.1749 R2:0.7171 0.5347 0.5292 RMSE:0.5584 0.6922 0.7555 Tau:0.6466 0.5172 0.4636\n",
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch: 152 Step: 16264 Index:-0.1664 R2:0.7312 0.5212 0.5236 RMSE:0.5235 0.6753 0.7264 Tau:0.6582 0.5089 0.4642\n",
      "Epoch: 153 Step: 16371 Index:-0.1419 R2:0.7339 0.5491 0.5342 RMSE:0.5282 0.6691 0.7356 Tau:0.6593 0.5271 0.4696\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 154 Step: 16478 Index:-0.1766 R2:0.7362 0.5343 0.5273 RMSE:0.5324 0.6961 0.7534 Tau:0.6598 0.5195 0.4701\n",
      "Epoch: 155 Step: 16585 Index:-0.1419 R2:0.7350 0.5310 0.5253 RMSE:0.5217 0.6686 0.7251 Tau:0.6623 0.5267 0.4703\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 156 Step: 16692 Index:-0.1572 R2:0.7376 0.5295 0.5280 RMSE:0.5328 0.6763 0.7333 Tau:0.6622 0.5191 0.4646\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 157 Step: 16799 Index:-0.1657 R2:0.7402 0.5348 0.5374 RMSE:0.5317 0.6841 0.7316 Tau:0.6636 0.5184 0.4737\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 158 Step: 16906 Index:-0.1506 R2:0.7323 0.5348 0.5381 RMSE:0.5184 0.6670 0.7194 Tau:0.6574 0.5164 0.4736\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 159 Step: 17013 Index:-0.1849 R2:0.7321 0.5220 0.5203 RMSE:0.5276 0.6909 0.7443 Tau:0.6562 0.5060 0.4633\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 160 Step: 17120 Index:-0.1905 R2:0.7244 0.5180 0.5095 RMSE:0.5443 0.7016 0.7624 Tau:0.6544 0.5112 0.4670\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 161 Step: 17227 Index:-0.1514 R2:0.7445 0.5453 0.5382 RMSE:0.5175 0.6733 0.7331 Tau:0.6673 0.5220 0.4738\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 162 Step: 17334 Index:-0.1476 R2:0.7395 0.5339 0.5257 RMSE:0.5208 0.6702 0.7285 Tau:0.6650 0.5227 0.4723\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 163 Step: 17441 Index:-0.1577 R2:0.7391 0.5240 0.5234 RMSE:0.5149 0.6737 0.7291 Tau:0.6631 0.5161 0.4729\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 164 Step: 17548 Index:-0.1489 R2:0.7449 0.5486 0.5368 RMSE:0.5200 0.6772 0.7377 Tau:0.6676 0.5283 0.4807\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 165 Step: 17655 Index:-0.1601 R2:0.7373 0.5425 0.5361 RMSE:0.5343 0.6842 0.7375 Tau:0.6636 0.5242 0.4800\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch: 166 Step: 17762 Index:-0.1553 R2:0.7353 0.5415 0.5275 RMSE:0.5287 0.6754 0.7421 Tau:0.6597 0.5201 0.4764\n",
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch: 167 Step: 17869 Index:-0.1493 R2:0.7455 0.5505 0.5334 RMSE:0.5201 0.6768 0.7423 Tau:0.6672 0.5275 0.4814\n",
      "EarlyStopping counter: 13 out of 30\n",
      "Epoch: 168 Step: 17976 Index:-0.2068 R2:0.7470 0.5338 0.5372 RMSE:0.5642 0.7237 0.7675 Tau:0.6691 0.5169 0.4831\n",
      "Epoch: 169 Step: 18083 Index:-0.1364 R2:0.7520 0.5456 0.5388 RMSE:0.4994 0.6599 0.7185 Tau:0.6723 0.5234 0.4810\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 170 Step: 18190 Index:-0.1925 R2:0.7586 0.5505 0.5265 RMSE:0.5573 0.7174 0.7832 Tau:0.6802 0.5249 0.4826\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 171 Step: 18297 Index:-0.1528 R2:0.7481 0.5470 0.5355 RMSE:0.5091 0.6794 0.7410 Tau:0.6701 0.5266 0.4730\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 172 Step: 18404 Index:-0.1564 R2:0.7416 0.5434 0.5313 RMSE:0.5218 0.6816 0.7414 Tau:0.6662 0.5252 0.4768\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 173 Step: 18511 Index:-0.1392 R2:0.7536 0.5508 0.5288 RMSE:0.5008 0.6621 0.7310 Tau:0.6766 0.5228 0.4833\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 174 Step: 18618 Index:-0.1471 R2:0.7425 0.5440 0.5187 RMSE:0.5268 0.6715 0.7473 Tau:0.6626 0.5243 0.4697\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 175 Step: 18725 Index:-0.1486 R2:0.7446 0.5524 0.5485 RMSE:0.5336 0.6833 0.7378 Tau:0.6670 0.5347 0.4851\n",
      "Epoch: 176 Step: 18832 Index:-0.1199 R2:0.7616 0.5450 0.5337 RMSE:0.4997 0.6557 0.7160 Tau:0.6798 0.5358 0.4871\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 177 Step: 18939 Index:-0.1478 R2:0.7510 0.5418 0.5236 RMSE:0.5042 0.6708 0.7383 Tau:0.6743 0.5230 0.4824\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 178 Step: 19046 Index:-0.1416 R2:0.7330 0.5378 0.5213 RMSE:0.5215 0.6664 0.7349 Tau:0.6579 0.5248 0.4749\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 179 Step: 19153 Index:-0.1416 R2:0.7614 0.5535 0.5363 RMSE:0.5073 0.6747 0.7432 Tau:0.6810 0.5330 0.4889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 180 Step: 19260 Index:-0.1248 R2:0.7688 0.5481 0.5257 RMSE:0.4889 0.6592 0.7274 Tau:0.6884 0.5344 0.4814\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 181 Step: 19367 Index:-0.1359 R2:0.7633 0.5438 0.5260 RMSE:0.4956 0.6613 0.7296 Tau:0.6839 0.5254 0.4783\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 182 Step: 19474 Index:-0.1577 R2:0.7636 0.5556 0.5335 RMSE:0.5144 0.6875 0.7561 Tau:0.6842 0.5299 0.4943\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 183 Step: 19581 Index:-0.1677 R2:0.7413 0.5411 0.5231 RMSE:0.5162 0.6813 0.7514 Tau:0.6651 0.5136 0.4832\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 184 Step: 19688 Index:-0.1728 R2:0.7545 0.5209 0.5062 RMSE:0.4989 0.6774 0.7467 Tau:0.6788 0.5046 0.4740\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 185 Step: 19795 Index:-0.1300 R2:0.7744 0.5563 0.5358 RMSE:0.4935 0.6603 0.7320 Tau:0.6924 0.5303 0.4884\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 186 Step: 19902 Index:-0.1295 R2:0.7675 0.5425 0.5254 RMSE:0.4875 0.6589 0.7257 Tau:0.6861 0.5293 0.4822\n",
      "Epoch: 187 Step: 20009 Index:-0.1154 R2:0.7590 0.5515 0.5244 RMSE:0.4934 0.6527 0.7310 Tau:0.6804 0.5373 0.4785\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 188 Step: 20116 Index:-0.2423 R2:0.7454 0.5364 0.5221 RMSE:0.6207 0.7727 0.8257 Tau:0.6684 0.5304 0.4872\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 189 Step: 20223 Index:-0.1243 R2:0.7715 0.5511 0.5247 RMSE:0.4812 0.6543 0.7294 Tau:0.6927 0.5300 0.4795\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 190 Step: 20330 Index:-0.1199 R2:0.7793 0.5570 0.5269 RMSE:0.4710 0.6572 0.7347 Tau:0.6978 0.5372 0.4867\n",
      "Epoch: 191 Step: 20437 Index:-0.0891 R2:0.7800 0.5720 0.5429 RMSE:0.4775 0.6357 0.7102 Tau:0.6958 0.5465 0.4877\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 192 Step: 20544 Index:-0.1428 R2:0.7777 0.5472 0.5327 RMSE:0.4914 0.6803 0.7416 Tau:0.6948 0.5375 0.4850\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 193 Step: 20651 Index:-0.1325 R2:0.7707 0.5532 0.5304 RMSE:0.4816 0.6561 0.7301 Tau:0.6881 0.5236 0.4809\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 194 Step: 20758 Index:-0.1198 R2:0.7887 0.5745 0.5422 RMSE:0.4868 0.6614 0.7399 Tau:0.7038 0.5416 0.4943\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 195 Step: 20865 Index:-0.1185 R2:0.7654 0.5515 0.5233 RMSE:0.4932 0.6541 0.7293 Tau:0.6858 0.5356 0.4856\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 196 Step: 20972 Index:-0.1005 R2:0.7744 0.5675 0.5374 RMSE:0.4830 0.6430 0.7217 Tau:0.6894 0.5425 0.4881\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 197 Step: 21079 Index:-0.1643 R2:0.7812 0.5589 0.5288 RMSE:0.5203 0.7020 0.7739 Tau:0.7000 0.5377 0.4885\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 198 Step: 21186 Index:-0.1319 R2:0.7804 0.5656 0.5425 RMSE:0.4974 0.6729 0.7384 Tau:0.6965 0.5410 0.4934\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 199 Step: 21293 Index:-0.1389 R2:0.7689 0.5574 0.5355 RMSE:0.4879 0.6701 0.7506 Tau:0.6869 0.5312 0.4893\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 200 Step: 21400 Index:-0.1293 R2:0.7842 0.5655 0.5456 RMSE:0.4827 0.6642 0.7374 Tau:0.6983 0.5349 0.4972\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 201 Step: 21507 Index:-0.1170 R2:0.7721 0.5669 0.5465 RMSE:0.4885 0.6531 0.7301 Tau:0.6877 0.5361 0.4877\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch: 202 Step: 21614 Index:-0.1027 R2:0.7923 0.5694 0.5391 RMSE:0.4590 0.6425 0.7238 Tau:0.7061 0.5398 0.4872\n",
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch: 203 Step: 21721 Index:-0.1249 R2:0.7935 0.5672 0.5388 RMSE:0.4860 0.6667 0.7393 Tau:0.7069 0.5418 0.4920\n",
      "EarlyStopping counter: 13 out of 30\n",
      "Epoch: 204 Step: 21828 Index:-0.1183 R2:0.7799 0.5532 0.5216 RMSE:0.4824 0.6643 0.7402 Tau:0.6969 0.5460 0.4836\n",
      "EarlyStopping counter: 14 out of 30\n",
      "Epoch: 205 Step: 21935 Index:-0.1076 R2:0.7858 0.5708 0.5362 RMSE:0.4665 0.6457 0.7245 Tau:0.7025 0.5381 0.4877\n",
      "Epoch: 206 Step: 22042 Index:-0.0872 R2:0.7895 0.5748 0.5375 RMSE:0.4688 0.6384 0.7191 Tau:0.7031 0.5511 0.4990\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 207 Step: 22149 Index:-0.1083 R2:0.7834 0.5662 0.5435 RMSE:0.4710 0.6492 0.7255 Tau:0.7005 0.5409 0.4941\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 208 Step: 22256 Index:-0.0957 R2:0.7957 0.5734 0.5398 RMSE:0.4522 0.6399 0.7230 Tau:0.7110 0.5442 0.4918\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 209 Step: 22363 Index:-0.0976 R2:0.7917 0.5829 0.5496 RMSE:0.4648 0.6424 0.7266 Tau:0.7058 0.5449 0.4951\n",
      "Epoch: 210 Step: 22470 Index:-0.0848 R2:0.7988 0.5837 0.5473 RMSE:0.4517 0.6344 0.7212 Tau:0.7130 0.5496 0.4978\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 211 Step: 22577 Index:-0.1064 R2:0.7937 0.5787 0.5468 RMSE:0.4727 0.6511 0.7317 Tau:0.7079 0.5447 0.4944\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 212 Step: 22684 Index:-0.0866 R2:0.8000 0.5760 0.5456 RMSE:0.4491 0.6395 0.7188 Tau:0.7124 0.5529 0.4919\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 213 Step: 22791 Index:-0.1108 R2:0.7856 0.5575 0.5280 RMSE:0.4665 0.6488 0.7269 Tau:0.7058 0.5380 0.4783\n",
      "Epoch: 214 Step: 22898 Index:-0.0786 R2:0.7984 0.5897 0.5603 RMSE:0.4494 0.6291 0.7096 Tau:0.7109 0.5505 0.4995\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 215 Step: 23005 Index:-0.0841 R2:0.7918 0.5681 0.5365 RMSE:0.4675 0.6400 0.7213 Tau:0.7065 0.5559 0.4916\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 216 Step: 23112 Index:-0.0974 R2:0.7953 0.5781 0.5507 RMSE:0.4651 0.6445 0.7214 Tau:0.7084 0.5471 0.5023\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 217 Step: 23219 Index:-0.0869 R2:0.8016 0.5811 0.5425 RMSE:0.4524 0.6385 0.7242 Tau:0.7144 0.5516 0.4898\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 218 Step: 23326 Index:-0.0836 R2:0.7998 0.5896 0.5448 RMSE:0.4554 0.6357 0.7292 Tau:0.7136 0.5521 0.4928\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 219 Step: 23433 Index:-0.1164 R2:0.7925 0.5708 0.5343 RMSE:0.4585 0.6548 0.7472 Tau:0.7079 0.5384 0.4935\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 220 Step: 23540 Index:-0.1553 R2:0.7823 0.5793 0.5251 RMSE:0.5253 0.6972 0.7972 Tau:0.6990 0.5420 0.4870\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 221 Step: 23647 Index:-0.1582 R2:0.7412 0.5265 0.4830 RMSE:0.5962 0.7018 0.7814 Tau:0.6690 0.5436 0.4683\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 222 Step: 23754 Index:-0.0995 R2:0.7986 0.5699 0.5434 RMSE:0.4569 0.6457 0.7175 Tau:0.7106 0.5463 0.4982\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 223 Step: 23861 Index:-0.1076 R2:0.7937 0.5767 0.5375 RMSE:0.4541 0.6374 0.7256 Tau:0.7072 0.5298 0.4946\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 224 Step: 23968 Index:-0.1180 R2:0.7991 0.5680 0.5360 RMSE:0.4600 0.6537 0.7345 Tau:0.7129 0.5357 0.5036\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch: 225 Step: 24075 Index:-0.1202 R2:0.8086 0.5828 0.5372 RMSE:0.4826 0.6691 0.7633 Tau:0.7212 0.5489 0.5008\n",
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch: 226 Step: 24182 Index:-0.0799 R2:0.8092 0.5876 0.5408 RMSE:0.4404 0.6293 0.7242 Tau:0.7194 0.5494 0.4979\n",
      "EarlyStopping counter: 13 out of 30\n",
      "Epoch: 227 Step: 24289 Index:-0.0821 R2:0.8103 0.5820 0.5468 RMSE:0.4419 0.6338 0.7166 Tau:0.7208 0.5517 0.5034\n",
      "EarlyStopping counter: 14 out of 30\n",
      "Epoch: 228 Step: 24396 Index:-0.1076 R2:0.8004 0.5867 0.5507 RMSE:0.4969 0.6573 0.7418 Tau:0.7107 0.5497 0.4872\n",
      "EarlyStopping counter: 15 out of 30\n",
      "Epoch: 229 Step: 24503 Index:-0.0858 R2:0.8089 0.5872 0.5536 RMSE:0.4407 0.6392 0.7231 Tau:0.7185 0.5534 0.5008\n",
      "EarlyStopping counter: 16 out of 30\n",
      "Epoch: 230 Step: 24610 Index:-0.0976 R2:0.8067 0.5771 0.5359 RMSE:0.4493 0.6406 0.7282 Tau:0.7170 0.5430 0.4976\n",
      "EarlyStopping counter: 17 out of 30\n",
      "Epoch: 231 Step: 24717 Index:-0.0794 R2:0.8173 0.5851 0.5396 RMSE:0.4437 0.6372 0.7248 Tau:0.7268 0.5578 0.4960\n",
      "EarlyStopping counter: 18 out of 30\n",
      "Epoch: 232 Step: 24824 Index:-0.1059 R2:0.8066 0.5722 0.5459 RMSE:0.4398 0.6442 0.7231 Tau:0.7175 0.5383 0.5036\n",
      "EarlyStopping counter: 19 out of 30\n",
      "Epoch: 233 Step: 24931 Index:-0.1078 R2:0.8078 0.5722 0.5459 RMSE:0.4546 0.6552 0.7333 Tau:0.7172 0.5474 0.4996\n",
      "EarlyStopping counter: 20 out of 30\n",
      "Epoch: 234 Step: 25038 Index:-0.0991 R2:0.8131 0.5771 0.5616 RMSE:0.4564 0.6496 0.7165 Tau:0.7237 0.5506 0.5079\n",
      "EarlyStopping counter: 21 out of 30\n",
      "Epoch: 235 Step: 25145 Index:-0.1275 R2:0.8065 0.5595 0.5402 RMSE:0.4550 0.6611 0.7367 Tau:0.7196 0.5336 0.5091\n",
      "EarlyStopping counter: 22 out of 30\n",
      "Epoch: 236 Step: 25252 Index:-0.1050 R2:0.8241 0.5837 0.5509 RMSE:0.4483 0.6590 0.7414 Tau:0.7326 0.5539 0.5058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 23 out of 30\n",
      "Epoch: 237 Step: 25359 Index:-0.0936 R2:0.8161 0.5781 0.5458 RMSE:0.4295 0.6385 0.7219 Tau:0.7256 0.5449 0.4996\n",
      "EarlyStopping counter: 24 out of 30\n",
      "Epoch: 238 Step: 25466 Index:-0.1164 R2:0.8143 0.5679 0.5434 RMSE:0.4332 0.6546 0.7340 Tau:0.7243 0.5382 0.5048\n",
      "Epoch: 239 Step: 25573 Index:-0.0722 R2:0.8200 0.5859 0.5382 RMSE:0.4292 0.6261 0.7203 Tau:0.7341 0.5539 0.5027\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 240 Step: 25680 Index:-0.0906 R2:0.8228 0.5916 0.5440 RMSE:0.4548 0.6524 0.7395 Tau:0.7335 0.5618 0.5071\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 241 Step: 25787 Index:-0.1172 R2:0.8152 0.5614 0.5380 RMSE:0.4387 0.6588 0.7344 Tau:0.7279 0.5415 0.5019\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 242 Step: 25894 Index:-0.1295 R2:0.8232 0.5854 0.5477 RMSE:0.4810 0.6798 0.7679 Tau:0.7328 0.5502 0.5009\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 243 Step: 26001 Index:-0.1042 R2:0.7986 0.5743 0.5434 RMSE:0.4809 0.6478 0.7226 Tau:0.7172 0.5436 0.4955\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 244 Step: 26108 Index:-0.1358 R2:0.8057 0.5605 0.5443 RMSE:0.4676 0.6770 0.7475 Tau:0.7183 0.5412 0.5151\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 245 Step: 26215 Index:-0.1082 R2:0.8183 0.5688 0.5355 RMSE:0.4292 0.6492 0.7365 Tau:0.7314 0.5409 0.5088\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 246 Step: 26322 Index:-0.1028 R2:0.8176 0.5751 0.5470 RMSE:0.4576 0.6612 0.7397 Tau:0.7293 0.5584 0.5083\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 247 Step: 26429 Index:-0.1182 R2:0.8222 0.5720 0.5343 RMSE:0.4543 0.6593 0.7445 Tau:0.7339 0.5410 0.5037\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 248 Step: 26536 Index:-0.1316 R2:0.8130 0.5819 0.5598 RMSE:0.5064 0.6868 0.7590 Tau:0.7190 0.5552 0.5089\n",
      "Epoch: 249 Step: 26643 Index:-0.0689 R2:0.8308 0.5933 0.5562 RMSE:0.4181 0.6286 0.7131 Tau:0.7389 0.5597 0.5100\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 250 Step: 26750 Index:-0.1138 R2:0.8298 0.5837 0.5530 RMSE:0.4438 0.6663 0.7438 Tau:0.7381 0.5524 0.5116\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 251 Step: 26857 Index:-0.0893 R2:0.8205 0.5778 0.5419 RMSE:0.4275 0.6394 0.7273 Tau:0.7303 0.5501 0.5065\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 252 Step: 26964 Index:-0.1207 R2:0.8157 0.5773 0.5362 RMSE:0.5106 0.6734 0.7487 Tau:0.7268 0.5527 0.4966\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 253 Step: 27071 Index:-0.0944 R2:0.8291 0.5940 0.5649 RMSE:0.4420 0.6556 0.7270 Tau:0.7360 0.5612 0.5104\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 254 Step: 27178 Index:-0.0820 R2:0.8307 0.5873 0.5668 RMSE:0.4199 0.6370 0.7105 Tau:0.7384 0.5550 0.5139\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 255 Step: 27285 Index:-0.0980 R2:0.8267 0.5863 0.5469 RMSE:0.4585 0.6568 0.7437 Tau:0.7340 0.5588 0.5058\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 256 Step: 27392 Index:-0.0756 R2:0.8345 0.5884 0.5609 RMSE:0.4130 0.6333 0.7143 Tau:0.7427 0.5577 0.5089\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 257 Step: 27499 Index:-0.0890 R2:0.8302 0.5973 0.5565 RMSE:0.4487 0.6504 0.7420 Tau:0.7401 0.5615 0.5108\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 258 Step: 27606 Index:-0.0928 R2:0.8272 0.5818 0.5580 RMSE:0.4187 0.6428 0.7198 Tau:0.7342 0.5500 0.5106\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 259 Step: 27713 Index:-0.0986 R2:0.8265 0.5721 0.5468 RMSE:0.4188 0.6411 0.7167 Tau:0.7386 0.5425 0.5070\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch: 260 Step: 27820 Index:-0.1177 R2:0.8322 0.5808 0.5629 RMSE:0.4429 0.6697 0.7413 Tau:0.7387 0.5520 0.5169\n",
      "Epoch: 261 Step: 27927 Index:-0.0654 R2:0.8365 0.5946 0.5640 RMSE:0.4087 0.6271 0.7068 Tau:0.7438 0.5616 0.5050\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 262 Step: 28034 Index:-0.0901 R2:0.8302 0.5808 0.5518 RMSE:0.4251 0.6426 0.7182 Tau:0.7377 0.5525 0.5149\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 263 Step: 28141 Index:-0.1829 R2:0.8055 0.5678 0.5436 RMSE:0.5098 0.7226 0.8073 Tau:0.7162 0.5397 0.5003\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 264 Step: 28248 Index:-0.0959 R2:0.8220 0.5769 0.5350 RMSE:0.4338 0.6343 0.7213 Tau:0.7335 0.5385 0.5036\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 265 Step: 28355 Index:-0.0940 R2:0.8362 0.5821 0.5581 RMSE:0.4342 0.6556 0.7309 Tau:0.7407 0.5616 0.5087\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 266 Step: 28462 Index:-0.0814 R2:0.8412 0.5957 0.5611 RMSE:0.4218 0.6434 0.7268 Tau:0.7454 0.5620 0.5040\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 267 Step: 28569 Index:-0.1074 R2:0.8258 0.5798 0.5352 RMSE:0.4274 0.6495 0.7391 Tau:0.7365 0.5421 0.5085\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 268 Step: 28676 Index:-0.0818 R2:0.8315 0.5851 0.5456 RMSE:0.4161 0.6357 0.7227 Tau:0.7425 0.5538 0.5084\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 269 Step: 28783 Index:-0.0714 R2:0.8400 0.6036 0.5688 RMSE:0.4223 0.6334 0.7214 Tau:0.7471 0.5620 0.5160\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 270 Step: 28890 Index:-0.0913 R2:0.8356 0.5966 0.5568 RMSE:0.4340 0.6506 0.7399 Tau:0.7416 0.5593 0.5111\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 271 Step: 28997 Index:-0.0972 R2:0.8420 0.5938 0.5689 RMSE:0.4400 0.6565 0.7385 Tau:0.7504 0.5594 0.5219\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch: 272 Step: 29104 Index:-0.1382 R2:0.8266 0.5786 0.5646 RMSE:0.4783 0.6903 0.7591 Tau:0.7347 0.5521 0.5205\n",
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch: 273 Step: 29211 Index:-0.0770 R2:0.8423 0.5810 0.5452 RMSE:0.4028 0.6323 0.7180 Tau:0.7509 0.5553 0.5042\n",
      "EarlyStopping counter: 13 out of 30\n",
      "Epoch: 274 Step: 29318 Index:-0.0814 R2:0.8459 0.5870 0.5603 RMSE:0.4088 0.6418 0.7230 Tau:0.7515 0.5604 0.5175\n",
      "EarlyStopping counter: 14 out of 30\n",
      "Epoch: 275 Step: 29425 Index:-0.0774 R2:0.8406 0.5836 0.5611 RMSE:0.4042 0.6355 0.7114 Tau:0.7499 0.5581 0.5110\n",
      "EarlyStopping counter: 15 out of 30\n",
      "Epoch: 276 Step: 29532 Index:-0.0942 R2:0.8297 0.5819 0.5407 RMSE:0.4184 0.6376 0.7350 Tau:0.7360 0.5434 0.5159\n",
      "EarlyStopping counter: 16 out of 30\n",
      "Epoch: 277 Step: 29639 Index:-0.1280 R2:0.8259 0.5656 0.5323 RMSE:0.4461 0.6691 0.7517 Tau:0.7341 0.5411 0.5081\n",
      "EarlyStopping counter: 17 out of 30\n",
      "Epoch: 278 Step: 29746 Index:-0.0790 R2:0.8440 0.5961 0.5473 RMSE:0.3994 0.6340 0.7321 Tau:0.7508 0.5550 0.5138\n",
      "EarlyStopping counter: 18 out of 30\n",
      "Epoch: 279 Step: 29853 Index:-0.0788 R2:0.8478 0.6050 0.5459 RMSE:0.4299 0.6429 0.7408 Tau:0.7551 0.5642 0.5045\n",
      "EarlyStopping counter: 19 out of 30\n",
      "Epoch: 280 Step: 29960 Index:-0.0655 R2:0.8398 0.5872 0.5620 RMSE:0.4109 0.6248 0.6975 Tau:0.7471 0.5593 0.5155\n",
      "Epoch: 281 Step: 30067 Index:-0.0613 R2:0.8509 0.5950 0.5558 RMSE:0.3990 0.6188 0.7029 Tau:0.7577 0.5575 0.5079\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 282 Step: 30174 Index:-0.0709 R2:0.8471 0.5921 0.5652 RMSE:0.4032 0.6345 0.7141 Tau:0.7520 0.5637 0.5177\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 283 Step: 30281 Index:-0.1176 R2:0.8471 0.5890 0.5511 RMSE:0.4287 0.6658 0.7591 Tau:0.7536 0.5482 0.5092\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 284 Step: 30388 Index:-0.0712 R2:0.8472 0.5908 0.5680 RMSE:0.4145 0.6352 0.7096 Tau:0.7520 0.5640 0.5202\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 285 Step: 30495 Index:-0.1439 R2:0.8157 0.5681 0.5425 RMSE:0.4689 0.6891 0.7650 Tau:0.7247 0.5452 0.5114\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 286 Step: 30602 Index:-0.0918 R2:0.8385 0.5715 0.5359 RMSE:0.4094 0.6387 0.7248 Tau:0.7452 0.5469 0.5099\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 287 Step: 30709 Index:-0.0981 R2:0.8455 0.5808 0.5538 RMSE:0.4017 0.6501 0.7345 Tau:0.7536 0.5520 0.5094\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 288 Step: 30816 Index:-0.1270 R2:0.8365 0.5715 0.5638 RMSE:0.4148 0.6667 0.7380 Tau:0.7405 0.5398 0.5113\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 289 Step: 30923 Index:-0.1176 R2:0.8431 0.5771 0.5689 RMSE:0.4081 0.6627 0.7323 Tau:0.7480 0.5451 0.5187\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 290 Step: 31030 Index:-0.1263 R2:0.8486 0.5912 0.5497 RMSE:0.4336 0.6774 0.7795 Tau:0.7538 0.5511 0.5174\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 291 Step: 31137 Index:-0.0642 R2:0.8570 0.5976 0.5559 RMSE:0.3786 0.6238 0.7181 Tau:0.7639 0.5596 0.5125\n",
      "Epoch: 292 Step: 31244 Index:-0.0496 R2:0.8470 0.5979 0.5573 RMSE:0.4001 0.6182 0.7075 Tau:0.7537 0.5687 0.5127\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch: 293 Step: 31351 Index:-0.1146 R2:0.8517 0.6074 0.5600 RMSE:0.4395 0.6752 0.7745 Tau:0.7541 0.5606 0.5142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch: 294 Step: 31458 Index:-0.1700 R2:0.8342 0.5773 0.5305 RMSE:0.4851 0.7081 0.7990 Tau:0.7402 0.5380 0.5230\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch: 295 Step: 31565 Index:-0.0518 R2:0.8503 0.6064 0.5623 RMSE:0.3873 0.6165 0.7113 Tau:0.7550 0.5647 0.5092\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch: 296 Step: 31672 Index:-0.1397 R2:0.8064 0.5621 0.5442 RMSE:0.4737 0.6692 0.7472 Tau:0.7185 0.5295 0.5003\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch: 297 Step: 31779 Index:-0.0682 R2:0.8364 0.5938 0.5642 RMSE:0.4241 0.6303 0.7128 Tau:0.7442 0.5621 0.5067\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch: 298 Step: 31886 Index:-0.0874 R2:0.8404 0.5792 0.5385 RMSE:0.4030 0.6390 0.7357 Tau:0.7479 0.5516 0.5117\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch: 299 Step: 31993 Index:-0.1719 R2:0.8343 0.5813 0.5431 RMSE:0.4923 0.7150 0.7980 Tau:0.7444 0.5431 0.5234\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch: 300 Step: 32100 Index:-0.0780 R2:0.8276 0.5681 0.5352 RMSE:0.4270 0.6446 0.7288 Tau:0.7369 0.5666 0.5118\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch: 301 Step: 32207 Index:-0.1253 R2:0.8506 0.5965 0.5653 RMSE:0.4487 0.6834 0.7743 Tau:0.7554 0.5581 0.5218\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch: 302 Step: 32314 Index:-0.0543 R2:0.8588 0.6000 0.5654 RMSE:0.3799 0.6177 0.7025 Tau:0.7615 0.5634 0.5170\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch: 303 Step: 32421 Index:-0.0620 R2:0.8518 0.5966 0.5460 RMSE:0.3859 0.6255 0.7284 Tau:0.7598 0.5635 0.5113\n",
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch: 304 Step: 32528 Index:-0.0591 R2:0.8647 0.6022 0.5641 RMSE:0.3739 0.6213 0.7102 Tau:0.7697 0.5623 0.5177\n",
      "EarlyStopping counter: 13 out of 30\n",
      "Epoch: 305 Step: 32635 Index:-0.0782 R2:0.8578 0.5939 0.5343 RMSE:0.3907 0.6390 0.7454 Tau:0.7638 0.5609 0.5139\n",
      "EarlyStopping counter: 14 out of 30\n",
      "Epoch: 306 Step: 32742 Index:-0.0944 R2:0.8531 0.5873 0.5433 RMSE:0.4111 0.6522 0.7505 Tau:0.7580 0.5579 0.5212\n",
      "EarlyStopping counter: 15 out of 30\n",
      "Epoch: 307 Step: 32849 Index:-0.0576 R2:0.8653 0.6017 0.5575 RMSE:0.3800 0.6246 0.7234 Tau:0.7723 0.5669 0.5213\n",
      "EarlyStopping counter: 16 out of 30\n",
      "Epoch: 308 Step: 32956 Index:-0.1487 R2:0.8480 0.5907 0.5675 RMSE:0.4771 0.7053 0.7886 Tau:0.7533 0.5566 0.5248\n",
      "EarlyStopping counter: 17 out of 30\n",
      "Epoch: 309 Step: 33063 Index:-0.0982 R2:0.8613 0.5873 0.5577 RMSE:0.4048 0.6552 0.7425 Tau:0.7670 0.5570 0.5279\n",
      "EarlyStopping counter: 18 out of 30\n",
      "Epoch: 310 Step: 33170 Index:-0.0891 R2:0.8685 0.6059 0.5609 RMSE:0.4242 0.6591 0.7520 Tau:0.7722 0.5701 0.5226\n",
      "EarlyStopping counter: 19 out of 30\n",
      "Epoch: 311 Step: 33277 Index:-0.0807 R2:0.8656 0.5889 0.5620 RMSE:0.3770 0.6386 0.7245 Tau:0.7704 0.5579 0.5170\n",
      "EarlyStopping counter: 20 out of 30\n",
      "Epoch: 312 Step: 33384 Index:-0.0832 R2:0.8662 0.5945 0.5502 RMSE:0.3932 0.6435 0.7377 Tau:0.7715 0.5603 0.5204\n",
      "EarlyStopping counter: 21 out of 30\n",
      "Epoch: 313 Step: 33491 Index:-0.1099 R2:0.8474 0.5942 0.5515 RMSE:0.4262 0.6644 0.7604 Tau:0.7509 0.5545 0.5124\n",
      "EarlyStopping counter: 22 out of 30\n",
      "Epoch: 314 Step: 33598 Index:-0.1203 R2:0.8481 0.5666 0.5533 RMSE:0.4479 0.6696 0.7289 Tau:0.7505 0.5493 0.5108\n",
      "EarlyStopping counter: 23 out of 30\n",
      "Epoch: 315 Step: 33705 Index:-0.0767 R2:0.8644 0.5891 0.5548 RMSE:0.4099 0.6422 0.7233 Tau:0.7716 0.5655 0.5165\n",
      "EarlyStopping counter: 24 out of 30\n",
      "Epoch: 316 Step: 33812 Index:-0.0998 R2:0.8601 0.5812 0.5336 RMSE:0.3848 0.6494 0.7471 Tau:0.7649 0.5495 0.5207\n",
      "EarlyStopping counter: 25 out of 30\n",
      "Epoch: 317 Step: 33919 Index:-0.0882 R2:0.8561 0.5819 0.5420 RMSE:0.3885 0.6420 0.7371 Tau:0.7606 0.5538 0.5175\n",
      "EarlyStopping counter: 26 out of 30\n",
      "Epoch: 318 Step: 34026 Index:-0.0831 R2:0.8630 0.5962 0.5475 RMSE:0.3715 0.6387 0.7484 Tau:0.7678 0.5557 0.5135\n",
      "EarlyStopping counter: 27 out of 30\n",
      "Epoch: 319 Step: 34133 Index:-0.0680 R2:0.8613 0.5989 0.5716 RMSE:0.3807 0.6344 0.7205 Tau:0.7652 0.5664 0.5157\n",
      "EarlyStopping counter: 28 out of 30\n",
      "Epoch: 320 Step: 34240 Index:-0.1257 R2:0.8393 0.5622 0.5178 RMSE:0.4017 0.6526 0.7514 Tau:0.7436 0.5270 0.5148\n",
      "EarlyStopping counter: 29 out of 30\n",
      "Epoch: 321 Step: 34347 Index:-0.0764 R2:0.8592 0.5900 0.5533 RMSE:0.3782 0.6373 0.7295 Tau:0.7679 0.5609 0.5157\n",
      "EarlyStopping counter: 30 out of 30\n",
      "Epoch: 322 Step: 34454 Index:-0.0573 R2:0.8649 0.6072 0.5583 RMSE:0.3692 0.6228 0.7278 Tau:0.7699 0.5655 0.5151\n"
     ]
    }
   ],
   "source": [
    "# train_f_list=[]\n",
    "# train_mse_list=[]\n",
    "# train_r2_list=[]\n",
    "# test_f_list=[]\n",
    "# test_mse_list=[]\n",
    "# test_r2_list=[]\n",
    "# val_f_list=[]\n",
    "# val_mse_list=[]\n",
    "# val_r2_list=[]\n",
    "# epoch_list=[]\n",
    "# train_predict_list=[]\n",
    "# test_predict_list=[]\n",
    "# val_predict_list=[]\n",
    "# train_y_list=[]\n",
    "# test_y_list=[]\n",
    "# val_y_list=[]\n",
    "# train_d_list=[]\n",
    "# test_d_list=[]\n",
    "# val_d_list=[]\n",
    "\n",
    "epoch = 0\n",
    "optimizer_list = [optimizer, optimizer_AFSE, optimizer_GRN]\n",
    "max_epoch = 1000\n",
    "while epoch < max_epoch:\n",
    "    train(model, amodel, gmodel, train_df, test_df, optimizer_list, loss_function, epoch)\n",
    "#     print(train_df.shape,test_df.shape)\n",
    "    train_d, train_f, train_r2, train_MSE, train_predict, reconstruction_loss, one_hot_loss, interger_loss,binary_loss = eval(model, amodel, gmodel, train_df,output_feature=True,return_GRN_loss=True)\n",
    "    train_predict = np.array(train_predict)\n",
    "    train_WTI = weighted_top_index(train_df, train_predict, len(train_df))\n",
    "    train_tau, _ = scipy.stats.kendalltau(train_predict,train_df[tasks[0]].values.astype(float).tolist())\n",
    "    val_d, val_f, val_r2, val_MSE, val_predict, val_reconstruction_loss, val_one_hot_loss, val_interger_loss,val_binary_loss = eval(model, amodel, gmodel, val_df,output_feature=True,return_GRN_loss=True)\n",
    "    val_predict = np.array(val_predict)\n",
    "    val_WTI = weighted_top_index(val_df, val_predict, len(val_df))\n",
    "    val_AP = AP(val_df, val_predict, len(val_df))\n",
    "    val_tau, _ = scipy.stats.kendalltau(val_predict,val_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "    test_d, test_f, test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df,output_feature=True)\n",
    "    test_predict = np.array(test_predict)\n",
    "    test_WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "#     test_AP = AP(test_df, test_predict, test_active)\n",
    "    test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    k_list = [int(len(test_df)*0.01),int(len(test_df)*0.03),int(len(test_df)*0.1),10,30,100]\n",
    "    topk_list =[]\n",
    "    false_positive_rate_list = []\n",
    "    for k in k_list:\n",
    "        a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "        topk_list.append(a)\n",
    "        false_positive_rate_list.append(b)\n",
    "    \n",
    "    epoch = epoch + 1\n",
    "    global_step = epoch * int(np.max([len(train_df),len(test_df)])/batch_size)\n",
    "    logger.add_scalar('val/WTI', val_WTI, global_step)\n",
    "    logger.add_scalar('val/AP', val_AP, global_step)\n",
    "    logger.add_scalar('val/r2', val_r2, global_step)\n",
    "    logger.add_scalar('val/RMSE', val_MSE**0.5, global_step)\n",
    "    logger.add_scalar('val/Tau', val_tau, global_step)\n",
    "#     logger.add_scalar('test/TAP', test_AP, global_step)\n",
    "    logger.add_scalar('test/r2', test_r2_a, global_step)\n",
    "    logger.add_scalar('test/RMSE', test_MSE_a**0.5, global_step)\n",
    "    logger.add_scalar('test/Tau', test_tau, global_step)\n",
    "    logger.add_scalar('val/GRN', reconstruction_loss, global_step)\n",
    "    logger.add_scalar('test/EF0.01', topk_list[0], global_step)\n",
    "    logger.add_scalar('test/EF0.03', topk_list[1], global_step)\n",
    "    logger.add_scalar('test/EF0.1', topk_list[2], global_step)\n",
    "    logger.add_scalar('test/EF10', topk_list[3], global_step)\n",
    "    logger.add_scalar('test/EF30', topk_list[4], global_step)\n",
    "    logger.add_scalar('test/EF100', topk_list[5], global_step)\n",
    "    \n",
    "#     train_mse_list.append(train_MSE**0.5)\n",
    "#     train_r2_list.append(train_r2)\n",
    "#     val_mse_list.append(val_MSE**0.5)  \n",
    "#     val_r2_list.append(val_r2)\n",
    "#     train_f_list.append(train_f)\n",
    "#     val_f_list.append(val_f)\n",
    "#     test_f_list.append(test_f)\n",
    "#     epoch_list.append(epoch)\n",
    "#     train_predict_list.append(train_predict.flatten())\n",
    "#     test_predict_list.append(test_predict.flatten())\n",
    "#     val_predict_list.append(val_predict.flatten())\n",
    "#     train_y_list.append(train_df[tasks[0]].values)\n",
    "#     val_y_list.append(val_df[tasks[0]].values)\n",
    "#     test_y_list.append(test_df[tasks[0]].values)\n",
    "#     train_d_list.append(train_d)\n",
    "#     val_d_list.append(val_d)\n",
    "#     test_d_list.append(test_d)\n",
    "\n",
    "    stop_index = - val_MSE**0.5 + val_tau\n",
    "    early_stop = stopper.step(stop_index, model)\n",
    "    early_stop = stopper_afse.step(stop_index, amodel, if_print=False)\n",
    "    early_stop = stopper_generate.step(stop_index, gmodel, if_print=False)\n",
    "#     print('epoch {:d}/{:d}, validation {} {:.4f}, {} {:.4f},best validation {r2} {:.4f}'.format(epoch, total_epoch, 'r2', val_r2, 'mse:',val_MSE, stopper.best_score))\n",
    "    print('Epoch:',epoch, 'Step:', global_step, 'Index:%.4f'%stop_index, 'R2:%.4f'%train_r2,'%.4f'%val_r2,'%.4f'%test_r2_a, 'RMSE:%.4f'%train_MSE**0.5, '%.4f'%val_MSE**0.5, \n",
    "          '%.4f'%test_MSE_a**0.5, 'Tau:%.4f'%train_tau,'%.4f'%val_tau,'%.4f'%test_tau)#, 'Tau:%.4f'%val_tau,'%.4f'%test_tau,'GRN:%.4f'%reconstruction_loss,'%.4f'%val_reconstruction_loss\n",
    "    if early_stop:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopper.load_checkpoint(model)\n",
    "stopper_afse.load_checkpoint(amodel)\n",
    "stopper_generate.load_checkpoint(gmodel)\n",
    "    \n",
    "test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df)\n",
    "test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "test_r2_ina, test_MSE_ina, test_predict_ina = eval(model, amodel, gmodel, test_df[test_active:].reset_index(drop=True))\n",
    "    \n",
    "test_predict = np.array(test_predict)\n",
    "test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "\n",
    "k_list = [int(len(test_df)*0.01),int(len(test_df)*0.05),int(len(test_df)*0.1),int(len(test_df)*0.15),int(len(test_df)*0.2),int(len(test_df)*0.25),\n",
    "          int(len(test_df)*0.3),int(len(test_df)*0.4),int(len(test_df)*0.5),50,100,150,200,250,300]\n",
    "topk_list =[]\n",
    "false_positive_rate_list = []\n",
    "for k in k_list:\n",
    "    a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "    topk_list.append(a)\n",
    "    false_positive_rate_list.append(b)\n",
    "WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "ap = AP(test_df, test_predict, test_active)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 322 r2:0.5573 RMSE:0.7075 WTI:0.3693 AP:0.7057 Tau:0.5127 \n",
      " \n",
      " Top-1:0.7000 Top-1-fp:0.0000 \n",
      " Top-5:0.4717 Top-5-fp:0.0943 \n",
      " Top-10:0.6168 Top-10-fp:0.0561 \n",
      " Top-15:0.7329 Top-15-fp:0.0683 \n",
      " Top-20:0.7581 Top-20-fp:0.1349 \n",
      " Top-25:0.7537 Top-25-fp:0.1716 \n",
      " Top-30:0.7547 Top-30-fp:0.2112 \n",
      " Top-40:0.7400 Top-40-fp:0.3116 \n",
      " Top-50:0.8075 Top-50-fp:0.3985 \n",
      " \n",
      " Top50:0.5000 Top50-fp:0.1000 \n",
      " Top100:0.6000 Top100-fp:0.0600 \n",
      " Top150:0.7333 Top150-fp:0.0667 \n",
      " Top200:0.7500 Top200-fp:0.1300 \n",
      " Top250:0.7360 Top250-fp:0.1680 \n",
      " Top300:0.7600 Top300-fp:0.1900 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(' epoch:',epoch,'r2:%.4f'%test_r2_a,'RMSE:%.4f'%test_MSE_a**0.5,'WTI:%.4f'%WTI,'AP:%.4f'%ap,'Tau:%.4f'%test_tau,'\\n','\\n',\n",
    "      'Top-1:%.4f'%topk_list[0],'Top-1-fp:%.4f'%false_positive_rate_list[0],'\\n',\n",
    "      'Top-5:%.4f'%topk_list[1],'Top-5-fp:%.4f'%false_positive_rate_list[1],'\\n',\n",
    "      'Top-10:%.4f'%topk_list[2],'Top-10-fp:%.4f'%false_positive_rate_list[2],'\\n',\n",
    "      'Top-15:%.4f'%topk_list[3],'Top-15-fp:%.4f'%false_positive_rate_list[3],'\\n',\n",
    "      'Top-20:%.4f'%topk_list[4],'Top-20-fp:%.4f'%false_positive_rate_list[4],'\\n',\n",
    "      'Top-25:%.4f'%topk_list[5],'Top-25-fp:%.4f'%false_positive_rate_list[5],'\\n',\n",
    "      'Top-30:%.4f'%topk_list[6],'Top-30-fp:%.4f'%false_positive_rate_list[6],'\\n',\n",
    "      'Top-40:%.4f'%topk_list[7],'Top-40-fp:%.4f'%false_positive_rate_list[7],'\\n',\n",
    "      'Top-50:%.4f'%topk_list[8],'Top-50-fp:%.4f'%false_positive_rate_list[8],'\\n','\\n',\n",
    "      'Top50:%.4f'%topk_list[9],'Top50-fp:%.4f'%false_positive_rate_list[9],'\\n',\n",
    "      'Top100:%.4f'%topk_list[10],'Top100-fp:%.4f'%false_positive_rate_list[10],'\\n',\n",
    "      'Top150:%.4f'%topk_list[11],'Top150-fp:%.4f'%false_positive_rate_list[11],'\\n',\n",
    "      'Top200:%.4f'%topk_list[12],'Top200-fp:%.4f'%false_positive_rate_list[12],'\\n',\n",
    "      'Top250:%.4f'%topk_list[13],'Top250-fp:%.4f'%false_positive_rate_list[13],'\\n',\n",
    "      'Top300:%.4f'%topk_list[14],'Top300-fp:%.4f'%false_positive_rate_list[14],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('target_file:',train_filename)\n",
    "# print('inactive_file:',test_filename)\n",
    "# np.savez(result_dir, epoch_list, train_f_list, train_d_list, \n",
    "#          train_predict_list, train_y_list, val_f_list, val_d_list, val_predict_list, val_y_list, test_f_list, \n",
    "#          test_d_list, test_predict_list, test_y_list)\n",
    "# sim_space = np.load(result_dir+'.npz')\n",
    "# print(sim_space['arr_10'].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
