{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import math\n",
    "torch.manual_seed(8)\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP.AttentiveLayers_Sim_copy import Fingerprint, GRN, AFSE\n",
    "from AttentiveFP import Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set()\n",
    "from IPython.display import SVG, display\n",
    "import sascorer\n",
    "from AttentiveFP.utils import EarlyStopping\n",
    "from AttentiveFP.utils import Meter\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "import AttentiveFP.Featurizer\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ki_P25099_1_500\n",
      "model_file/0_GAFSE_Ki_P25099_1_500_run_0\n"
     ]
    }
   ],
   "source": [
    "train_filename = \"./data/benchmark/Ki_P25099_1_500_train.csv\"\n",
    "test_filename = \"./data/benchmark/Ki_P25099_1_500_test.csv\"\n",
    "test_active = 500\n",
    "val_rate = 0.06\n",
    "random_seed = 2023\n",
    "file_list1 = train_filename.split('/')\n",
    "file1 = file_list1[-1]\n",
    "file1 = file1[:-10]\n",
    "number = '_run_0'\n",
    "model_file = \"model_file/0_GAFSE_\"+file1+number\n",
    "log_dir = f'log/{\"0_GAFSE_\"+file1}'+number\n",
    "result_dir = './result/0_GAFSE_'+file1+number\n",
    "print(file1)\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              smiles     value\n",
      "0    C1CC2CC1CC2NC3=NC(=NC4=C3N=CN4C5C6CC6C(C5O)O)Cl  0.154902\n",
      "1  CNC(=O)C1C(C(C(O1)N2C=NC3=C2N=CN=C3NC(=O)NC4=C... -2.740363\n",
      "2           COCC1C(C(C(O1)N2C=NC3=C2N=C(N=C3N)Cl)O)O -2.227887\n",
      "3  C1=CC=C(C=C1)CCCCC(=O)NC2C(OC(C2O)N3C=NC4=C3N=... -3.831870\n",
      "4  C1CN(CCN1CC2=CC3=CC=CC=C3N=C2Cl)C4=NC5=NC(=NN5... -2.397940\n",
      "number of all smiles:  1822\n",
      "number of successfully processed smiles:  1822\n",
      "                                              smiles     value  \\\n",
      "0    C1CC2CC1CC2NC3=NC(=NC4=C3N=CN4C5C6CC6C(C5O)O)Cl  0.154902   \n",
      "1  CNC(=O)C1C(C(C(O1)N2C=NC3=C2N=CN=C3NC(=O)NC4=C... -2.740363   \n",
      "2           COCC1C(C(C(O1)N2C=NC3=C2N=C(N=C3N)Cl)O)O -2.227887   \n",
      "3  C1=CC=C(C=C1)CCCCC(=O)NC2C(OC(C2O)N3C=NC4=C3N=... -3.831870   \n",
      "4  C1CN(CCN1CC2=CC3=CC=CC=C3N=C2Cl)C4=NC5=NC(=NN5... -2.397940   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0    OC1C(O)C(n2cnc3c(NC4CC5CCC4C5)nc(Cl)nc32)C2CC12  \n",
      "1  CNC(=O)C1OC(n2cnc3c(NC(=O)Nc4cccc(Cl)c4)ncnc32...  \n",
      "2               COCC1OC(n2cnc3c(N)nc(Cl)nc32)C(O)C1O  \n",
      "3     Nc1ncnc2c1ncn2C1OC(CO)C(NC(=O)CCCCc2ccccc2)C1O  \n",
      "4  Nc1nc(N2CCN(Cc3cc4ccccc4nc3Cl)CC2)nc2nc(-c3ccc...  \n"
     ]
    }
   ],
   "source": [
    "# task_name = 'Malaria Bioactivity'\n",
    "tasks = ['value']\n",
    "\n",
    "# train_filename = \"../data/active_inactive/median_active/EC50/Q99500.csv\"\n",
    "feature_filename = train_filename.replace('.csv','.pickle')\n",
    "filename = train_filename.replace('.csv','')\n",
    "prefix_filename = train_filename.split('/')[-1].replace('.csv','')\n",
    "train_df = pd.read_csv(train_filename, header=0, names = [\"smiles\",\"value\"],usecols=[0,1])\n",
    "# train_df = train_df[1:]\n",
    "# train_df = train_df.drop(0,axis=1,inplace=False) \n",
    "print(train_df[:5])\n",
    "# print(train_df.iloc(1))\n",
    "def add_canonical_smiles(train_df):\n",
    "    smilesList = train_df.smiles.values\n",
    "    print(\"number of all smiles: \",len(smilesList))\n",
    "    atom_num_dist = []\n",
    "    remained_smiles = []\n",
    "    canonical_smiles_list = []\n",
    "    for smiles in smilesList:\n",
    "        try:        \n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            atom_num_dist.append(len(mol.GetAtoms()))\n",
    "            remained_smiles.append(smiles)\n",
    "            canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "        except:\n",
    "            print(smiles)\n",
    "            pass\n",
    "    print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "    train_df = train_df[train_df[\"smiles\"].isin(remained_smiles)]\n",
    "    train_df['cano_smiles'] =canonical_smiles_list\n",
    "    return train_df\n",
    "# print(train_df)\n",
    "train_df = add_canonical_smiles(train_df)\n",
    "\n",
    "print(train_df.head())\n",
    "# plt.figure(figsize=(5, 3))\n",
    "# sns.set(font_scale=1.5)\n",
    "# ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "# plt.tight_layout()\n",
    "# # plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "# plt.show()\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "\n",
    "p_dropout= 0.03\n",
    "fingerprint_dim = 100\n",
    "\n",
    "weight_decay = 4.3 # also known as l2_regularization_lambda\n",
    "learning_rate = 4\n",
    "radius = 2 # default: 2\n",
    "T = 1\n",
    "per_task_output_units_num = 1 # for regression model\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  1190\n",
      "number of successfully processed smiles:  1190\n",
      "(1190, 3)\n",
      "                                              smiles     value  \\\n",
      "0          CC1C(C(C(O1)N2C=NC3=C2N=CN=C3NC4CCCC4)O)O -1.845098   \n",
      "1  CCNC(=O)C1C(C(C(O1)N2C=NC3=C2N=C(N=C3N)C#CCN4C... -1.723456   \n",
      "2  C1CCC(C1)NC2=NC=NC3=C2N=CN3C4C(C(C(O4)COC5CC5)O)O -1.607455   \n",
      "3                   CCN(CC)C1=NC2=CC=CC=C2N3C1=NN=C3 -3.949390   \n",
      "4         CONC1=NC(=NC2=C1N=CN2C3C(C(C(O3)C=C)O)O)Cl -3.089905   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0              CC1OC(n2cnc3c(NC4CCCC4)ncnc32)C(O)C1O  \n",
      "1  CCNC(=O)C1OC(n2cnc3c(N)nc(C#CCN4CCSCC4)nc32)C(...  \n",
      "2        OC1C(COC2CC2)OC(n2cnc3c(NC4CCCC4)ncnc32)C1O  \n",
      "3                         CCN(CC)c1nc2ccccc2n2cnnc12  \n",
      "4             C=CC1OC(n2cnc3c(NOC)nc(Cl)nc32)C(O)C1O  \n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_filename,header=0,names=[\"smiles\",\"value\"],usecols=[0,1])\n",
    "test_df = add_canonical_smiles(test_df)\n",
    "for l in test_df[\"cano_smiles\"]:\n",
    "    if l in train_df[\"cano_smiles\"]:\n",
    "        print(\"same smiles:\",l)\n",
    "        \n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/benchmark/Ki_P25099_1_500_train.pickle\n",
      "./data/benchmark/Ki_P25099_1_500_train\n",
      "3012\n",
      "feature dicts file saved as ./data/benchmark/Ki_P25099_1_500_train.pickle\n"
     ]
    }
   ],
   "source": [
    "print(feature_filename)\n",
    "print(filename)\n",
    "total_df = pd.concat([train_df,test_df],axis=0)\n",
    "total_smilesList = total_df['smiles'].values\n",
    "print(len(total_smilesList))\n",
    "# if os.path.isfile(feature_filename):\n",
    "#     feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "# else:\n",
    "#     feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "feature_dicts = save_smiles_dicts(total_smilesList,filename)\n",
    "remained_df = total_df[total_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = total_df.drop(remained_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1713, 3) (109, 3) (1190, 3)\n"
     ]
    }
   ],
   "source": [
    "val_df = train_df.sample(frac=val_rate,random_state=random_seed)\n",
    "train_df = train_df.drop(val_df.index)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "train_df = train_df[train_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df[val_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df[test_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "print(train_df.shape,val_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([total_df[\"cano_smiles\"].values[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "loss_function = nn.MSELoss()\n",
    "model = Fingerprint(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "amodel = AFSE(fingerprint_dim, output_units_num, p_dropout)\n",
    "gmodel = GRN(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, p_dropout)\n",
    "model.cuda()\n",
    "amodel.cuda()\n",
    "gmodel.cuda()\n",
    "\n",
    "# optimizer = optim.Adam([\n",
    "# {'params': model.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# {'params': gmodel.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# ])\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "optimizer_AFSE = optim.Adam(params=amodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# optimizer_AFSE = optim.SGD(params=amodel.parameters(), lr = 0.01, momentum=0.9)\n",
    "\n",
    "optimizer_GRN = optim.Adam(params=gmodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# tensorboard = SummaryWriter(log_dir=\"runs/\"+start_time+\"_\"+prefix_filename+\"_\"+str(fingerprint_dim)+\"_\"+str(p_dropout))\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "# print(params)\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def sorted_show_pik(dataset, p, k, k_predict, i, acc):\n",
    "    p_value = dataset[tasks[0]].astype(float).tolist()\n",
    "    x = np.arange(0,len(dataset),1)\n",
    "#     print('plt',dataset.head(),p[:10],k_predict,k)\n",
    "#     plt.figure()\n",
    "#     fig, ax1 = plt.subplots()\n",
    "#     ax1.grid(False)\n",
    "#     ax2 = ax1.twinx()\n",
    "#     plt.grid(False)\n",
    "    plt.scatter(x,p,marker='.',s=6,color='r',label='predict')\n",
    "#     plt.ylabel('predict')\n",
    "    plt.scatter(x,p_value,s=6,marker=',',color='blue',label='p_value')\n",
    "    plt.axvline(x=k-1,ls=\"-\",c=\"black\")#添加垂直直线\n",
    "    k_value = np.ones(len(dataset))\n",
    "# #     print(EC50[k-1])\n",
    "    k_value = k_value*k_predict\n",
    "    plt.plot(x,k_value,'-',color='black')\n",
    "    plt.ylabel('p_value')\n",
    "    plt.title(\"epoch: {},  top-k recall: {}\".format(i,acc))\n",
    "    plt.legend(loc=3,fontsize=5)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def topk_acc2(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "    \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    k_true = true_sort[tasks[0]].values[k-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('k_true: ',type(k_true),k_true)\n",
    "#     print('k_true: ',k_true,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=k_true,'acc_num: ',len(df3[df3['predict'].values>=k_true]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k)\n",
    "    acc = len(df3[df3[tasks[0]].values>=k_true])/k #预测值前k个中真实排在前k个的个数/k\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/k\n",
    "    if k>active_num:\n",
    "        min_active = true_sort[tasks[0]].values[active_num-1]\n",
    "        acc = len(df3[df3[tasks[0]].values>=min_active])/k\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "def topk_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "        \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个，因为后面的全是-4.1\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    min_active = true_sort[tasks[0]].values[active_num-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('min_active: ',type(min_active),min_active)\n",
    "#     print('min_active: ',min_active,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=min_active,'acc_num: ',len(df3[df3['predict'].values>=min_active]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k,'active_num: ',active_num)\n",
    "    acc = len(df3[df3[tasks[0]].values>-4.1])/active_num #预测值前k个中真实排在前active_num个的个数/active_num\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/active_num\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "    \n",
    "def topk_acc_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    if k>active_num:\n",
    "        return topk_recall(df, predict, k, active_num, show_flag, i)\n",
    "    return topk_acc2(df,predict,k, active_num,show_flag,i)\n",
    "\n",
    "def weighted_top_index(df, predict, active_num):\n",
    "    weighted_acc_list=[]\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        acc, fp = topk_acc_recall(df, predict, k, active_num)\n",
    "        weight = (len(df)-k)/len(df)\n",
    "#         print('weight=',weight,'acc=',acc)\n",
    "        weighted_acc_list.append(acc*weight)#\n",
    "    weighted_acc_list = np.array(weighted_acc_list)\n",
    "#     print('weighted_acc_list=',weighted_acc_list)\n",
    "    return np.sum(weighted_acc_list)/weighted_acc_list.shape[0]\n",
    "\n",
    "def AP(df, predict, active_num):\n",
    "    prec = []\n",
    "    rec = []\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        prec_k, fp1 = topk_acc2(df,predict,k, active_num)\n",
    "        rec_k, fp2 = topk_recall(df, predict, k, active_num)\n",
    "        prec.append(prec_k)\n",
    "        rec.append(rec_k)\n",
    "    # 取所有不同的recall对应的点处的精度值做平均\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.], rec, [1.]))\n",
    "    mpre = np.concatenate(([0.], prec, [0.]))\n",
    "\n",
    "    # 计算包络线，从后往前取最大保证precise非减\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # 找出所有检测结果中recall不同的点\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "#     print(prec)\n",
    "#     print('prec='+str(prec)+'\\n\\n'+'rec='+str(rec))\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    # 用recall的间隔对精度作加权平均\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_r2(y,predict):\n",
    "#     print(y)\n",
    "#     print(predict)\n",
    "    y = torch.FloatTensor(y).reshape(-1,1)\n",
    "    predict = torch.FloatTensor(predict).reshape(-1,1)\n",
    "    y_mean = torch.mean(y)\n",
    "    predict_mean = torch.mean(predict)\n",
    "    \n",
    "    y1 = torch.pow(torch.mm((y-y_mean).t(),(predict-predict_mean)),2)\n",
    "    y2 = torch.mm((y-y_mean).t(),(y-y_mean))*torch.mm((predict-predict_mean).t(),(predict-predict_mean))\n",
    "#     print(y1,y2)\n",
    "    return y1/y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def l2_norm(input, dim):\n",
    "    norm = torch.norm(input, dim=dim, keepdim=True)\n",
    "    output = torch.div(input, norm+1e-6)\n",
    "    return output\n",
    "\n",
    "def normalize_perturbation(d,dim=-1):\n",
    "    output = l2_norm(d, dim)\n",
    "    return output\n",
    "\n",
    "def tanh(x):\n",
    "    return (torch.exp(x)-torch.exp(-x))/(torch.exp(x)+torch.exp(-x))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "def perturb_feature(f, model, alpha=1, lamda=10**-learning_rate, output_lr=False, output_plr=False, y=None):\n",
    "    mol_prediction = model(feature=f, d=0)\n",
    "    pred = mol_prediction.detach()\n",
    "#     f = torch.div(f, torch.norm(f, dim=-1, keepdim=True)+1e-9)\n",
    "    eps = 1e-6 * normalize_perturbation(torch.randn(f.shape))\n",
    "    eps = Variable(eps, requires_grad=True)\n",
    "    # Predict on randomly perturbed image\n",
    "    eps_p = model(feature=f, d=eps.cuda())\n",
    "    eps_p_ = model(feature=f, d=-eps.cuda())\n",
    "    p_aux = nn.Sigmoid()(eps_p/(pred+1e-6))\n",
    "    p_aux_ = nn.Sigmoid()(eps_p_/(pred+1e-6))\n",
    "#     loss = nn.BCELoss()(abs(p_aux),torch.ones_like(p_aux))+nn.BCELoss()(abs(p_aux_),torch.ones_like(p_aux_))\n",
    "    loss = loss_function(p_aux,torch.ones_like(p_aux))+loss_function(p_aux_,torch.ones_like(p_aux_))\n",
    "    loss.backward(retain_graph=True)\n",
    "\n",
    "    # Based on perturbed image, get direction of greatest error\n",
    "    eps_adv = eps.grad#/10**-learning_rate\n",
    "    optimizer_AFSE.zero_grad()\n",
    "    # Use that direction as adversarial perturbation\n",
    "    eps_adv_normed = normalize_perturbation(eps_adv)\n",
    "    d_adv = lamda * eps_adv_normed.cuda()\n",
    "    if output_lr:\n",
    "        f_p, max_lr = model(feature=f, d=d_adv, output_lr=output_lr)\n",
    "    f_p = model(feature=f, d=d_adv)\n",
    "    f_p_ = model(feature=f, d=-d_adv)\n",
    "    p = nn.Sigmoid()(f_p/(pred+1e-6))\n",
    "    p_ = nn.Sigmoid()(f_p_/(pred+1e-6))\n",
    "    vat_loss = loss_function(p,torch.ones_like(p))+loss_function(p_,torch.ones_like(p_))\n",
    "    if output_lr:\n",
    "        if output_plr:\n",
    "            loss = loss_function(mol_prediction,y)\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer_AFSE.zero_grad()\n",
    "            punish_lr = torch.norm(torch.mean(eps.grad,0))\n",
    "            return eps_adv, d_adv, vat_loss, mol_prediction, max_lr, punish_lr\n",
    "        return eps_adv, d_adv, vat_loss, mol_prediction, max_lr\n",
    "    return eps_adv, d_adv, vat_loss, mol_prediction\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "\n",
    "def d_loss(f, pred, model, y_val):\n",
    "    diff_loss = 0\n",
    "    length = len(pred)\n",
    "    for i in range(length):\n",
    "        for j in range(length):\n",
    "            if j == i:\n",
    "                continue\n",
    "            pred_diff = model(feature_only=True, feature1=f[i], feature2=f[j])\n",
    "            true_diff = y_val[i] - y_val[j]\n",
    "            diff_loss += loss_function(pred_diff, torch.Tensor([true_diff]).view(-1,1))\n",
    "    diff_loss = diff_loss/(length*(length-1))\n",
    "    return diff_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CE(x,y):\n",
    "    c = 0\n",
    "    l = len(y)\n",
    "    for i in range(l):\n",
    "        if y[i]==1:\n",
    "            c += 1\n",
    "    w1 = (l-c)/l\n",
    "    w0 = c/l\n",
    "    loss = -w1*y*torch.log(x+1e-6)-w0*(1-y)*torch.log(1-x+1e-6)\n",
    "    loss = loss.mean(-1)\n",
    "    return loss\n",
    "\n",
    "def weighted_CE_loss(x,y):\n",
    "    weight = 1/(y.detach().float().mean(0)+1e-9)\n",
    "    weighted_CE = nn.CrossEntropyLoss(weight=weight)\n",
    "#     atom_weights = (atom_weights-min(atom_weights))/(max(atom_weights)-min(atom_weights))\n",
    "    return weighted_CE(x, torch.argmax(y,-1))\n",
    "\n",
    "def generate_loss_function(refer_atom_list, x_atom, validity_mask, atom_list):\n",
    "    [a,b,c] = x_atom.shape\n",
    "    reconstruction_loss = 0\n",
    "    counter = 0\n",
    "    validity_mask = torch.from_numpy(validity_mask).cuda()\n",
    "    for i in range(a):\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        reconstruction_loss += weighted_CE_loss(refer_atom_list[i,:l,:16], x_atom[i,:l,:16]) - \\\n",
    "                        ((validity_mask[i,:l]*torch.log(1-atom_list[i,:l,:16]+1e-9)).sum(-1)/(validity_mask[i,:l].sum(-1)+1e-9)).mean(-1).mean(-1)\n",
    "        counter += 1\n",
    "    reconstruction_loss = reconstruction_loss/counter\n",
    "    return reconstruction_loss\n",
    "\n",
    "\n",
    "def train(model, amodel, gmodel, dataset, test_df, optimizer_list, loss_function, epoch):\n",
    "    model.train()\n",
    "    amodel.train()\n",
    "    gmodel.train()\n",
    "    optimizer, optimizer_AFSE, optimizer_GRN = optimizer_list\n",
    "    np.random.seed(epoch)\n",
    "    max_len = np.max([len(dataset),len(test_df)])\n",
    "    valList = np.arange(0,max_len)\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, max_len, batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[batch%len(dataset),:]\n",
    "        batch_test = test_df.loc[batch%len(test_df),:]\n",
    "        global_step = epoch * len(batch_list) + counter\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        smiles_list_test = batch_test.cano_smiles.values\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        x_atom_test, x_bonds_test, x_atom_index_test, x_bond_index_test, x_mask_test, smiles_to_rdkit_list_test = get_smiles_array(smiles_list_test,feature_dicts)\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                  torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),\n",
    "                                                  mol_feature=mol_feature,activated_features=activated_features.detach())\n",
    "        \n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        \n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        eps_adv, d_adv, vat_loss, mol_prediction, conv_lr, punish_lr = perturb_feature(mol_feature, amodel, alpha=1, \n",
    "                                                                                       lamda=10**-learning_rate, output_lr=True, \n",
    "                                                                                       output_plr=True, y=torch.Tensor(y_val).view(-1,1)) # 10**-learning_rate     \n",
    "        regression_loss = loss_function(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "        atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "                                      torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/1e-6,activated_features=activated_features.detach())\n",
    "        success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(smiles_list, x_atom, \n",
    "                            bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "                                                     refer_atom_list, refer_bond_list,topn=1)\n",
    "        reconstruction_loss = generate_loss_function(refer_atom_list, x_atom, validity_mask, atom_list)\n",
    "        x_atom_test = torch.Tensor(x_atom_test)\n",
    "        x_bonds_test = torch.Tensor(x_bonds_test)\n",
    "        x_bond_index_test = torch.cuda.LongTensor(x_bond_index_test)\n",
    "        \n",
    "        bond_neighbor_test = [x_bonds_test[i][x_bond_index_test[i]] for i in range(len(batch_test))]\n",
    "        bond_neighbor_test = torch.stack(bond_neighbor_test, dim=0)\n",
    "        activated_features_test, mol_feature_test = model(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "                                                          torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),\n",
    "                                                          torch.Tensor(x_mask_test),output_activated_features=True)\n",
    "#         mol_feature_test = torch.div(mol_feature_test, torch.norm(mol_feature_test, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features_test = torch.div(activated_features_test, torch.norm(activated_features_test, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_test, d_test, test_vat_loss, mol_prediction_test = perturb_feature(mol_feature_test, amodel, \n",
    "                                                                                    alpha=1, lamda=10**-learning_rate)\n",
    "        atom_list_test, bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),torch.cuda.LongTensor(x_atom_index_test),\n",
    "                                                torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "                                                mol_feature=mol_feature_test+d_test/1e-6,activated_features=activated_features_test.detach())\n",
    "        refer_atom_list_test, refer_bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "                                                            torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "                                                            mol_feature=mol_feature_test,activated_features=activated_features_test.detach())\n",
    "        success_smiles_batch_test, modified_smiles_test, success_batch_test, total_batch_test, reconstruction_test, validity_test, validity_mask_test = modify_atoms(smiles_list_test, x_atom_test, \n",
    "                            bond_neighbor_test, atom_list_test, bond_list_test,smiles_list_test,smiles_to_rdkit_list_test,\n",
    "                                                     refer_atom_list_test, refer_bond_list_test,topn=1)\n",
    "        test_reconstruction_loss = generate_loss_function(atom_list_test, x_atom_test, validity_mask_test, atom_list_test)\n",
    "        \n",
    "        if vat_loss>1 or test_vat_loss>1:\n",
    "            vat_loss = 1*(vat_loss/(vat_loss+1e-6).item())\n",
    "            test_vat_loss = 1*(test_vat_loss/(test_vat_loss+1e-6).item())\n",
    "        \n",
    "        logger.add_scalar('loss/regression', regression_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE', vat_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE_test', test_vat_loss, global_step)\n",
    "        logger.add_scalar('loss/GRN', reconstruction_loss, global_step)\n",
    "        logger.add_scalar('loss/GRN_test', test_reconstruction_loss, global_step)\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_AFSE.zero_grad()\n",
    "        optimizer_GRN.zero_grad()\n",
    "        loss =  regression_loss + 0.6 * (vat_loss + test_vat_loss) + reconstruction_loss + test_reconstruction_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_AFSE.step()\n",
    "        optimizer_GRN.step()\n",
    "\n",
    "        \n",
    "def clear_atom_map(mol):\n",
    "    [a.ClearProp('molAtomMapNumber') for a  in mol.GetAtoms()]\n",
    "    return mol\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "        \n",
    "def modify_atoms(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list,refer_atom_list, refer_bond_list,topn=1,viz=False):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    refer_atom_list = refer_atom_list.cpu().detach().numpy()\n",
    "    refer_bond_list = refer_bond_list.cpu().detach().numpy()\n",
    "    atom_symbol_sorted = np.argsort(x_atom[:,:,:16], axis=-1)\n",
    "    atom_symbol_generated_sorted = np.argsort(atom_list[:,:,:16], axis=-1)\n",
    "    generate_confidence_sorted = np.sort(atom_list[:,:,:16], axis=-1)\n",
    "    modified_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    confidence_threshold = 0.001\n",
    "    validity_mask = np.zeros_like(atom_list[:,:,:16])\n",
    "    symbol_list = ['B','C','N','O','F','Si','P','S','Cl','As','Se','Br','Te','I','At','other']\n",
    "    symbol_to_rdkit = [4,6,7,8,9,14,15,16,17,33,34,35,52,53,85,0]\n",
    "    for i in range(len(atom_list)):\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        first_run_flag = True\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "        mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "        counter = 0\n",
    "        for j in range(l): \n",
    "            if mol.GetAtomWithIdx(int(smiles_to_rdkit_list[cano_smiles][j])).GetAtomicNum() == \\\n",
    "                symbol_to_rdkit[refer_atom_list[i,j,:16].argmax(-1)]:\n",
    "                counter += 1\n",
    "#             print(f'atom#{smiles_to_rdkit_list[cano_smiles][j]}(f):',{symbol_list[k]: np.around(refer_atom_list[i,j,k],3) for k in range(16)},\n",
    "#                   f'\\natom#{smiles_to_rdkit_list[cano_smiles][j]}(f+d):',{symbol_list[k]: np.around(atom_list[i,j,k],3) for k in range(16)},\n",
    "#                  '\\n------------------------------------------------------------------------------------------------------------')\n",
    "#         print('预测为每个原子的平均概率：\\n',np.around(atom_list[i,:l,:16].mean(1),2))\n",
    "#         print('预测为每个原子的最大概率：\\n',np.around(atom_list[i,:l,:16].max(1),2))\n",
    "        if counter == l:\n",
    "            success_reconstruction += 1\n",
    "        while not flag==topn:\n",
    "            if rank == 16:\n",
    "                rank = 0\n",
    "                top_idx += 1\n",
    "            if top_idx == l:\n",
    "#                 print('没有满足条件的分子生成。')\n",
    "                flag += 1\n",
    "                continue\n",
    "#             if np.sum((atom_symbol_sorted[i,:l,-1]!=atom_symbol_generated_sorted[i,:l,-1-rank]).astype(int))==0:\n",
    "#                 print(f'根据预测的第{rank}大概率的原子构成的分子与原分子一致，原子位重置为0，生成下一个元素……')\n",
    "#                 rank += 1\n",
    "#                 top_idx = 0\n",
    "#                 generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "#                                              x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "#             print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            if rank == 0:\n",
    "                generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "                                             x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "            atom_symbol_generated = np.argsort(atom_list[i,generate_index,:16]-\\\n",
    "                                                    refer_atom_list[i,generate_index,:16] -\\\n",
    "                                                    x_atom[i,generate_index,:16])[-1-rank]\n",
    "            if atom_symbol_generated==x_atom[i,generate_index,:16].argmax(-1):\n",
    "#                 print('生成了相同元素，生成下一个元素……')\n",
    "                rank += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            if np.sort(atom_list[i,generate_index,:16]-\\\n",
    "                refer_atom_list[i,generate_index,:16] -\\\n",
    "                x_atom[i,generate_index,:16])[-1-rank]<confidence_threshold:\n",
    "#                 print(f'原子位{generate_rdkit_index}生成{symbol_list[atom_symbol_generated]}元素的置信度小于{confidence_threshold}，寻找下一个原子位……')\n",
    "                top_idx += 1\n",
    "                rank = 0\n",
    "                continue\n",
    "#             if symbol_to_rdkit[atom_symbol_generated]==6:\n",
    "#                 print('生成了不推荐的C元素')\n",
    "#                 rank += 1\n",
    "#                 continue\n",
    "            mol.GetAtomWithIdx(int(generate_rdkit_index)).SetAtomicNum(symbol_to_rdkit[atom_symbol_generated])\n",
    "            print_mol = mol\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                if first_run_flag == True:\n",
    "                    success_validity += 1\n",
    "                total[flag] += 1\n",
    "                if Chem.MolToSmiles(clear_atom_map(print_mol))==y_smiles[i]:\n",
    "                    success[flag] +=1\n",
    "#                     print('Congratulations!', success, total)\n",
    "                    success_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "#                 print(\"修改前的分子：\", smiles[i])\n",
    "#                 display(mol_init)\n",
    "                modified_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 print(f\"将第{generate_rdkit_index}个原子修改为{symbol_list[atom_symbol_generated]}的分子：\", Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 display(mol_with_atom_index(mol))\n",
    "                mol_y = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "#                 print(\"高活性分子：\", y_smiles[i])\n",
    "#                 display(mol_y)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "#                 print(f\"第{generate_rdkit_index}个原子符号修改为{symbol_list[atom_symbol_generated]}不符合规范，生成下一个元素……\")\n",
    "                validity_mask[i,generate_index,atom_symbol_generated] = 1\n",
    "                rank += 1\n",
    "                first_run_flag = False\n",
    "    return success_smiles, modified_smiles, success, total, success_reconstruction, success_validity, validity_mask\n",
    "\n",
    "def modify_bonds(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    modified_smiles = []\n",
    "    for i in range(len(bond_neighbor)):\n",
    "        l = (bond_neighbor[i].sum(-1).sum(-1)!=0).sum(-1)\n",
    "        bond_type_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        bond_type_generated_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        generate_confidence_sorted = np.sort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        while not flag==3:\n",
    "            cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "            if np.sum((bond_type_sorted[i,:,-1]!=bond_type_generated_sorted[:,:,-1-rank]).astype(int))==0:\n",
    "                rank += 1\n",
    "                top_idx = 0\n",
    "            print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            bond_type = bond_type_sorted[i,:,-1]\n",
    "            bond_type_generated = bond_type_generated_sorted[:,:,-1-rank]\n",
    "            generate_confidence = generate_confidence_sorted[:,:,-1-rank]\n",
    "#             print(np.sort(generate_confidence + \\\n",
    "#                                     (atom_symbol!=atom_symbol_generated).astype(int), axis=-1))\n",
    "            generate_index = np.argsort(generate_confidence + \n",
    "                                (bond_type!=bond_type_generated).astype(int), axis=-1)[-1-top_idx]\n",
    "            bond_type_generated_one = bond_type_generated[generate_index]\n",
    "            mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "            if generate_index >= len(smiles_to_rdkit_list[cano_smiles]):\n",
    "                top_idx += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            mol.GetBondWithIdx(int(generate_rdkit_index)).SetBondType(bond_type_generated_one)\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "                print(\"修改前的分子：\")\n",
    "                display(mol_init)\n",
    "                modified_smiles.append(mol)\n",
    "                print(f\"将第{generate_rdkit_index}个键修改为{atom_symbol_generated}的分子：\")\n",
    "                display(mol)\n",
    "                mol = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "                print(\"高活性分子：\")\n",
    "                display(mol)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "                print(f\"第{generate_rdkit_index}个原子符号修改为{atom_symbol_generated}不符合规范\")\n",
    "                top_idx += 1\n",
    "    return modified_smiles\n",
    "        \n",
    "def eval(model, amodel, gmodel, dataset, topn=1, output_feature=False, generate=False, modify_atom=True,return_GRN_loss=False, viz=False):\n",
    "    model.eval()\n",
    "    amodel.eval()\n",
    "    gmodel.eval()\n",
    "    predict_list = []\n",
    "    test_MSE_list = []\n",
    "    r2_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    feature_list = []\n",
    "    d_list = []\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    generated_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    reconstruction_loss, one_hot_loss, interger_loss, binary_loss = [0,0,0,0]\n",
    "    \n",
    "# #     取dataset中排序后的第k个\n",
    "#     sorted_dataset = dataset.sort_values(by=tasks[0],ascending=False)\n",
    "#     k_df = sorted_dataset.iloc[[k-1]]\n",
    "#     k_smiles = k_df['cano_smiles'].values\n",
    "#     k_value = k_df[tasks[0]].values.astype(float)    \n",
    "    \n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch) \n",
    "#     print(batch_list)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "#         print(type(batch))\n",
    "        batch_df = dataset.loc[batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        matched_smiles_list = smiles_list\n",
    "#         print(batch_df)\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "#         print(type(y_val))\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(matched_smiles_list,feature_dicts)\n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        lamda=10**-learning_rate\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_adv, d_adv, vat_loss, mol_prediction = perturb_feature(mol_feature, amodel, alpha=1, lamda=lamda)\n",
    "#         print(mol_feature,d_adv)\n",
    "        atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),\n",
    "                                      torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "                                      torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/(1e-6),activated_features=activated_features)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),mol_feature=mol_feature,activated_features=activated_features)\n",
    "        if generate:\n",
    "            if modify_atom:\n",
    "                success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(matched_smiles_list, x_atom, \n",
    "                            bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "                                                     refer_atom_list, refer_bond_list,topn=topn,viz=viz)\n",
    "            else:\n",
    "                modified_smiles = modify_bonds(matched_smiles_list, x_atom, bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list)\n",
    "            generated_smiles.extend(modified_smiles)\n",
    "            success_smiles.extend(success_smiles_batch)\n",
    "#             for n in range(topn):\n",
    "#                 success[n] += success_batch[n]\n",
    "#                 total[n] += total_batch[n]\n",
    "#                 print('congratulations:',success,total)\n",
    "            success_reconstruction += reconstruction\n",
    "            success_validity += validity\n",
    "            reconstruction_loss, one_hot_loss, interger_loss, binary_loss = generate_loss_function(refer_atom_list, x_atom, refer_bond_list, bond_neighbor, validity_mask, atom_list, bond_list)\n",
    "        d = d_adv.cpu().detach().numpy().tolist()\n",
    "        d_list.extend(d)\n",
    "        mol_feature_output = mol_feature.cpu().detach().numpy().tolist()\n",
    "        feature_list.extend(mol_feature_output)\n",
    "#         MAE = F.l1_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')   \n",
    "#         print(type(mol_prediction))\n",
    "        \n",
    "        MSE = F.mse_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')\n",
    "#         r2 = caculate_r2(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "# #         r2_list.extend(r2.cpu().detach().numpy())\n",
    "#         if r2!=r2:\n",
    "#             r2 = torch.tensor(0)\n",
    "#         r2_list.append(r2.item())\n",
    "#         predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         print(x_mask[:2],atoms_prediction.shape, mol_prediction,MSE)\n",
    "        predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         test_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n",
    "        test_MSE_list.extend(MSE.data.view(-1,1).cpu().numpy())\n",
    "#     print(r2_list)\n",
    "    if generate:\n",
    "        generated_num = len(generated_smiles)\n",
    "        eval_num = len(dataset)\n",
    "        unique = generated_num\n",
    "        novelty = generated_num\n",
    "        for i in range(generated_num):\n",
    "            for j in range(generated_num-i-1):\n",
    "                if generated_smiles[i]==generated_smiles[i+j+1]:\n",
    "                    unique -= 1\n",
    "            for k in range(eval_num):\n",
    "                if generated_smiles[i]==dataset['smiles'].values[k]:\n",
    "                    novelty -= 1\n",
    "        unique_rate = unique/(generated_num+1e-9)\n",
    "        novelty_rate = novelty/(generated_num+1e-9)\n",
    "#         print(f'successfully/total generated molecules =', {f'Top-{i+1}': f'{success[i]}/{total[i]}' for i in range(topn)})\n",
    "        return success_reconstruction/len(dataset), success_validity/len(dataset), unique_rate, novelty_rate, success_smiles, generated_smiles, caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    if return_GRN_loss:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list,reconstruction_loss, one_hot_loss, interger_loss,binary_loss\n",
    "    if output_feature:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    return caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "\n",
    "epoch = 0\n",
    "max_epoch = 1000\n",
    "batch_size = 8\n",
    "patience = 60\n",
    "stopper = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_model.pth')\n",
    "stopper_afse = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_amodel.pth')\n",
    "stopper_generate = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_gmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log/0_GAFSE_Ki_P25099_1_500_run_0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "now = datetime.datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "if os.path.isdir(log_dir):\n",
    "    for files in os.listdir(log_dir):\n",
    "        os.remove(log_dir+\"/\"+files)\n",
    "    os.rmdir(log_dir)\n",
    "logger = SummaryWriter(log_dir)\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3171335/3510960041.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  y = torch.FloatTensor(y).reshape(-1,1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Step: 214 Index:-1.0252 R2:0.0345 0.0354 0.0065 RMSE:1.0289 1.1449 1.0139 Tau:0.1105 0.1196 -0.0091\n",
      "Epoch: 2 Step: 428 Index:-0.9009 R2:0.0821 0.0859 0.0322 RMSE:0.9899 1.1137 0.9964 Tau:0.1949 0.2128 0.0939\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 3 Step: 642 Index:-0.9251 R2:0.0958 0.1018 0.0417 RMSE:0.9972 1.1324 1.0054 Tau:0.2055 0.2073 0.1135\n",
      "Epoch: 4 Step: 856 Index:-0.8735 R2:0.1147 0.1229 0.0557 RMSE:0.9766 1.1036 0.9851 Tau:0.2250 0.2301 0.1378\n",
      "Epoch: 5 Step: 1070 Index:-0.8470 R2:0.1334 0.1438 0.0684 RMSE:0.9659 1.0897 0.9743 Tau:0.2422 0.2427 0.1588\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 6 Step: 1284 Index:-0.8557 R2:0.1511 0.1621 0.0821 RMSE:0.9762 1.1085 0.9863 Tau:0.2585 0.2529 0.1800\n",
      "Epoch: 7 Step: 1498 Index:-0.8040 R2:0.1626 0.1708 0.0929 RMSE:0.9539 1.0654 0.9666 Tau:0.2697 0.2614 0.2005\n",
      "Epoch: 8 Step: 1712 Index:-0.8017 R2:0.1814 0.1852 0.1162 RMSE:0.9407 1.0648 0.9502 Tau:0.2848 0.2631 0.2241\n",
      "Epoch: 9 Step: 1926 Index:-0.7969 R2:0.1912 0.1901 0.1225 RMSE:0.9370 1.0603 0.9468 Tau:0.2947 0.2634 0.2266\n",
      "Epoch: 10 Step: 2140 Index:-0.7888 R2:0.2016 0.1917 0.1352 RMSE:0.9257 1.0495 0.9383 Tau:0.3031 0.2607 0.2457\n",
      "Epoch: 11 Step: 2354 Index:-0.7702 R2:0.2161 0.2035 0.1490 RMSE:0.9218 1.0475 0.9330 Tau:0.3154 0.2774 0.2660\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 12 Step: 2568 Index:-0.9032 R2:0.2116 0.1879 0.1757 RMSE:1.0488 1.1792 1.0399 Tau:0.3089 0.2760 0.2873\n",
      "Epoch: 13 Step: 2782 Index:-0.7506 R2:0.2419 0.2104 0.1767 RMSE:0.9041 1.0378 0.9165 Tau:0.3347 0.2872 0.2910\n",
      "Epoch: 14 Step: 2996 Index:-0.7384 R2:0.2577 0.2204 0.1959 RMSE:0.8994 1.0372 0.9091 Tau:0.3481 0.2988 0.3165\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 15 Step: 3210 Index:-0.7592 R2:0.2639 0.2142 0.1978 RMSE:0.9096 1.0542 0.9219 Tau:0.3504 0.2950 0.3289\n",
      "Epoch: 16 Step: 3424 Index:-0.7369 R2:0.2772 0.2176 0.2120 RMSE:0.8888 1.0339 0.9008 Tau:0.3599 0.2971 0.3353\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 17 Step: 3638 Index:-0.7454 R2:0.2877 0.2185 0.2286 RMSE:0.8934 1.0452 0.9016 Tau:0.3656 0.2998 0.3459\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 18 Step: 3852 Index:-0.7943 R2:0.2867 0.2179 0.2325 RMSE:0.9414 1.0900 0.9466 Tau:0.3651 0.2957 0.3489\n",
      "Epoch: 19 Step: 4066 Index:-0.7317 R2:0.3012 0.2196 0.2458 RMSE:0.8825 1.0390 0.8894 Tau:0.3746 0.3073 0.3505\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 20 Step: 4280 Index:-0.7606 R2:0.3104 0.2195 0.2603 RMSE:0.8944 1.0542 0.8992 Tau:0.3809 0.2937 0.3566\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 21 Step: 4494 Index:-0.7492 R2:0.3074 0.2214 0.2493 RMSE:0.8888 1.0473 0.8991 Tau:0.3801 0.2981 0.3513\n",
      "EarlyStopping counter: 3 out of 60\n",
      "Epoch: 22 Step: 4708 Index:-0.7339 R2:0.3198 0.2258 0.2675 RMSE:0.8677 1.0323 0.8762 Tau:0.3888 0.2984 0.3573\n",
      "Epoch: 23 Step: 4922 Index:-0.7172 R2:0.3282 0.2355 0.2707 RMSE:0.8612 1.0265 0.8729 Tau:0.3955 0.3093 0.3585\n",
      "Epoch: 24 Step: 5136 Index:-0.7076 R2:0.3346 0.2370 0.2789 RMSE:0.8555 1.0230 0.8671 Tau:0.3999 0.3154 0.3597\n",
      "Epoch: 25 Step: 5350 Index:-0.7003 R2:0.3453 0.2403 0.2980 RMSE:0.8537 1.0219 0.8589 Tau:0.4044 0.3215 0.3690\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 26 Step: 5564 Index:-0.7024 R2:0.3470 0.2382 0.2942 RMSE:0.8413 1.0137 0.8509 Tau:0.4085 0.3114 0.3685\n",
      "Epoch: 27 Step: 5778 Index:-0.6908 R2:0.3502 0.2326 0.3039 RMSE:0.8359 1.0151 0.8425 Tau:0.4073 0.3243 0.3663\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 28 Step: 5992 Index:-0.6979 R2:0.3488 0.2491 0.3072 RMSE:0.8702 1.0338 0.8730 Tau:0.4062 0.3358 0.3742\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 29 Step: 6206 Index:-0.7634 R2:0.3666 0.2473 0.3221 RMSE:0.9290 1.0921 0.9371 Tau:0.4193 0.3287 0.3718\n",
      "Epoch: 30 Step: 6420 Index:-0.6696 R2:0.3593 0.2573 0.2996 RMSE:0.8345 1.0030 0.8499 Tau:0.4174 0.3334 0.3644\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 31 Step: 6634 Index:-0.6734 R2:0.3687 0.2538 0.3144 RMSE:0.8293 1.0089 0.8437 Tau:0.4246 0.3355 0.3697\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 32 Step: 6848 Index:-0.6699 R2:0.3811 0.2664 0.3314 RMSE:0.8438 1.0166 0.8545 Tau:0.4307 0.3467 0.3812\n",
      "Epoch: 33 Step: 7062 Index:-0.6519 R2:0.3861 0.2726 0.3359 RMSE:0.8182 0.9921 0.8279 Tau:0.4365 0.3402 0.3781\n",
      "Epoch: 34 Step: 7276 Index:-0.6503 R2:0.3943 0.2633 0.3439 RMSE:0.8099 0.9953 0.8190 Tau:0.4383 0.3450 0.3834\n",
      "Epoch: 35 Step: 7490 Index:-0.6388 R2:0.4008 0.2750 0.3517 RMSE:0.8102 0.9933 0.8222 Tau:0.4434 0.3545 0.3860\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 36 Step: 7704 Index:-0.6388 R2:0.4042 0.2774 0.3517 RMSE:0.8150 0.9968 0.8281 Tau:0.4505 0.3579 0.3833\n",
      "Epoch: 37 Step: 7918 Index:-0.6172 R2:0.4033 0.2874 0.3436 RMSE:0.7994 0.9812 0.8194 Tau:0.4487 0.3640 0.3836\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 38 Step: 8132 Index:-0.6278 R2:0.3969 0.2918 0.3402 RMSE:0.8215 0.9945 0.8408 Tau:0.4453 0.3668 0.3772\n",
      "Epoch: 39 Step: 8346 Index:-0.5949 R2:0.4189 0.3026 0.3584 RMSE:0.7905 0.9688 0.8091 Tau:0.4596 0.3739 0.3915\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 40 Step: 8560 Index:-0.6270 R2:0.4257 0.2993 0.3569 RMSE:0.8365 1.0043 0.8498 Tau:0.4667 0.3773 0.3922\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 41 Step: 8774 Index:-0.6832 R2:0.4262 0.2943 0.3630 RMSE:0.8857 1.0537 0.8962 Tau:0.4626 0.3705 0.3914\n",
      "Epoch: 42 Step: 8988 Index:-0.5942 R2:0.4357 0.2984 0.3711 RMSE:0.7817 0.9718 0.8025 Tau:0.4721 0.3776 0.3968\n",
      "Epoch: 43 Step: 9202 Index:-0.5788 R2:0.4482 0.3190 0.3781 RMSE:0.7814 0.9616 0.8014 Tau:0.4783 0.3827 0.4065\n",
      "Epoch: 44 Step: 9416 Index:-0.5673 R2:0.4493 0.3157 0.3826 RMSE:0.7693 0.9592 0.7938 Tau:0.4792 0.3919 0.4088\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 45 Step: 9630 Index:-0.5688 R2:0.4514 0.3202 0.3844 RMSE:0.7833 0.9686 0.8085 Tau:0.4774 0.3997 0.4065\n",
      "Epoch: 46 Step: 9844 Index:-0.5588 R2:0.4495 0.3300 0.3751 RMSE:0.7711 0.9487 0.7981 Tau:0.4786 0.3899 0.4096\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 47 Step: 10058 Index:-0.5700 R2:0.4569 0.3187 0.3846 RMSE:0.7723 0.9582 0.7940 Tau:0.4896 0.3882 0.4108\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 48 Step: 10272 Index:-0.5971 R2:0.4535 0.3254 0.3764 RMSE:0.8016 0.9866 0.8392 Tau:0.4866 0.3895 0.4102\n",
      "Epoch: 49 Step: 10486 Index:-0.5404 R2:0.4688 0.3392 0.3995 RMSE:0.7600 0.9435 0.7827 Tau:0.4909 0.4031 0.4192\n",
      "Epoch: 50 Step: 10700 Index:-0.5292 R2:0.4718 0.3476 0.3975 RMSE:0.7582 0.9370 0.7841 Tau:0.5000 0.4079 0.4122\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 51 Step: 10914 Index:-0.5465 R2:0.4665 0.3510 0.3826 RMSE:0.7762 0.9557 0.8171 Tau:0.4888 0.4092 0.4199\n",
      "Epoch: 52 Step: 11128 Index:-0.5221 R2:0.4800 0.3588 0.3909 RMSE:0.7580 0.9317 0.7927 Tau:0.4988 0.4096 0.4216\n",
      "Epoch: 53 Step: 11342 Index:-0.5051 R2:0.4810 0.3631 0.3951 RMSE:0.7460 0.9249 0.7855 Tau:0.5021 0.4198 0.4269\n",
      "Epoch: 54 Step: 11556 Index:-0.4974 R2:0.5023 0.3754 0.4209 RMSE:0.7424 0.9243 0.7794 Tau:0.5141 0.4269 0.4307\n",
      "Epoch: 55 Step: 11770 Index:-0.4872 R2:0.4941 0.3728 0.4007 RMSE:0.7359 0.9189 0.7841 Tau:0.5120 0.4317 0.4308\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 56 Step: 11984 Index:-0.5084 R2:0.4864 0.3649 0.4044 RMSE:0.7463 0.9251 0.7805 Tau:0.5026 0.4167 0.4240\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 57 Step: 12198 Index:-0.5003 R2:0.4766 0.3731 0.4004 RMSE:0.7501 0.9218 0.7911 Tau:0.4961 0.4215 0.4269\n",
      "Epoch: 58 Step: 12412 Index:-0.4622 R2:0.5162 0.3966 0.4295 RMSE:0.7275 0.9065 0.7700 Tau:0.5252 0.4443 0.4351\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 59 Step: 12626 Index:-0.5135 R2:0.4748 0.3626 0.4046 RMSE:0.7527 0.9272 0.7816 Tau:0.4923 0.4137 0.4240\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 60 Step: 12840 Index:-0.4648 R2:0.5098 0.3893 0.4256 RMSE:0.7280 0.9056 0.7645 Tau:0.5235 0.4409 0.4339\n",
      "EarlyStopping counter: 3 out of 60\n",
      "Epoch: 61 Step: 13054 Index:-0.4970 R2:0.5121 0.3762 0.4264 RMSE:0.7281 0.9205 0.7718 Tau:0.5234 0.4235 0.4323\n",
      "EarlyStopping counter: 4 out of 60\n",
      "Epoch: 62 Step: 13268 Index:-0.4636 R2:0.5211 0.4083 0.4406 RMSE:0.7448 0.9140 0.7829 Tau:0.5284 0.4504 0.4339\n",
      "Epoch: 63 Step: 13482 Index:-0.4321 R2:0.5270 0.4180 0.4367 RMSE:0.7172 0.8848 0.7571 Tau:0.5345 0.4528 0.4304\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 64 Step: 13696 Index:-0.4489 R2:0.5288 0.4227 0.4364 RMSE:0.7318 0.9033 0.7853 Tau:0.5338 0.4545 0.4443\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 65 Step: 13910 Index:-0.4939 R2:0.5265 0.4109 0.4202 RMSE:0.7473 0.9293 0.8050 Tau:0.5367 0.4354 0.4352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 60\n",
      "Epoch: 66 Step: 14124 Index:-0.4474 R2:0.5364 0.4197 0.4385 RMSE:0.7150 0.8964 0.7740 Tau:0.5359 0.4490 0.4435\n",
      "EarlyStopping counter: 4 out of 60\n",
      "Epoch: 67 Step: 14338 Index:-0.4393 R2:0.5268 0.4155 0.4344 RMSE:0.7134 0.8927 0.7728 Tau:0.5302 0.4534 0.4398\n",
      "Epoch: 68 Step: 14552 Index:-0.4175 R2:0.5464 0.4304 0.4447 RMSE:0.6998 0.8818 0.7624 Tau:0.5481 0.4643 0.4472\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 69 Step: 14766 Index:-0.4455 R2:0.5486 0.4283 0.4411 RMSE:0.7232 0.9050 0.7853 Tau:0.5505 0.4596 0.4425\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 70 Step: 14980 Index:-0.4699 R2:0.5627 0.4293 0.4616 RMSE:0.7466 0.9297 0.8081 Tau:0.5553 0.4599 0.4414\n",
      "EarlyStopping counter: 3 out of 60\n",
      "Epoch: 71 Step: 15194 Index:-0.4254 R2:0.5407 0.4228 0.4496 RMSE:0.7028 0.8813 0.7515 Tau:0.5386 0.4558 0.4458\n",
      "EarlyStopping counter: 4 out of 60\n",
      "Epoch: 72 Step: 15408 Index:-0.4663 R2:0.5466 0.4334 0.4431 RMSE:0.7468 0.9296 0.8177 Tau:0.5441 0.4633 0.4428\n",
      "EarlyStopping counter: 5 out of 60\n",
      "Epoch: 73 Step: 15622 Index:-0.4264 R2:0.5658 0.4348 0.4534 RMSE:0.7305 0.8965 0.7727 Tau:0.5605 0.4701 0.4332\n",
      "Epoch: 74 Step: 15836 Index:-0.3721 R2:0.5682 0.4585 0.4591 RMSE:0.6859 0.8540 0.7467 Tau:0.5637 0.4820 0.4528\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 75 Step: 16050 Index:-0.4063 R2:0.5677 0.4641 0.4488 RMSE:0.7183 0.8927 0.7932 Tau:0.5643 0.4864 0.4492\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 76 Step: 16264 Index:-0.3833 R2:0.5649 0.4509 0.4579 RMSE:0.6878 0.8643 0.7531 Tau:0.5596 0.4810 0.4466\n",
      "EarlyStopping counter: 3 out of 60\n",
      "Epoch: 77 Step: 16478 Index:-0.4918 R2:0.5757 0.4678 0.4619 RMSE:0.8044 0.9701 0.8735 Tau:0.5682 0.4782 0.4549\n",
      "Epoch: 78 Step: 16692 Index:-0.3689 R2:0.5617 0.4618 0.4535 RMSE:0.6875 0.8549 0.7582 Tau:0.5579 0.4861 0.4532\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 79 Step: 16906 Index:-0.4003 R2:0.5645 0.4472 0.4511 RMSE:0.7039 0.8905 0.7821 Tau:0.5610 0.4901 0.4423\n",
      "Epoch: 80 Step: 17120 Index:-0.3382 R2:0.5921 0.4842 0.4766 RMSE:0.6658 0.8345 0.7308 Tau:0.5783 0.4963 0.4566\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 81 Step: 17334 Index:-0.3551 R2:0.5801 0.4816 0.4564 RMSE:0.6811 0.8493 0.7548 Tau:0.5759 0.4942 0.4598\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 82 Step: 17548 Index:-0.3512 R2:0.5948 0.4716 0.4741 RMSE:0.6699 0.8454 0.7326 Tau:0.5794 0.4942 0.4471\n",
      "EarlyStopping counter: 3 out of 60\n",
      "Epoch: 83 Step: 17762 Index:-0.3565 R2:0.6004 0.4672 0.4755 RMSE:0.6556 0.8480 0.7354 Tau:0.5842 0.4915 0.4563\n",
      "EarlyStopping counter: 4 out of 60\n",
      "Epoch: 84 Step: 17976 Index:-0.3533 R2:0.6060 0.4699 0.4754 RMSE:0.6585 0.8452 0.7344 Tau:0.5890 0.4918 0.4549\n",
      "EarlyStopping counter: 5 out of 60\n",
      "Epoch: 85 Step: 18190 Index:-0.3404 R2:0.5980 0.4784 0.4724 RMSE:0.6567 0.8390 0.7391 Tau:0.5855 0.4986 0.4579\n",
      "EarlyStopping counter: 6 out of 60\n",
      "Epoch: 86 Step: 18404 Index:-0.3810 R2:0.5968 0.4511 0.4794 RMSE:0.6585 0.8596 0.7299 Tau:0.5828 0.4786 0.4538\n",
      "Epoch: 87 Step: 18618 Index:-0.3118 R2:0.6158 0.4972 0.4821 RMSE:0.6547 0.8257 0.7269 Tau:0.5951 0.5139 0.4535\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 88 Step: 18832 Index:-0.3435 R2:0.6057 0.4828 0.4794 RMSE:0.6658 0.8506 0.7508 Tau:0.5859 0.5071 0.4574\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 89 Step: 19046 Index:-0.3465 R2:0.6134 0.4874 0.4850 RMSE:0.6580 0.8458 0.7466 Tau:0.5913 0.4993 0.4628\n",
      "EarlyStopping counter: 3 out of 60\n",
      "Epoch: 90 Step: 19260 Index:-0.3791 R2:0.6041 0.4592 0.4860 RMSE:0.6797 0.8682 0.7368 Tau:0.5845 0.4891 0.4457\n",
      "EarlyStopping counter: 4 out of 60\n",
      "Epoch: 91 Step: 19474 Index:-0.3634 R2:0.6064 0.4668 0.4801 RMSE:0.6694 0.8600 0.7418 Tau:0.5853 0.4966 0.4544\n",
      "EarlyStopping counter: 5 out of 60\n",
      "Epoch: 92 Step: 19688 Index:-0.3415 R2:0.6127 0.4801 0.4735 RMSE:0.6752 0.8496 0.7547 Tau:0.5969 0.5082 0.4532\n",
      "Epoch: 93 Step: 19902 Index:-0.3107 R2:0.6076 0.5000 0.4628 RMSE:0.6546 0.8273 0.7459 Tau:0.5914 0.5167 0.4502\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 94 Step: 20116 Index:-0.3327 R2:0.6084 0.4818 0.4832 RMSE:0.6537 0.8348 0.7261 Tau:0.5872 0.5020 0.4571\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 95 Step: 20330 Index:-0.3171 R2:0.6117 0.4955 0.4797 RMSE:0.6472 0.8262 0.7343 Tau:0.5902 0.5092 0.4629\n",
      "EarlyStopping counter: 3 out of 60\n",
      "Epoch: 96 Step: 20544 Index:-0.3394 R2:0.6159 0.4876 0.4848 RMSE:0.6504 0.8384 0.7403 Tau:0.5922 0.4990 0.4621\n",
      "EarlyStopping counter: 4 out of 60\n",
      "Epoch: 97 Step: 20758 Index:-0.3246 R2:0.6332 0.5109 0.4909 RMSE:0.6501 0.8334 0.7482 Tau:0.6049 0.5088 0.4661\n",
      "EarlyStopping counter: 5 out of 60\n",
      "Epoch: 98 Step: 20972 Index:-0.3539 R2:0.6217 0.4991 0.4802 RMSE:0.6798 0.8647 0.7828 Tau:0.5951 0.5109 0.4498\n",
      "EarlyStopping counter: 6 out of 60\n",
      "Epoch: 99 Step: 21186 Index:-0.3444 R2:0.6451 0.5095 0.5005 RMSE:0.6872 0.8746 0.7858 Tau:0.6112 0.5303 0.4526\n",
      "Epoch: 100 Step: 21400 Index:-0.3054 R2:0.6452 0.5111 0.4957 RMSE:0.6383 0.8296 0.7410 Tau:0.6117 0.5241 0.4578\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 101 Step: 21614 Index:-0.3059 R2:0.6284 0.5121 0.4910 RMSE:0.6342 0.8161 0.7326 Tau:0.6016 0.5102 0.4613\n",
      "Epoch: 102 Step: 21828 Index:-0.2805 R2:0.6513 0.5168 0.4994 RMSE:0.6177 0.8094 0.7190 Tau:0.6181 0.5289 0.4604\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 103 Step: 22042 Index:-0.2886 R2:0.6426 0.5154 0.4948 RMSE:0.6203 0.8090 0.7267 Tau:0.6092 0.5204 0.4624\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 104 Step: 22256 Index:-0.2806 R2:0.6354 0.5147 0.4945 RMSE:0.6266 0.8071 0.7223 Tau:0.6042 0.5265 0.4610\n",
      "EarlyStopping counter: 3 out of 60\n",
      "Epoch: 105 Step: 22470 Index:-0.3340 R2:0.6352 0.4807 0.4985 RMSE:0.6293 0.8374 0.7183 Tau:0.6032 0.5034 0.4561\n",
      "EarlyStopping counter: 4 out of 60\n",
      "Epoch: 106 Step: 22684 Index:-0.3026 R2:0.6390 0.5124 0.4960 RMSE:0.6292 0.8189 0.7341 Tau:0.6093 0.5163 0.4664\n",
      "EarlyStopping counter: 5 out of 60\n",
      "Epoch: 107 Step: 22898 Index:-0.2975 R2:0.6504 0.5107 0.5029 RMSE:0.6345 0.8213 0.7211 Tau:0.6140 0.5238 0.4629\n",
      "EarlyStopping counter: 6 out of 60\n",
      "Epoch: 108 Step: 23112 Index:-0.2923 R2:0.6424 0.5179 0.4944 RMSE:0.6248 0.8175 0.7379 Tau:0.6115 0.5252 0.4654\n",
      "EarlyStopping counter: 7 out of 60\n",
      "Epoch: 109 Step: 23326 Index:-0.2858 R2:0.6604 0.5165 0.5049 RMSE:0.6176 0.8143 0.7216 Tau:0.6218 0.5286 0.4643\n",
      "EarlyStopping counter: 8 out of 60\n",
      "Epoch: 110 Step: 23540 Index:-0.3096 R2:0.6617 0.5253 0.4976 RMSE:0.6584 0.8538 0.7713 Tau:0.6230 0.5442 0.4641\n",
      "Epoch: 111 Step: 23754 Index:-0.2564 R2:0.6714 0.5270 0.5054 RMSE:0.6018 0.7985 0.7124 Tau:0.6294 0.5421 0.4639\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 112 Step: 23968 Index:-0.2980 R2:0.6636 0.5078 0.5024 RMSE:0.6345 0.8266 0.7249 Tau:0.6242 0.5286 0.4607\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 113 Step: 24182 Index:-0.2831 R2:0.6472 0.5245 0.5014 RMSE:0.6312 0.8147 0.7284 Tau:0.6120 0.5316 0.4710\n",
      "EarlyStopping counter: 3 out of 60\n",
      "Epoch: 114 Step: 24396 Index:-0.2570 R2:0.6684 0.5309 0.5026 RMSE:0.5996 0.7940 0.7143 Tau:0.6286 0.5370 0.4715\n",
      "EarlyStopping counter: 4 out of 60\n",
      "Epoch: 115 Step: 24610 Index:-0.2654 R2:0.6687 0.5270 0.5106 RMSE:0.6057 0.8048 0.7185 Tau:0.6259 0.5394 0.4594\n",
      "EarlyStopping counter: 5 out of 60\n",
      "Epoch: 116 Step: 24824 Index:-0.3057 R2:0.6682 0.5085 0.5165 RMSE:0.6047 0.8261 0.7219 Tau:0.6270 0.5204 0.4715\n",
      "EarlyStopping counter: 6 out of 60\n",
      "Epoch: 117 Step: 25038 Index:-0.2685 R2:0.6666 0.5413 0.5121 RMSE:0.6280 0.8124 0.7414 Tau:0.6267 0.5438 0.4681\n",
      "Epoch: 118 Step: 25252 Index:-0.2549 R2:0.6732 0.5320 0.5156 RMSE:0.5947 0.7936 0.7060 Tau:0.6299 0.5387 0.4679\n",
      "Epoch: 119 Step: 25466 Index:-0.2525 R2:0.6768 0.5363 0.5111 RMSE:0.6035 0.7980 0.7171 Tau:0.6314 0.5455 0.4654\n",
      "Epoch: 120 Step: 25680 Index:-0.2327 R2:0.6817 0.5389 0.5105 RMSE:0.5891 0.7868 0.7095 Tau:0.6372 0.5540 0.4684\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 121 Step: 25894 Index:-0.2966 R2:0.6814 0.5408 0.5135 RMSE:0.6516 0.8500 0.7757 Tau:0.6370 0.5534 0.4699\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 122 Step: 26108 Index:-0.2661 R2:0.6816 0.5227 0.5113 RMSE:0.5887 0.8066 0.7155 Tau:0.6354 0.5404 0.4637\n",
      "EarlyStopping counter: 3 out of 60\n",
      "Epoch: 123 Step: 26322 Index:-0.2464 R2:0.6828 0.5330 0.5146 RMSE:0.5939 0.7954 0.7072 Tau:0.6372 0.5489 0.4733\n",
      "EarlyStopping counter: 4 out of 60\n",
      "Epoch: 124 Step: 26536 Index:-0.2637 R2:0.6789 0.5329 0.5138 RMSE:0.5859 0.7984 0.7106 Tau:0.6352 0.5347 0.4708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 60\n",
      "Epoch: 125 Step: 26750 Index:-0.2466 R2:0.6578 0.5358 0.4960 RMSE:0.6058 0.7911 0.7220 Tau:0.6195 0.5445 0.4558\n",
      "EarlyStopping counter: 6 out of 60\n",
      "Epoch: 126 Step: 26964 Index:-0.2984 R2:0.6755 0.5171 0.5131 RMSE:0.5924 0.8310 0.7254 Tau:0.6312 0.5326 0.4688\n",
      "EarlyStopping counter: 7 out of 60\n",
      "Epoch: 127 Step: 27178 Index:-0.2383 R2:0.6792 0.5376 0.5125 RMSE:0.5910 0.7880 0.7061 Tau:0.6358 0.5496 0.4733\n",
      "EarlyStopping counter: 8 out of 60\n",
      "Epoch: 128 Step: 27392 Index:-0.2991 R2:0.6792 0.5151 0.5092 RMSE:0.6166 0.8389 0.7416 Tau:0.6328 0.5398 0.4600\n",
      "EarlyStopping counter: 9 out of 60\n",
      "Epoch: 129 Step: 27606 Index:-0.2441 R2:0.6986 0.5384 0.5256 RMSE:0.5755 0.7934 0.7069 Tau:0.6466 0.5493 0.4782\n",
      "EarlyStopping counter: 10 out of 60\n",
      "Epoch: 130 Step: 27820 Index:-0.2712 R2:0.6998 0.5325 0.5223 RMSE:0.5923 0.8177 0.7273 Tau:0.6485 0.5466 0.4728\n",
      "EarlyStopping counter: 11 out of 60\n",
      "Epoch: 131 Step: 28034 Index:-0.2535 R2:0.6775 0.5454 0.5044 RMSE:0.6106 0.8147 0.7478 Tau:0.6339 0.5612 0.4626\n",
      "EarlyStopping counter: 12 out of 60\n",
      "Epoch: 132 Step: 28248 Index:-0.2421 R2:0.6962 0.5318 0.5223 RMSE:0.5765 0.7996 0.7086 Tau:0.6452 0.5574 0.4578\n",
      "EarlyStopping counter: 13 out of 60\n",
      "Epoch: 133 Step: 28462 Index:-0.3255 R2:0.6860 0.5127 0.5212 RMSE:0.6211 0.8557 0.7498 Tau:0.6369 0.5303 0.4658\n",
      "EarlyStopping counter: 14 out of 60\n",
      "Epoch: 134 Step: 28676 Index:-0.2534 R2:0.7069 0.5468 0.5264 RMSE:0.5883 0.8048 0.7231 Tau:0.6545 0.5513 0.4832\n",
      "EarlyStopping counter: 15 out of 60\n",
      "Epoch: 135 Step: 28890 Index:-0.2692 R2:0.6908 0.5303 0.5204 RMSE:0.5786 0.8093 0.7152 Tau:0.6409 0.5401 0.4716\n",
      "Epoch: 136 Step: 29104 Index:-0.2312 R2:0.7086 0.5383 0.5261 RMSE:0.5908 0.7978 0.7063 Tau:0.6548 0.5666 0.4760\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 137 Step: 29318 Index:-0.2970 R2:0.6886 0.5394 0.5160 RMSE:0.6473 0.8429 0.7733 Tau:0.6364 0.5459 0.4698\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 138 Step: 29532 Index:-0.2634 R2:0.7069 0.5252 0.5323 RMSE:0.5658 0.8140 0.7055 Tau:0.6535 0.5506 0.4714\n",
      "EarlyStopping counter: 3 out of 60\n",
      "Epoch: 139 Step: 29746 Index:-0.2439 R2:0.7130 0.5335 0.5297 RMSE:0.5609 0.7942 0.6945 Tau:0.6570 0.5503 0.4739\n",
      "EarlyStopping counter: 4 out of 60\n",
      "Epoch: 140 Step: 29960 Index:-0.2994 R2:0.7134 0.5265 0.5294 RMSE:0.6206 0.8528 0.7553 Tau:0.6568 0.5534 0.4686\n",
      "Epoch: 141 Step: 30174 Index:-0.2123 R2:0.7158 0.5559 0.5372 RMSE:0.5549 0.7779 0.6980 Tau:0.6572 0.5656 0.4760\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 142 Step: 30388 Index:-0.2387 R2:0.7142 0.5296 0.5173 RMSE:0.5702 0.7999 0.7078 Tau:0.6584 0.5612 0.4673\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 143 Step: 30602 Index:-0.2395 R2:0.7143 0.5412 0.5312 RMSE:0.5727 0.7979 0.7031 Tau:0.6562 0.5585 0.4716\n",
      "EarlyStopping counter: 3 out of 60\n",
      "Epoch: 144 Step: 30816 Index:-0.2310 R2:0.7099 0.5567 0.5344 RMSE:0.5819 0.7973 0.7201 Tau:0.6560 0.5663 0.4818\n",
      "EarlyStopping counter: 4 out of 60\n",
      "Epoch: 145 Step: 31030 Index:-0.2625 R2:0.7148 0.5435 0.5315 RMSE:0.5740 0.8135 0.7234 Tau:0.6586 0.5510 0.4772\n",
      "Epoch: 146 Step: 31244 Index:-0.2042 R2:0.7263 0.5555 0.5356 RMSE:0.5495 0.7746 0.6899 Tau:0.6644 0.5704 0.4682\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 147 Step: 31458 Index:-0.2503 R2:0.7137 0.5483 0.5323 RMSE:0.5726 0.7938 0.7160 Tau:0.6557 0.5435 0.4784\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 148 Step: 31672 Index:-0.2427 R2:0.7060 0.5358 0.5090 RMSE:0.5756 0.7937 0.7154 Tau:0.6528 0.5510 0.4674\n",
      "EarlyStopping counter: 3 out of 60\n",
      "Epoch: 149 Step: 31886 Index:-0.2105 R2:0.7162 0.5578 0.5276 RMSE:0.5536 0.7792 0.7061 Tau:0.6614 0.5687 0.4701\n",
      "EarlyStopping counter: 4 out of 60\n",
      "Epoch: 150 Step: 32100 Index:-0.2179 R2:0.7265 0.5553 0.5295 RMSE:0.5420 0.7811 0.7034 Tau:0.6657 0.5632 0.4772\n",
      "Epoch: 151 Step: 32314 Index:-0.1984 R2:0.7267 0.5618 0.5300 RMSE:0.5492 0.7736 0.7032 Tau:0.6664 0.5751 0.4735\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 152 Step: 32528 Index:-0.2065 R2:0.7180 0.5611 0.5314 RMSE:0.5502 0.7741 0.6978 Tau:0.6612 0.5676 0.4869\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 153 Step: 32742 Index:-0.3023 R2:0.6747 0.5344 0.5095 RMSE:0.6173 0.8309 0.7528 Tau:0.6290 0.5286 0.4656\n",
      "EarlyStopping counter: 3 out of 60\n",
      "Epoch: 154 Step: 32956 Index:-0.2733 R2:0.7359 0.5405 0.5406 RMSE:0.5719 0.8379 0.7345 Tau:0.6728 0.5646 0.4689\n",
      "EarlyStopping counter: 4 out of 60\n",
      "Epoch: 155 Step: 33170 Index:-0.2260 R2:0.6956 0.5495 0.5255 RMSE:0.5762 0.7865 0.7018 Tau:0.6484 0.5605 0.4665\n",
      "EarlyStopping counter: 5 out of 60\n",
      "Epoch: 156 Step: 33384 Index:-0.2118 R2:0.7405 0.5572 0.5485 RMSE:0.5282 0.7821 0.6881 Tau:0.6745 0.5704 0.4815\n",
      "EarlyStopping counter: 6 out of 60\n",
      "Epoch: 157 Step: 33598 Index:-0.2309 R2:0.7224 0.5430 0.5298 RMSE:0.5499 0.7914 0.6991 Tau:0.6637 0.5605 0.4729\n",
      "EarlyStopping counter: 7 out of 60\n",
      "Epoch: 158 Step: 33812 Index:-0.3113 R2:0.7350 0.5118 0.5336 RMSE:0.5479 0.8388 0.7120 Tau:0.6718 0.5275 0.4820\n",
      "EarlyStopping counter: 8 out of 60\n",
      "Epoch: 159 Step: 34026 Index:-0.2634 R2:0.7444 0.5259 0.5456 RMSE:0.5252 0.8133 0.6871 Tau:0.6801 0.5500 0.4813\n",
      "EarlyStopping counter: 9 out of 60\n",
      "Epoch: 160 Step: 34240 Index:-0.2676 R2:0.7067 0.5235 0.5244 RMSE:0.5612 0.8206 0.7058 Tau:0.6518 0.5530 0.4597\n",
      "EarlyStopping counter: 10 out of 60\n",
      "Epoch: 161 Step: 34454 Index:-0.2386 R2:0.7463 0.5371 0.5439 RMSE:0.5273 0.7960 0.6846 Tau:0.6807 0.5574 0.4811\n",
      "Epoch: 162 Step: 34668 Index:-0.1960 R2:0.7360 0.5575 0.5320 RMSE:0.5413 0.7759 0.7003 Tau:0.6728 0.5799 0.4681\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 163 Step: 34882 Index:-0.2452 R2:0.7292 0.5455 0.5374 RMSE:0.5398 0.7972 0.7011 Tau:0.6691 0.5520 0.4740\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 164 Step: 35096 Index:-0.2292 R2:0.7490 0.5566 0.5373 RMSE:0.5333 0.7961 0.7119 Tau:0.6808 0.5670 0.4742\n",
      "EarlyStopping counter: 3 out of 60\n",
      "Epoch: 165 Step: 35310 Index:-0.2462 R2:0.7445 0.5475 0.5494 RMSE:0.5367 0.8105 0.7090 Tau:0.6807 0.5642 0.4819\n",
      "EarlyStopping counter: 4 out of 60\n",
      "Epoch: 166 Step: 35524 Index:-0.2989 R2:0.7260 0.5234 0.5222 RMSE:0.5439 0.8379 0.7179 Tau:0.6665 0.5391 0.4677\n",
      "EarlyStopping counter: 5 out of 60\n",
      "Epoch: 167 Step: 35738 Index:-0.2209 R2:0.7422 0.5646 0.5449 RMSE:0.5405 0.7835 0.7086 Tau:0.6761 0.5625 0.4761\n",
      "EarlyStopping counter: 6 out of 60\n",
      "Epoch: 168 Step: 35952 Index:-0.2457 R2:0.7473 0.5407 0.5475 RMSE:0.5216 0.7990 0.6890 Tau:0.6800 0.5534 0.4702\n",
      "EarlyStopping counter: 7 out of 60\n",
      "Epoch: 169 Step: 36166 Index:-0.2402 R2:0.7608 0.5443 0.5489 RMSE:0.5124 0.8007 0.6882 Tau:0.6908 0.5605 0.4818\n",
      "EarlyStopping counter: 8 out of 60\n",
      "Epoch: 170 Step: 36380 Index:-0.2422 R2:0.7425 0.5326 0.5432 RMSE:0.5317 0.7966 0.6862 Tau:0.6780 0.5544 0.4674\n",
      "EarlyStopping counter: 9 out of 60\n",
      "Epoch: 171 Step: 36594 Index:-0.2320 R2:0.7403 0.5505 0.5368 RMSE:0.5300 0.8027 0.7091 Tau:0.6804 0.5707 0.4748\n",
      "EarlyStopping counter: 10 out of 60\n",
      "Epoch: 172 Step: 36808 Index:-0.2218 R2:0.7615 0.5543 0.5485 RMSE:0.5238 0.7905 0.6919 Tau:0.6905 0.5687 0.4807\n",
      "EarlyStopping counter: 11 out of 60\n",
      "Epoch: 173 Step: 37022 Index:-0.2540 R2:0.7582 0.5561 0.5463 RMSE:0.5506 0.8206 0.7355 Tau:0.6891 0.5666 0.4796\n",
      "EarlyStopping counter: 12 out of 60\n",
      "Epoch: 174 Step: 37236 Index:-0.2172 R2:0.7432 0.5638 0.5436 RMSE:0.5359 0.7885 0.7057 Tau:0.6793 0.5714 0.4804\n",
      "EarlyStopping counter: 13 out of 60\n",
      "Epoch: 175 Step: 37450 Index:-0.2038 R2:0.7480 0.5704 0.5391 RMSE:0.5475 0.7847 0.7228 Tau:0.6794 0.5809 0.4725\n",
      "EarlyStopping counter: 14 out of 60\n",
      "Epoch: 176 Step: 37664 Index:-0.2171 R2:0.7461 0.5513 0.5373 RMSE:0.5332 0.7861 0.7047 Tau:0.6759 0.5690 0.4683\n",
      "EarlyStopping counter: 15 out of 60\n",
      "Epoch: 177 Step: 37878 Index:-0.2322 R2:0.7656 0.5515 0.5527 RMSE:0.5009 0.7927 0.6873 Tau:0.6946 0.5605 0.4868\n",
      "EarlyStopping counter: 16 out of 60\n",
      "Epoch: 178 Step: 38092 Index:-0.2484 R2:0.7492 0.5426 0.5445 RMSE:0.5185 0.7963 0.6968 Tau:0.6810 0.5479 0.4802\n",
      "EarlyStopping counter: 17 out of 60\n",
      "Epoch: 179 Step: 38306 Index:-0.2665 R2:0.7680 0.5398 0.5559 RMSE:0.5189 0.8219 0.7037 Tau:0.6945 0.5554 0.4758\n",
      "EarlyStopping counter: 18 out of 60\n",
      "Epoch: 180 Step: 38520 Index:-0.2231 R2:0.7685 0.5598 0.5513 RMSE:0.5080 0.7910 0.7000 Tau:0.6962 0.5680 0.4883\n",
      "EarlyStopping counter: 19 out of 60\n",
      "Epoch: 181 Step: 38734 Index:-0.2228 R2:0.7473 0.5530 0.5476 RMSE:0.5223 0.7976 0.6993 Tau:0.6805 0.5748 0.4801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 20 out of 60\n",
      "Epoch: 182 Step: 38948 Index:-0.2335 R2:0.7589 0.5425 0.5429 RMSE:0.5114 0.7944 0.6916 Tau:0.6885 0.5608 0.4737\n",
      "EarlyStopping counter: 21 out of 60\n",
      "Epoch: 183 Step: 39162 Index:-0.2091 R2:0.7695 0.5529 0.5457 RMSE:0.5060 0.7808 0.6864 Tau:0.6949 0.5717 0.4779\n",
      "EarlyStopping counter: 22 out of 60\n",
      "Epoch: 184 Step: 39376 Index:-0.2057 R2:0.7731 0.5595 0.5530 RMSE:0.5090 0.7836 0.6863 Tau:0.7016 0.5778 0.4856\n",
      "EarlyStopping counter: 23 out of 60\n",
      "Epoch: 185 Step: 39590 Index:-0.2700 R2:0.7527 0.5286 0.5467 RMSE:0.5267 0.8108 0.6868 Tau:0.6867 0.5408 0.4818\n",
      "EarlyStopping counter: 24 out of 60\n",
      "Epoch: 186 Step: 39804 Index:-0.2305 R2:0.7708 0.5493 0.5570 RMSE:0.4992 0.7913 0.6789 Tau:0.6987 0.5608 0.4827\n",
      "EarlyStopping counter: 25 out of 60\n",
      "Epoch: 187 Step: 40018 Index:-0.2813 R2:0.7673 0.5312 0.5476 RMSE:0.5120 0.8282 0.7051 Tau:0.6954 0.5469 0.4793\n",
      "EarlyStopping counter: 26 out of 60\n",
      "Epoch: 188 Step: 40232 Index:-0.2237 R2:0.7734 0.5677 0.5529 RMSE:0.5254 0.7907 0.7173 Tau:0.6991 0.5670 0.4872\n",
      "EarlyStopping counter: 27 out of 60\n",
      "Epoch: 189 Step: 40446 Index:-0.2999 R2:0.6831 0.4920 0.4860 RMSE:0.6009 0.8258 0.7232 Tau:0.6445 0.5258 0.4511\n",
      "EarlyStopping counter: 28 out of 60\n",
      "Epoch: 190 Step: 40660 Index:-0.2385 R2:0.7783 0.5626 0.5657 RMSE:0.5231 0.8075 0.7106 Tau:0.7035 0.5690 0.4799\n",
      "EarlyStopping counter: 29 out of 60\n",
      "Epoch: 191 Step: 40874 Index:-0.2450 R2:0.7630 0.5505 0.5576 RMSE:0.5294 0.8024 0.6899 Tau:0.6923 0.5574 0.4843\n",
      "EarlyStopping counter: 30 out of 60\n",
      "Epoch: 192 Step: 41088 Index:-0.2114 R2:0.7769 0.5723 0.5623 RMSE:0.5155 0.7797 0.7019 Tau:0.7011 0.5683 0.4805\n",
      "Epoch: 193 Step: 41302 Index:-0.1881 R2:0.7771 0.5783 0.5675 RMSE:0.5033 0.7723 0.6903 Tau:0.7026 0.5843 0.4805\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 194 Step: 41516 Index:-0.2687 R2:0.7737 0.5355 0.5473 RMSE:0.5126 0.8177 0.7103 Tau:0.6997 0.5489 0.4706\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 195 Step: 41730 Index:-0.2307 R2:0.7843 0.5418 0.5586 RMSE:0.4885 0.7898 0.6751 Tau:0.7090 0.5591 0.4750\n",
      "EarlyStopping counter: 3 out of 60\n",
      "Epoch: 196 Step: 41944 Index:-0.2264 R2:0.7898 0.5550 0.5655 RMSE:0.4801 0.7794 0.6716 Tau:0.7108 0.5530 0.4911\n",
      "EarlyStopping counter: 4 out of 60\n",
      "Epoch: 197 Step: 42158 Index:-0.3310 R2:0.7758 0.5312 0.5547 RMSE:0.5726 0.8785 0.7665 Tau:0.7012 0.5476 0.4816\n",
      "EarlyStopping counter: 5 out of 60\n",
      "Epoch: 198 Step: 42372 Index:-0.1884 R2:0.7847 0.5737 0.5531 RMSE:0.4814 0.7724 0.6949 Tau:0.7104 0.5840 0.4821\n",
      "EarlyStopping counter: 6 out of 60\n",
      "Epoch: 199 Step: 42586 Index:-0.2203 R2:0.7887 0.5631 0.5591 RMSE:0.4937 0.7954 0.7038 Tau:0.7112 0.5751 0.4903\n",
      "EarlyStopping counter: 7 out of 60\n",
      "Epoch: 200 Step: 42800 Index:-0.2239 R2:0.7877 0.5610 0.5683 RMSE:0.4960 0.7973 0.6991 Tau:0.7106 0.5734 0.4889\n",
      "EarlyStopping counter: 8 out of 60\n",
      "Epoch: 201 Step: 43014 Index:-0.2060 R2:0.7917 0.5655 0.5662 RMSE:0.4803 0.7875 0.6879 Tau:0.7120 0.5816 0.4901\n",
      "EarlyStopping counter: 9 out of 60\n",
      "Epoch: 202 Step: 43228 Index:-0.2801 R2:0.7560 0.5166 0.5185 RMSE:0.5249 0.8202 0.7116 Tau:0.6942 0.5401 0.4847\n",
      "EarlyStopping counter: 10 out of 60\n",
      "Epoch: 203 Step: 43442 Index:-0.2531 R2:0.7898 0.5476 0.5645 RMSE:0.4752 0.8105 0.6897 Tau:0.7105 0.5574 0.4890\n",
      "EarlyStopping counter: 11 out of 60\n",
      "Epoch: 204 Step: 43656 Index:-0.2444 R2:0.7852 0.5543 0.5668 RMSE:0.4889 0.8097 0.6951 Tau:0.7114 0.5653 0.4848\n",
      "EarlyStopping counter: 12 out of 60\n",
      "Epoch: 205 Step: 43870 Index:-0.2029 R2:0.7872 0.5690 0.5672 RMSE:0.4778 0.7722 0.6792 Tau:0.7105 0.5693 0.4899\n",
      "EarlyStopping counter: 13 out of 60\n",
      "Epoch: 206 Step: 44084 Index:-0.2128 R2:0.7839 0.5565 0.5603 RMSE:0.4859 0.7784 0.6797 Tau:0.7099 0.5656 0.4745\n",
      "EarlyStopping counter: 14 out of 60\n",
      "Epoch: 207 Step: 44298 Index:-0.2952 R2:0.7263 0.5093 0.5112 RMSE:0.5425 0.8251 0.7154 Tau:0.6729 0.5299 0.4719\n",
      "EarlyStopping counter: 15 out of 60\n",
      "Epoch: 208 Step: 44512 Index:-0.1891 R2:0.8013 0.5685 0.5694 RMSE:0.4772 0.7656 0.6648 Tau:0.7218 0.5765 0.4792\n",
      "EarlyStopping counter: 16 out of 60\n",
      "Epoch: 209 Step: 44726 Index:-0.2061 R2:0.7900 0.5708 0.5599 RMSE:0.4765 0.7802 0.6921 Tau:0.7101 0.5741 0.4881\n",
      "EarlyStopping counter: 17 out of 60\n",
      "Epoch: 210 Step: 44940 Index:-0.2374 R2:0.7954 0.5492 0.5624 RMSE:0.4697 0.7938 0.6833 Tau:0.7148 0.5564 0.4916\n",
      "EarlyStopping counter: 18 out of 60\n",
      "Epoch: 211 Step: 45154 Index:-0.1885 R2:0.7970 0.5700 0.5619 RMSE:0.4825 0.7741 0.6803 Tau:0.7217 0.5857 0.4899\n",
      "Epoch: 212 Step: 45368 Index:-0.1816 R2:0.8019 0.5813 0.5744 RMSE:0.4699 0.7638 0.6796 Tau:0.7207 0.5823 0.4828\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 213 Step: 45582 Index:-0.1892 R2:0.7909 0.5860 0.5700 RMSE:0.4976 0.7779 0.7030 Tau:0.7121 0.5887 0.4934\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 214 Step: 45796 Index:-0.2123 R2:0.7844 0.5554 0.5634 RMSE:0.4817 0.7834 0.6781 Tau:0.7103 0.5710 0.4821\n",
      "EarlyStopping counter: 3 out of 60\n",
      "Epoch: 215 Step: 46010 Index:-0.2277 R2:0.7919 0.5645 0.5647 RMSE:0.4724 0.7835 0.6794 Tau:0.7146 0.5557 0.4932\n",
      "EarlyStopping counter: 4 out of 60\n",
      "Epoch: 216 Step: 46224 Index:-0.2432 R2:0.7955 0.5592 0.5660 RMSE:0.5081 0.8132 0.7179 Tau:0.7140 0.5700 0.4753\n",
      "EarlyStopping counter: 5 out of 60\n",
      "Epoch: 217 Step: 46438 Index:-0.1927 R2:0.8001 0.5849 0.5683 RMSE:0.4853 0.7716 0.7026 Tau:0.7176 0.5789 0.4906\n",
      "EarlyStopping counter: 6 out of 60\n",
      "Epoch: 218 Step: 46652 Index:-0.1988 R2:0.7994 0.5824 0.5712 RMSE:0.4785 0.7695 0.6777 Tau:0.7196 0.5707 0.4844\n",
      "EarlyStopping counter: 7 out of 60\n",
      "Epoch: 219 Step: 46866 Index:-0.1816 R2:0.8018 0.5820 0.5618 RMSE:0.4698 0.7714 0.6978 Tau:0.7211 0.5897 0.4964\n",
      "EarlyStopping counter: 8 out of 60\n",
      "Epoch: 220 Step: 47080 Index:-0.2320 R2:0.7947 0.5457 0.5441 RMSE:0.4715 0.7959 0.6968 Tau:0.7184 0.5639 0.4788\n",
      "Epoch: 221 Step: 47294 Index:-0.1717 R2:0.8096 0.5826 0.5745 RMSE:0.4602 0.7594 0.6754 Tau:0.7280 0.5877 0.4928\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 222 Step: 47508 Index:-0.2335 R2:0.7864 0.5588 0.5675 RMSE:0.4784 0.7933 0.6800 Tau:0.7098 0.5598 0.4828\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 223 Step: 47722 Index:-0.2444 R2:0.7944 0.5371 0.5523 RMSE:0.4758 0.8015 0.6867 Tau:0.7161 0.5571 0.4804\n",
      "EarlyStopping counter: 3 out of 60\n",
      "Epoch: 224 Step: 47936 Index:-0.7485 R2:0.5401 0.3839 0.4180 RMSE:0.8898 1.2023 1.0047 Tau:0.5551 0.4538 0.3716\n",
      "EarlyStopping counter: 4 out of 60\n",
      "Epoch: 225 Step: 48150 Index:-0.2420 R2:0.7675 0.5483 0.5455 RMSE:0.5155 0.7981 0.6987 Tau:0.7001 0.5561 0.4802\n",
      "EarlyStopping counter: 5 out of 60\n",
      "Epoch: 226 Step: 48364 Index:-0.2278 R2:0.7959 0.5585 0.5583 RMSE:0.4681 0.7890 0.6902 Tau:0.7177 0.5612 0.4854\n",
      "EarlyStopping counter: 6 out of 60\n",
      "Epoch: 227 Step: 48578 Index:-0.2220 R2:0.8050 0.5676 0.5657 RMSE:0.4671 0.7835 0.6965 Tau:0.7263 0.5615 0.4914\n",
      "EarlyStopping counter: 7 out of 60\n",
      "Epoch: 228 Step: 48792 Index:-0.1829 R2:0.8085 0.5842 0.5756 RMSE:0.4552 0.7536 0.6677 Tau:0.7257 0.5707 0.4961\n",
      "EarlyStopping counter: 8 out of 60\n",
      "Epoch: 229 Step: 49006 Index:-0.2011 R2:0.8063 0.5759 0.5766 RMSE:0.4599 0.7765 0.6877 Tau:0.7237 0.5755 0.4986\n",
      "EarlyStopping counter: 9 out of 60\n",
      "Epoch: 230 Step: 49220 Index:-0.2037 R2:0.8138 0.5615 0.5656 RMSE:0.4474 0.7829 0.6825 Tau:0.7323 0.5792 0.4863\n",
      "Epoch: 231 Step: 49434 Index:-0.1668 R2:0.8206 0.5909 0.5716 RMSE:0.4552 0.7556 0.6875 Tau:0.7355 0.5887 0.4879\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 232 Step: 49648 Index:-0.1939 R2:0.7930 0.5744 0.5527 RMSE:0.4711 0.7748 0.7079 Tau:0.7147 0.5809 0.4897\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 233 Step: 49862 Index:-0.2206 R2:0.8076 0.5542 0.5654 RMSE:0.4549 0.7858 0.6819 Tau:0.7259 0.5653 0.4811\n",
      "Epoch: 234 Step: 50076 Index:-0.1538 R2:0.8140 0.5903 0.5701 RMSE:0.4561 0.7456 0.6708 Tau:0.7293 0.5918 0.4818\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 235 Step: 50290 Index:-0.2161 R2:0.8023 0.5683 0.5766 RMSE:0.4883 0.7930 0.7008 Tau:0.7219 0.5768 0.4903\n",
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 236 Step: 50504 Index:-0.2592 R2:0.8021 0.5530 0.5511 RMSE:0.4877 0.8160 0.7303 Tau:0.7198 0.5568 0.4754\n",
      "EarlyStopping counter: 3 out of 60\n",
      "Epoch: 237 Step: 50718 Index:-0.2019 R2:0.8169 0.5668 0.5780 RMSE:0.4490 0.7723 0.6658 Tau:0.7325 0.5704 0.4984\n",
      "Epoch: 238 Step: 50932 Index:-0.1298 R2:0.8151 0.6081 0.5742 RMSE:0.4522 0.7315 0.6699 Tau:0.7321 0.6016 0.5017\n",
      "EarlyStopping counter: 1 out of 60\n",
      "Epoch: 239 Step: 51146 Index:-0.2277 R2:0.8111 0.5555 0.5701 RMSE:0.4493 0.7974 0.6805 Tau:0.7310 0.5697 0.4840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 60\n",
      "Epoch: 240 Step: 51360 Index:-0.1965 R2:0.8226 0.5709 0.5672 RMSE:0.4429 0.7679 0.6768 Tau:0.7377 0.5714 0.4929\n",
      "EarlyStopping counter: 3 out of 60\n",
      "Epoch: 241 Step: 51574 Index:-0.2276 R2:0.8246 0.5684 0.5762 RMSE:0.4729 0.8017 0.7097 Tau:0.7384 0.5741 0.4898\n",
      "EarlyStopping counter: 4 out of 60\n",
      "Epoch: 242 Step: 51788 Index:-0.2028 R2:0.8127 0.5684 0.5582 RMSE:0.4538 0.7657 0.6799 Tau:0.7289 0.5629 0.4820\n",
      "EarlyStopping counter: 5 out of 60\n",
      "Epoch: 243 Step: 52002 Index:-0.2272 R2:0.8025 0.5615 0.5570 RMSE:0.4736 0.7809 0.6947 Tau:0.7219 0.5537 0.4917\n",
      "EarlyStopping counter: 6 out of 60\n",
      "Epoch: 244 Step: 52216 Index:-0.2339 R2:0.8162 0.5784 0.5667 RMSE:0.4856 0.8087 0.7358 Tau:0.7329 0.5748 0.4975\n",
      "EarlyStopping counter: 7 out of 60\n",
      "Epoch: 245 Step: 52430 Index:-0.1363 R2:0.8123 0.6077 0.5701 RMSE:0.4561 0.7301 0.6748 Tau:0.7288 0.5938 0.4910\n",
      "EarlyStopping counter: 8 out of 60\n",
      "Epoch: 246 Step: 52644 Index:-0.2194 R2:0.8207 0.5876 0.5829 RMSE:0.4907 0.7942 0.7216 Tau:0.7354 0.5748 0.4925\n",
      "EarlyStopping counter: 9 out of 60\n",
      "Epoch: 247 Step: 52858 Index:-0.2104 R2:0.8197 0.5714 0.5666 RMSE:0.4779 0.7971 0.7162 Tau:0.7357 0.5867 0.4870\n",
      "EarlyStopping counter: 10 out of 60\n",
      "Epoch: 248 Step: 53072 Index:-0.1876 R2:0.8258 0.5853 0.5681 RMSE:0.4627 0.7696 0.6874 Tau:0.7416 0.5819 0.4876\n",
      "EarlyStopping counter: 11 out of 60\n",
      "Epoch: 249 Step: 53286 Index:-0.1834 R2:0.8182 0.5702 0.5637 RMSE:0.4427 0.7700 0.6821 Tau:0.7358 0.5867 0.4830\n",
      "EarlyStopping counter: 12 out of 60\n",
      "Epoch: 250 Step: 53500 Index:-0.1863 R2:0.8203 0.5788 0.5790 RMSE:0.4577 0.7757 0.6912 Tau:0.7357 0.5894 0.4914\n",
      "EarlyStopping counter: 13 out of 60\n",
      "Epoch: 251 Step: 53714 Index:-0.1772 R2:0.8208 0.5804 0.5655 RMSE:0.4469 0.7564 0.6825 Tau:0.7357 0.5792 0.4788\n",
      "EarlyStopping counter: 14 out of 60\n",
      "Epoch: 252 Step: 53928 Index:-0.1862 R2:0.8263 0.5881 0.5811 RMSE:0.4524 0.7637 0.6920 Tau:0.7383 0.5775 0.4927\n",
      "EarlyStopping counter: 15 out of 60\n",
      "Epoch: 253 Step: 54142 Index:-0.2162 R2:0.8124 0.5599 0.5547 RMSE:0.4504 0.7838 0.6929 Tau:0.7299 0.5676 0.4758\n",
      "EarlyStopping counter: 16 out of 60\n",
      "Epoch: 254 Step: 54356 Index:-0.1772 R2:0.8319 0.5948 0.5857 RMSE:0.4532 0.7652 0.6970 Tau:0.7462 0.5880 0.4969\n",
      "EarlyStopping counter: 17 out of 60\n",
      "Epoch: 255 Step: 54570 Index:-0.1822 R2:0.8359 0.5773 0.5793 RMSE:0.4216 0.7723 0.6802 Tau:0.7486 0.5901 0.4918\n",
      "EarlyStopping counter: 18 out of 60\n",
      "Epoch: 256 Step: 54784 Index:-0.1931 R2:0.8316 0.5643 0.5751 RMSE:0.4291 0.7733 0.6682 Tau:0.7457 0.5802 0.4811\n",
      "EarlyStopping counter: 19 out of 60\n",
      "Epoch: 257 Step: 54998 Index:-0.1644 R2:0.8318 0.5768 0.5668 RMSE:0.4313 0.7596 0.6764 Tau:0.7458 0.5952 0.4844\n",
      "EarlyStopping counter: 20 out of 60\n",
      "Epoch: 258 Step: 55212 Index:-0.2276 R2:0.8295 0.5606 0.5890 RMSE:0.4271 0.7936 0.6632 Tau:0.7434 0.5659 0.4926\n",
      "EarlyStopping counter: 21 out of 60\n",
      "Epoch: 259 Step: 55426 Index:-0.1412 R2:0.8280 0.6009 0.5837 RMSE:0.4334 0.7391 0.6702 Tau:0.7404 0.5979 0.4976\n",
      "EarlyStopping counter: 22 out of 60\n",
      "Epoch: 260 Step: 55640 Index:-0.2322 R2:0.8187 0.5838 0.5709 RMSE:0.5239 0.8124 0.7580 Tau:0.7357 0.5802 0.4845\n",
      "EarlyStopping counter: 23 out of 60\n",
      "Epoch: 261 Step: 55854 Index:-0.1448 R2:0.8239 0.5946 0.5813 RMSE:0.4390 0.7467 0.6799 Tau:0.7385 0.6020 0.4976\n",
      "EarlyStopping counter: 24 out of 60\n",
      "Epoch: 262 Step: 56068 Index:-0.2592 R2:0.8290 0.5784 0.5717 RMSE:0.5165 0.8299 0.7684 Tau:0.7390 0.5707 0.4968\n",
      "EarlyStopping counter: 25 out of 60\n",
      "Epoch: 263 Step: 56282 Index:-0.1778 R2:0.8440 0.5729 0.5679 RMSE:0.4197 0.7601 0.6702 Tau:0.7559 0.5823 0.4959\n",
      "EarlyStopping counter: 26 out of 60\n",
      "Epoch: 264 Step: 56496 Index:-0.1845 R2:0.8325 0.5826 0.5672 RMSE:0.4234 0.7616 0.6881 Tau:0.7466 0.5772 0.4883\n",
      "EarlyStopping counter: 27 out of 60\n",
      "Epoch: 265 Step: 56710 Index:-0.1891 R2:0.8394 0.5857 0.5589 RMSE:0.4308 0.7707 0.7171 Tau:0.7507 0.5816 0.4958\n",
      "EarlyStopping counter: 28 out of 60\n",
      "Epoch: 266 Step: 56924 Index:-0.1808 R2:0.8348 0.5897 0.5625 RMSE:0.4437 0.7678 0.7145 Tau:0.7494 0.5870 0.4913\n",
      "EarlyStopping counter: 29 out of 60\n",
      "Epoch: 267 Step: 57138 Index:-0.2003 R2:0.8368 0.5793 0.5567 RMSE:0.4263 0.7659 0.7017 Tau:0.7505 0.5656 0.4934\n",
      "EarlyStopping counter: 30 out of 60\n",
      "Epoch: 268 Step: 57352 Index:-0.1919 R2:0.8450 0.5853 0.5608 RMSE:0.4286 0.7656 0.7058 Tau:0.7554 0.5738 0.4929\n",
      "EarlyStopping counter: 31 out of 60\n",
      "Epoch: 269 Step: 57566 Index:-0.1729 R2:0.8294 0.5962 0.5734 RMSE:0.4673 0.7612 0.6941 Tau:0.7467 0.5884 0.4888\n",
      "EarlyStopping counter: 32 out of 60\n",
      "Epoch: 270 Step: 57780 Index:-0.1879 R2:0.8469 0.5849 0.5762 RMSE:0.4172 0.7633 0.6955 Tau:0.7560 0.5755 0.4941\n",
      "EarlyStopping counter: 33 out of 60\n",
      "Epoch: 271 Step: 57994 Index:-0.1911 R2:0.8455 0.5785 0.5809 RMSE:0.4088 0.7621 0.6786 Tau:0.7547 0.5710 0.4966\n",
      "EarlyStopping counter: 34 out of 60\n",
      "Epoch: 272 Step: 58208 Index:-0.2125 R2:0.8450 0.5630 0.5685 RMSE:0.4248 0.7866 0.6950 Tau:0.7535 0.5741 0.4896\n",
      "EarlyStopping counter: 35 out of 60\n",
      "Epoch: 273 Step: 58422 Index:-0.2279 R2:0.8406 0.5512 0.5671 RMSE:0.4574 0.7952 0.6786 Tau:0.7502 0.5673 0.4840\n",
      "EarlyStopping counter: 36 out of 60\n",
      "Epoch: 274 Step: 58636 Index:-0.1577 R2:0.8417 0.5928 0.5775 RMSE:0.4137 0.7447 0.6755 Tau:0.7511 0.5870 0.4907\n",
      "EarlyStopping counter: 37 out of 60\n",
      "Epoch: 275 Step: 58850 Index:-0.1740 R2:0.8347 0.5818 0.5745 RMSE:0.4444 0.7641 0.6948 Tau:0.7460 0.5901 0.4844\n",
      "EarlyStopping counter: 38 out of 60\n",
      "Epoch: 276 Step: 59064 Index:-0.1586 R2:0.8464 0.6034 0.5842 RMSE:0.4181 0.7408 0.6855 Tau:0.7557 0.5823 0.5016\n",
      "EarlyStopping counter: 39 out of 60\n",
      "Epoch: 277 Step: 59278 Index:-0.2250 R2:0.8400 0.5718 0.5540 RMSE:0.4381 0.7974 0.7321 Tau:0.7506 0.5724 0.4781\n",
      "EarlyStopping counter: 40 out of 60\n",
      "Epoch: 278 Step: 59492 Index:-0.2368 R2:0.8311 0.5520 0.5466 RMSE:0.4308 0.7946 0.7068 Tau:0.7461 0.5578 0.4894\n",
      "EarlyStopping counter: 41 out of 60\n",
      "Epoch: 279 Step: 59706 Index:-0.2063 R2:0.8326 0.5534 0.5752 RMSE:0.4259 0.7800 0.6709 Tau:0.7480 0.5738 0.4868\n",
      "EarlyStopping counter: 42 out of 60\n",
      "Epoch: 280 Step: 59920 Index:-0.1867 R2:0.8461 0.5837 0.5753 RMSE:0.4080 0.7625 0.6884 Tau:0.7556 0.5758 0.4817\n",
      "EarlyStopping counter: 43 out of 60\n",
      "Epoch: 281 Step: 60134 Index:-0.1955 R2:0.8582 0.5784 0.5785 RMSE:0.3952 0.7645 0.6825 Tau:0.7666 0.5690 0.4984\n",
      "EarlyStopping counter: 44 out of 60\n",
      "Epoch: 282 Step: 60348 Index:-0.2085 R2:0.8472 0.5697 0.5629 RMSE:0.4070 0.7789 0.6998 Tau:0.7556 0.5704 0.4996\n",
      "EarlyStopping counter: 45 out of 60\n",
      "Epoch: 283 Step: 60562 Index:-0.1828 R2:0.8461 0.5753 0.5700 RMSE:0.4077 0.7613 0.6814 Tau:0.7577 0.5785 0.4871\n",
      "EarlyStopping counter: 46 out of 60\n",
      "Epoch: 284 Step: 60776 Index:-0.1990 R2:0.8507 0.5726 0.5777 RMSE:0.4071 0.7701 0.6833 Tau:0.7604 0.5710 0.4931\n",
      "EarlyStopping counter: 47 out of 60\n",
      "Epoch: 285 Step: 60990 Index:-0.1766 R2:0.8391 0.5747 0.5641 RMSE:0.4235 0.7612 0.6740 Tau:0.7522 0.5846 0.4885\n",
      "EarlyStopping counter: 48 out of 60\n",
      "Epoch: 286 Step: 61204 Index:-0.2068 R2:0.8455 0.5646 0.5655 RMSE:0.4122 0.7799 0.6903 Tau:0.7551 0.5731 0.4910\n",
      "EarlyStopping counter: 49 out of 60\n",
      "Epoch: 287 Step: 61418 Index:-0.1738 R2:0.8497 0.5900 0.5827 RMSE:0.4025 0.7604 0.6723 Tau:0.7602 0.5867 0.4965\n",
      "EarlyStopping counter: 50 out of 60\n",
      "Epoch: 288 Step: 61632 Index:-0.1723 R2:0.8491 0.5875 0.5600 RMSE:0.4146 0.7620 0.7018 Tau:0.7611 0.5897 0.4888\n",
      "EarlyStopping counter: 51 out of 60\n",
      "Epoch: 289 Step: 61846 Index:-0.1781 R2:0.8368 0.5929 0.5765 RMSE:0.4467 0.7583 0.7046 Tau:0.7470 0.5802 0.4923\n",
      "EarlyStopping counter: 52 out of 60\n",
      "Epoch: 290 Step: 62060 Index:-0.2083 R2:0.7804 0.5729 0.5532 RMSE:0.4887 0.7633 0.6899 Tau:0.7239 0.5551 0.4901\n",
      "EarlyStopping counter: 53 out of 60\n",
      "Epoch: 291 Step: 62274 Index:-0.1816 R2:0.8380 0.5746 0.5601 RMSE:0.4329 0.7682 0.6991 Tau:0.7525 0.5867 0.4817\n",
      "EarlyStopping counter: 54 out of 60\n",
      "Epoch: 292 Step: 62488 Index:-0.1636 R2:0.8530 0.5902 0.5795 RMSE:0.4067 0.7438 0.6626 Tau:0.7614 0.5802 0.4950\n",
      "EarlyStopping counter: 55 out of 60\n",
      "Epoch: 293 Step: 62702 Index:-0.1856 R2:0.8525 0.5782 0.5645 RMSE:0.3991 0.7597 0.6859 Tau:0.7623 0.5741 0.4978\n",
      "EarlyStopping counter: 56 out of 60\n",
      "Epoch: 294 Step: 62916 Index:-0.2487 R2:0.8553 0.5574 0.5587 RMSE:0.4534 0.8208 0.7530 Tau:0.7644 0.5721 0.4792\n",
      "EarlyStopping counter: 57 out of 60\n",
      "Epoch: 295 Step: 63130 Index:-0.2099 R2:0.8425 0.5723 0.5605 RMSE:0.4281 0.7830 0.7241 Tau:0.7507 0.5731 0.4953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 58 out of 60\n",
      "Epoch: 296 Step: 63344 Index:-0.1849 R2:0.8407 0.5910 0.5605 RMSE:0.4290 0.7580 0.7159 Tau:0.7533 0.5731 0.4790\n",
      "EarlyStopping counter: 59 out of 60\n",
      "Epoch: 297 Step: 63558 Index:-0.1972 R2:0.8561 0.5645 0.5638 RMSE:0.4171 0.7751 0.6790 Tau:0.7651 0.5778 0.4784\n",
      "EarlyStopping counter: 60 out of 60\n",
      "Epoch: 298 Step: 63772 Index:-0.1506 R2:0.8610 0.6017 0.5752 RMSE:0.3884 0.7387 0.6854 Tau:0.7694 0.5880 0.4950\n"
     ]
    }
   ],
   "source": [
    "# train_f_list=[]\n",
    "# train_mse_list=[]\n",
    "# train_r2_list=[]\n",
    "# test_f_list=[]\n",
    "# test_mse_list=[]\n",
    "# test_r2_list=[]\n",
    "# val_f_list=[]\n",
    "# val_mse_list=[]\n",
    "# val_r2_list=[]\n",
    "# epoch_list=[]\n",
    "# train_predict_list=[]\n",
    "# test_predict_list=[]\n",
    "# val_predict_list=[]\n",
    "# train_y_list=[]\n",
    "# test_y_list=[]\n",
    "# val_y_list=[]\n",
    "# train_d_list=[]\n",
    "# test_d_list=[]\n",
    "# val_d_list=[]\n",
    "\n",
    "epoch = 0\n",
    "optimizer_list = [optimizer, optimizer_AFSE, optimizer_GRN]\n",
    "max_epoch = 1000\n",
    "while epoch < max_epoch:\n",
    "    train(model, amodel, gmodel, train_df, test_df, optimizer_list, loss_function, epoch)\n",
    "#     print(train_df.shape,test_df.shape)\n",
    "    train_d, train_f, train_r2, train_MSE, train_predict, reconstruction_loss, one_hot_loss, interger_loss,binary_loss = eval(model, amodel, gmodel, train_df,output_feature=True,return_GRN_loss=True)\n",
    "    train_predict = np.array(train_predict)\n",
    "    train_WTI = weighted_top_index(train_df, train_predict, len(train_df))\n",
    "    train_tau, _ = scipy.stats.kendalltau(train_predict,train_df[tasks[0]].values.astype(float).tolist())\n",
    "    val_d, val_f, val_r2, val_MSE, val_predict, val_reconstruction_loss, val_one_hot_loss, val_interger_loss,val_binary_loss = eval(model, amodel, gmodel, val_df,output_feature=True,return_GRN_loss=True)\n",
    "    val_predict = np.array(val_predict)\n",
    "    val_WTI = weighted_top_index(val_df, val_predict, len(val_df))\n",
    "    val_AP = AP(val_df, val_predict, len(val_df))\n",
    "    val_tau, _ = scipy.stats.kendalltau(val_predict,val_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "    test_d, test_f, test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df,output_feature=True)\n",
    "    test_predict = np.array(test_predict)\n",
    "    test_WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "#     test_AP = AP(test_df, test_predict, test_active)\n",
    "    test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    k_list = [int(len(test_df)*0.01),int(len(test_df)*0.03),int(len(test_df)*0.1),10,30,100]\n",
    "    topk_list =[]\n",
    "    false_positive_rate_list = []\n",
    "    for k in k_list:\n",
    "        a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "        topk_list.append(a)\n",
    "        false_positive_rate_list.append(b)\n",
    "    \n",
    "    epoch = epoch + 1\n",
    "    global_step = epoch * int(np.max([len(train_df),len(test_df)])/batch_size)\n",
    "    logger.add_scalar('val/WTI', val_WTI, global_step)\n",
    "    logger.add_scalar('val/AP', val_AP, global_step)\n",
    "    logger.add_scalar('val/r2', val_r2, global_step)\n",
    "    logger.add_scalar('val/RMSE', val_MSE**0.5, global_step)\n",
    "    logger.add_scalar('val/Tau', val_tau, global_step)\n",
    "#     logger.add_scalar('test/TAP', test_AP, global_step)\n",
    "    logger.add_scalar('test/r2', test_r2_a, global_step)\n",
    "    logger.add_scalar('test/RMSE', test_MSE_a**0.5, global_step)\n",
    "    logger.add_scalar('test/Tau', test_tau, global_step)\n",
    "    logger.add_scalar('val/GRN', reconstruction_loss, global_step)\n",
    "    logger.add_scalar('test/EF0.01', topk_list[0], global_step)\n",
    "    logger.add_scalar('test/EF0.03', topk_list[1], global_step)\n",
    "    logger.add_scalar('test/EF0.1', topk_list[2], global_step)\n",
    "    logger.add_scalar('test/EF10', topk_list[3], global_step)\n",
    "    logger.add_scalar('test/EF30', topk_list[4], global_step)\n",
    "    logger.add_scalar('test/EF100', topk_list[5], global_step)\n",
    "    \n",
    "#     train_mse_list.append(train_MSE**0.5)\n",
    "#     train_r2_list.append(train_r2)\n",
    "#     val_mse_list.append(val_MSE**0.5)  \n",
    "#     val_r2_list.append(val_r2)\n",
    "#     train_f_list.append(train_f)\n",
    "#     val_f_list.append(val_f)\n",
    "#     test_f_list.append(test_f)\n",
    "#     epoch_list.append(epoch)\n",
    "#     train_predict_list.append(train_predict.flatten())\n",
    "#     test_predict_list.append(test_predict.flatten())\n",
    "#     val_predict_list.append(val_predict.flatten())\n",
    "#     train_y_list.append(train_df[tasks[0]].values)\n",
    "#     val_y_list.append(val_df[tasks[0]].values)\n",
    "#     test_y_list.append(test_df[tasks[0]].values)\n",
    "#     train_d_list.append(train_d)\n",
    "#     val_d_list.append(val_d)\n",
    "#     test_d_list.append(test_d)\n",
    "\n",
    "    stop_index = - val_MSE**0.5 + val_tau\n",
    "    early_stop = stopper.step(stop_index, model)\n",
    "    early_stop = stopper_afse.step(stop_index, amodel, if_print=False)\n",
    "    early_stop = stopper_generate.step(stop_index, gmodel, if_print=False)\n",
    "#     print('epoch {:d}/{:d}, validation {} {:.4f}, {} {:.4f},best validation {r2} {:.4f}'.format(epoch, total_epoch, 'r2', val_r2, 'mse:',val_MSE, stopper.best_score))\n",
    "    print('Epoch:',epoch, 'Step:', global_step, 'Index:%.4f'%stop_index, 'R2:%.4f'%train_r2,'%.4f'%val_r2,'%.4f'%test_r2_a, 'RMSE:%.4f'%train_MSE**0.5, '%.4f'%val_MSE**0.5, \n",
    "          '%.4f'%test_MSE_a**0.5, 'Tau:%.4f'%train_tau,'%.4f'%val_tau,'%.4f'%test_tau)#, 'Tau:%.4f'%val_tau,'%.4f'%test_tau,'GRN:%.4f'%reconstruction_loss,'%.4f'%val_reconstruction_loss\n",
    "    if early_stop:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopper.load_checkpoint(model)\n",
    "stopper_afse.load_checkpoint(amodel)\n",
    "stopper_generate.load_checkpoint(gmodel)\n",
    "    \n",
    "test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df)\n",
    "test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "test_r2_ina, test_MSE_ina, test_predict_ina = eval(model, amodel, gmodel, test_df[test_active:].reset_index(drop=True))\n",
    "    \n",
    "test_predict = np.array(test_predict)\n",
    "test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "\n",
    "k_list = [int(len(test_df)*0.01),int(len(test_df)*0.05),int(len(test_df)*0.1),int(len(test_df)*0.15),int(len(test_df)*0.2),int(len(test_df)*0.25),\n",
    "          int(len(test_df)*0.3),int(len(test_df)*0.4),int(len(test_df)*0.5),50,100,150,200,250,300]\n",
    "topk_list =[]\n",
    "false_positive_rate_list = []\n",
    "for k in k_list:\n",
    "    a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "    topk_list.append(a)\n",
    "    false_positive_rate_list.append(b)\n",
    "WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "ap = AP(test_df, test_predict, test_active)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 298 r2:0.5742 RMSE:0.6699 WTI:0.3586 AP:0.6926 Tau:0.5017 \n",
      " \n",
      " Top-1:0.1818 Top-1-fp:0.0000 \n",
      " Top-5:0.5763 Top-5-fp:0.0847 \n",
      " Top-10:0.6555 Top-10-fp:0.1176 \n",
      " Top-15:0.6798 Top-15-fp:0.1517 \n",
      " Top-20:0.6891 Top-20-fp:0.1807 \n",
      " Top-25:0.7104 Top-25-fp:0.2121 \n",
      " Top-30:0.7227 Top-30-fp:0.2297 \n",
      " Top-40:0.7059 Top-40-fp:0.2836 \n",
      " Top-50:0.7860 Top-50-fp:0.3395 \n",
      " \n",
      " Top50:0.5200 Top50-fp:0.1000 \n",
      " Top100:0.6100 Top100-fp:0.1100 \n",
      " Top150:0.6933 Top150-fp:0.1533 \n",
      " Top200:0.6650 Top200-fp:0.1650 \n",
      " Top250:0.7120 Top250-fp:0.1800 \n",
      " Top300:0.7133 Top300-fp:0.2133 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(' epoch:',epoch,'r2:%.4f'%test_r2_a,'RMSE:%.4f'%test_MSE_a**0.5,'WTI:%.4f'%WTI,'AP:%.4f'%ap,'Tau:%.4f'%test_tau,'\\n','\\n',\n",
    "      'Top-1:%.4f'%topk_list[0],'Top-1-fp:%.4f'%false_positive_rate_list[0],'\\n',\n",
    "      'Top-5:%.4f'%topk_list[1],'Top-5-fp:%.4f'%false_positive_rate_list[1],'\\n',\n",
    "      'Top-10:%.4f'%topk_list[2],'Top-10-fp:%.4f'%false_positive_rate_list[2],'\\n',\n",
    "      'Top-15:%.4f'%topk_list[3],'Top-15-fp:%.4f'%false_positive_rate_list[3],'\\n',\n",
    "      'Top-20:%.4f'%topk_list[4],'Top-20-fp:%.4f'%false_positive_rate_list[4],'\\n',\n",
    "      'Top-25:%.4f'%topk_list[5],'Top-25-fp:%.4f'%false_positive_rate_list[5],'\\n',\n",
    "      'Top-30:%.4f'%topk_list[6],'Top-30-fp:%.4f'%false_positive_rate_list[6],'\\n',\n",
    "      'Top-40:%.4f'%topk_list[7],'Top-40-fp:%.4f'%false_positive_rate_list[7],'\\n',\n",
    "      'Top-50:%.4f'%topk_list[8],'Top-50-fp:%.4f'%false_positive_rate_list[8],'\\n','\\n',\n",
    "      'Top50:%.4f'%topk_list[9],'Top50-fp:%.4f'%false_positive_rate_list[9],'\\n',\n",
    "      'Top100:%.4f'%topk_list[10],'Top100-fp:%.4f'%false_positive_rate_list[10],'\\n',\n",
    "      'Top150:%.4f'%topk_list[11],'Top150-fp:%.4f'%false_positive_rate_list[11],'\\n',\n",
    "      'Top200:%.4f'%topk_list[12],'Top200-fp:%.4f'%false_positive_rate_list[12],'\\n',\n",
    "      'Top250:%.4f'%topk_list[13],'Top250-fp:%.4f'%false_positive_rate_list[13],'\\n',\n",
    "      'Top300:%.4f'%topk_list[14],'Top300-fp:%.4f'%false_positive_rate_list[14],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('target_file:',train_filename)\n",
    "# print('inactive_file:',test_filename)\n",
    "# np.savez(result_dir, epoch_list, train_f_list, train_d_list, \n",
    "#          train_predict_list, train_y_list, val_f_list, val_d_list, val_predict_list, val_y_list, test_f_list, \n",
    "#          test_d_list, test_predict_list, test_y_list)\n",
    "# sim_space = np.load(result_dir+'.npz')\n",
    "# print(sim_space['arr_10'].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
